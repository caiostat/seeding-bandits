{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeeb4572",
   "metadata": {},
   "source": [
    "This notebook is the executionable version of Seeding bandits. It performs the following:\n",
    "1. Data import and preprocessing;\n",
    "2. Estimate creator level expected reward per receiver type;\n",
    "3. Displays creator level behavior (per creator distribution of actions per receiver type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f459c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run parameters\n",
    "\n",
    "path_dir = r\"/Users/../Volumes/Raw/\"\n",
    "music_before = 1500 # all creators kept, regardless of when they made content available\n",
    "low_success = 0.5 #below the median: unsuccessful\n",
    "high_success = 0.9 #top 10% creators with more followers are deemed successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a758ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "import pickle\n",
    "sys.path.insert(0, '/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/')\n",
    "import numpy as np\n",
    "import src.utils\n",
    "from collections import Counter\n",
    "from src.utils import import_dta, import_tracks_dta, successful_creators_followers,\\\n",
    "gen_active_relations, get_fan_interactions_per_week, calculate_avg_monthly_valence,\\\n",
    "gen_active_relations_prob, get_fan_interactions_per_week_prob, stripplot_prob,\\\n",
    "reaction_probability, follower_list, filter_quantile, sample_creators_music,\\\n",
    "gen_outbound_creators\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5605a3",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2d1bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date(date):\n",
    "    '''convert date format like '2013-w09' to '2013-03-04', i.e. the first day of that week'''\n",
    "    year = date[0:4]\n",
    "    week = date[6:]\n",
    "    day = \"1\"\n",
    "    date = \"{}-{}-1\".format(year, week)\n",
    "    dt = datetime.datetime.strptime(date, \"%Y-%W-%w\")\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f8fad",
   "metadata": {},
   "source": [
    "# Data Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2605f798",
   "metadata": {},
   "source": [
    "We start by importing the raw data.  `follows_sent`, `comments_sent`, `shares_sent`, `likes_sent` and `messages_sent` contains data pn the promotional activities that the 35k users tracked in the dataset directed to other users. It includes the `user_id`, the `fan_id` and the `date_sent` which identifies the date when the prom. activity was sent. `users_info_1st` shows the type of user (creator or non-creator, which is identified by a blank) and the date the user entered the platform, for every user that sent or received prom. activities from any of the 35k users tracked in this dataset, while `users_info` contains the same information, but pertaining to the 35k users themselves.\n",
    "\n",
    "`follows_received` contains information on the follows received by the 35k users and will be used to generate the successful/unsuccessful groups of content creators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03f61585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%% 12sample_tracks.dta %%%%%%%%%%\n",
      "(56262, 7)\n",
      "%%%%%%%%%% 12sample_affiliations_sent.dta %%%%%%%%%%\n",
      "(800913, 3)\n",
      "%%%%%%%%%% 12sample_comments_made.dta %%%%%%%%%%\n",
      "(29258, 4)\n",
      "%%%%%%%%%% 12sample_reposts_made.dta %%%%%%%%%%\n",
      "(179329, 4)\n",
      "%%%%%%%%%% 12sample_favoritings_made.dta %%%%%%%%%%\n",
      "(527701, 4)\n",
      "%%%%%%%%%% 12sample_messages_sent.dta %%%%%%%%%%\n",
      "(11091, 3)\n",
      "%%%%%%%%%% 12sample_1st_deg_user_infos.dta %%%%%%%%%%\n",
      "(670746, 3)\n",
      "%%%%%%%%%% 12sample_user_infos.dta %%%%%%%%%%\n",
      "(35000, 3)\n",
      "%%%%%%%%%% 12sample_affiliations_received.dta %%%%%%%%%%\n",
      "(432503, 3)\n"
     ]
    }
   ],
   "source": [
    "#affiliations :follows\n",
    "#favoritings :likes\n",
    "\n",
    "#used in filtering:\n",
    "path_dir = r\"/Users/../Volumes/Raw/\"\n",
    "tracks = import_tracks_dta(path_dir, \"12sample_tracks.dta\");\n",
    "\n",
    "#these are the actions sent to \n",
    "follows_sent = import_dta(path_dir, \"12sample_affiliations_sent.dta\");\n",
    "comments_sent = import_dta(path_dir, \"12sample_comments_made.dta\");\n",
    "shares_sent = import_dta(path_dir, \"12sample_reposts_made.dta\");\n",
    "likes_sent = import_dta(path_dir, \"12sample_favoritings_made.dta\");\n",
    "messages_sent = import_dta(path_dir, \"12sample_messages_sent.dta\");\n",
    "\n",
    "#Used to track information on the 1st degree connections\n",
    "user_info_1st = import_dta(path_dir, \"12sample_1st_deg_user_infos.dta\");\n",
    "user_info_1st.columns = ['user_id', 'type', 'entered_platform'];\n",
    "user_info = import_dta(path_dir, \"12sample_user_infos.dta\");\n",
    "\n",
    "#Used to compute creator's success measure\n",
    "follows_received = import_dta(path_dir, \"12sample_affiliations_received.dta\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35300c65",
   "metadata": {},
   "source": [
    "Indegree and outdegree information.\n",
    "\n",
    "The functions below import the indegree and outdegree dataset. Because the raw version of those dataset are too large to be processed in memory, we preprocessed them in a separate script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbc279c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the preprocessed indegree data.\n",
    "# the data was previously split in 9 pickeld pd.dataframes for memory reasons\n",
    "def import_indegree_dask(path='/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/indegree/'):\n",
    "    df = pd.read_pickle('{}df0.pkl'.format(path))\n",
    "    df1 = pd.read_pickle('{}df1.pkl'.format(path))\n",
    "    df2 = pd.read_pickle('{}df2.pkl'.format(path))\n",
    "    df3 = pd.read_pickle('{}df3.pkl'.format(path))\n",
    "    df4 = pd.read_pickle('{}df4.pkl'.format(path))\n",
    "    df5 = pd.read_pickle('{}df5.pkl'.format(path))\n",
    "    df6 = pd.read_pickle('{}df6.pkl'.format(path))\n",
    "    df7 = pd.read_pickle('{}df7.pkl'.format(path))\n",
    "    df8 = pd.read_pickle('{}df8.pkl'.format(path))\n",
    "    df9 = pd.read_pickle('{}df9.pkl'.format(path))\n",
    "     \n",
    "    #convert pd.dataframe to dask.dataframe, which better suits big data.\n",
    "    ddf = dd.from_pandas(df, npartitions = 3)\n",
    "    ddf1 = dd.from_pandas(df1, npartitions = 3)\n",
    "    ddf2 = dd.from_pandas(df2, npartitions = 3)\n",
    "    ddf3 = dd.from_pandas(df3, npartitions = 3)\n",
    "    ddf4 = dd.from_pandas(df4, npartitions = 3)\n",
    "    ddf5 = dd.from_pandas(df5, npartitions = 3)\n",
    "    ddf6 = dd.from_pandas(df6, npartitions = 3)\n",
    "    ddf7 = dd.from_pandas(df7, npartitions = 3)\n",
    "    ddf8 = dd.from_pandas(df8, npartitions = 3)\n",
    "    ddf9 = dd.from_pandas(df9, npartitions = 3)\n",
    "    \n",
    "    concatdf = dd.multi.concat([ddf,ddf1,ddf2,ddf3,ddf4,ddf5,ddf6,ddf7,ddf8,ddf9])\n",
    "    \n",
    "    return concatdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cca037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregates preprocessed outdegree of 1st degree users\n",
    "def import_outdegree(path='/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/'):\n",
    "    d = {}\n",
    "    for i in range(6):\n",
    "       d[str(i)] = pd.read_pickle(os.path.join(path,'{}.pkl'.format(i))) \n",
    "       d[str(i)]['created_at'] =  pd.to_datetime(d[str(i)]['created_at'])\n",
    "       d[str(i)]['created_at'] = pd.to_datetime(d[str(i)]['created_at']).dt.floor('d')\n",
    "       d[str(i)] = d[str(i)].groupby([d[str(i)].contact_id, 'created_at'], as_index = False).size() \n",
    "    \n",
    "    data_outdegree = pd.concat([d['0'], d['1'], d['2'], d['3'], d['4'], d['5']])\n",
    "    data_outdegree.set_index('created_at', inplace = True)\n",
    "    return data_outdegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ded8277",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_indegree = import_indegree_dask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64e1a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outdegree = import_outdegree()\n",
    "data_outdegree.reset_index(inplace = True)\n",
    "data_outdegree['created_at'] = pd.to_datetime(data_outdegree['created_at']).dt.floor('d')\n",
    "data_outdegree.groupby(['sender_id','created_at'], as_index = False).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb3d51",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a358956e",
   "metadata": {},
   "source": [
    "## Creator ids, successful and unsucessful creators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb7bc74",
   "metadata": {},
   "source": [
    "Next, we define three lists of ids: one with the ids from the content creators, according to the `users_info` table, one with the ids of successful creators and the last one with the ids of the unsuccessful ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77715356",
   "metadata": {},
   "source": [
    "Let's start with a list of the id of creators. We also create a dataset with containing information on creators only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd634fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = user_info.type == 'creator'\n",
    "creator_ids = user_info[mask].user_id.unique()\n",
    "\n",
    "creators = user_info[user_info.type == 'creator']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b06476a",
   "metadata": {},
   "source": [
    "## Putting together a dataset with the promotional activities made by content creators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b8a09",
   "metadata": {},
   "source": [
    "The function `gen_actions_sent_df` creates a dataframe with all the promotional activities that content creators sent to users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fff0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_actions_sent_df(follows_sent, shares_sent, likes_sent, comments_sent, messages_sent, creator_ids = creator_ids):\n",
    "    '''\n",
    "    Creates dataframe containing the actions that content creators send to users.\n",
    "        Attributes:\n",
    "                    follows_sent:  dataframe with the follows sent by the 35k users.\n",
    "                    shares_sent:   dataframe with the shares sent by the 35k users.\n",
    "                    likes_sent:    dataframe with the likes sent by the 35k users.\n",
    "                    comments_sent: dataframe with the comments sent by the 35k users.\n",
    "                    messages_sent: dataframe with the messages sent by the 35k users.\n",
    "                    creator_ids:   list with content creator ids. If not none, is used to\n",
    "                                   filter out activities from non creators.\n",
    "    '''\n",
    "    \n",
    "    follows_sent['outbound_activity'] = 'follow'\n",
    "    follows_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'song_id' in shares_sent.columns:\n",
    "        shares_sent.drop(columns=[\"song_id\"])\n",
    "    shares_sent = shares_sent[['reposter_id', \"owner_id\", 'created_at']]\n",
    "    shares_sent['outbound_activity'] = 'share'\n",
    "    shares_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'track_id' in likes_sent.columns:\n",
    "        likes_sent.drop(columns=[\"track_id\"], inplace=True)\n",
    "    likes_sent['outbound_activity'] = 'like'\n",
    "    likes_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'track_id' in comments_sent.columns:\n",
    "        comments_sent.drop(columns=[\"track_id\"], inplace=True)\n",
    "    comments_sent['outbound_activity'] = 'comment'\n",
    "    comments_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    messages_sent[\"outbound_activity\"] = 'message'\n",
    "    messages_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "    df = pd.concat([follows_sent, shares_sent, likes_sent, comments_sent, messages_sent])\n",
    "\n",
    "\n",
    "    if type(creator_ids) == numpy.ndarray:\n",
    "        df = df[df['user_id'].isin(creator_ids)]\n",
    "        \n",
    "    df['week_yr'] = df.date_sent.dt.strftime('%Y-w%U')\n",
    "    df = df.loc[df['user_id'] != df['fan_id'],:]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c6b8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_sent = gen_actions_sent_df(follows_sent, shares_sent, likes_sent, comments_sent,\n",
    "                                     messages_sent, creator_ids = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6f8c4",
   "metadata": {},
   "source": [
    "## Filter only actions that were sent to non-fans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2688cf1e",
   "metadata": {},
   "source": [
    "Since are interested in acquisition of fans, we must filter the `actions_sent` to contain only the promotional activities sent to non-fans. \n",
    "We start by selecting only the necessary columns of the `follows_received` table and merging it to the `actions_sent` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b904f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_received.columns = ['fan_id', 'user_id', 'date_sent']\n",
    "followers = follows_received[[\"fan_id\", \"user_id\", \"date_sent\"]]\n",
    "followers.columns = [\"fan_id\", \"user_id\", \"follower_since\"]\n",
    "\n",
    "actions_sent = actions_sent.merge(followers, right_on = ['user_id', 'fan_id'],\n",
    "                                      left_on = ['user_id', 'fan_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dbf162",
   "metadata": {},
   "source": [
    "We then filter only actions that happened before the user follows the content creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c957f00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/cgjzt69n5hlgmtsm36p1pztw0000gn/T/ipykernel_16518/3898105865.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  actions_sent_non_followers['week_yr_date'] = actions_sent_non_followers.week_yr.apply(lambda x: process_date(x))\n"
     ]
    }
   ],
   "source": [
    "mask = (actions_sent.date_sent < actions_sent.follower_since) | (actions_sent.follower_since.isnull())\n",
    "actions_sent_non_followers =  actions_sent[mask]\n",
    "actions_sent_non_followers['week_yr_date'] = actions_sent_non_followers.week_yr.apply(lambda x: process_date(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7c2b1a",
   "metadata": {},
   "source": [
    "# Compute rewards "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc188853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reward(data_actions_sent, interval):\n",
    "    # Target Creation\n",
    "    delta = datetime.timedelta(days = interval)\n",
    "    mask = (data_actions_sent['follower_since'] <= (data_actions_sent['date_sent'] + delta).dt.floor('d'))\n",
    "\n",
    "    data_actions_sent.loc[mask, 'reward'] = 1\n",
    "    mask = data_actions_sent['reward'].isnull()\n",
    "    data_actions_sent.loc[mask, 'reward'] = 0\n",
    "    return data_actions_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4022874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_dataset = create_reward(actions_sent_non_followers,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d9b9e",
   "metadata": {},
   "source": [
    "## Updating the membership table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a61f1",
   "metadata": {},
   "source": [
    "The arms of the multiarmed bandit used in the notebook are based on user types. The user types are based on the indegree of the receivers, and are, therefore, dynamic. The function below receives a date and generates the user types at that date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3290386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_membership_table_dask(data, date, user_info = user_info_1st, d_percentiles = 10):\n",
    "    \n",
    "    '''\n",
    "    This function returns the membership table at date equals `date`. Every user that interacted with the 35k tracked \n",
    "    users and entered the platform before `date` is present in the table, even if it has indegree 0.\n",
    "    arguments:\n",
    "              data:           the indegree dataset.\n",
    "              user_info:      the dataset containing all the users that interacted with the 35k users tracked.\n",
    "              d_percentiles:  the percentiles breaks e.g. d_percentiles = 25 means that user types are the quartiles\n",
    "                              of the indegree distribution.\n",
    "    '''\n",
    "    \n",
    "    data = data[data.created_at.dt.floor('d')<=date]\n",
    "    data = data.groupby('contact_id').agg({'size':'sum'}).compute()\n",
    "    steps = 100//d_percentiles\n",
    "    \n",
    "    #merge with user info to obtain users that are not followed by anyone at the current date\n",
    "    data = user_info_1st.merge(data, left_on = 'user_id', right_on = 'contact_id', how= 'outer')\n",
    "    data.loc[data['size'].isnull(), 'size'] = 0\n",
    "    data = data[['user_id', 'size', 'entered_platform']].set_index('user_id')\n",
    "    \n",
    "    #filter out users that didnt exist in the current date\n",
    "    mask = data['entered_platform'].dt.floor('d') <= date\n",
    "    data = data.loc[mask]\n",
    "    \n",
    "    mask = (data['size']>0)\n",
    "    data.loc[~mask, 'type'] = 0 \n",
    "    \n",
    "    #cutpoints ignore users with 0 followers as they will appear in their own category\n",
    "    cutpoints = np.percentile(data['size'], np.arange(0,100, steps)) \n",
    "\n",
    "    for i in range(len(cutpoints)):\n",
    "        low = cutpoints[i]\n",
    "        try:\n",
    "            high = cutpoints[i+1]\n",
    "        except:\n",
    "            high = 100000\n",
    "        \n",
    "        mask2 = (data[mask]['size']>=low) & (data[mask]['size'] <high) & (data['size']>0)\n",
    "        data.loc[mask2,'type'] = i + 1 \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08434fcb",
   "metadata": {},
   "source": [
    "## Outdegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "63a49e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_outdegree = dd.from_pandas(data_outdegree, npartitions = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21950961",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_day =  max(actions_sent.date_sent.dt.floor('d').unique())\n",
    "outdegree_membership = update_membership_table_dask(data_outdegree, last_day,user_info = user_info_1st, d_percentiles = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b80f2",
   "metadata": {},
   "source": [
    "## Responsiveness (follow-back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f1b31f",
   "metadata": {},
   "source": [
    "1. Use actions-sent to non fans.\n",
    "2. Per fan:\n",
    "    a. number of activities received.\n",
    "    b. number of rewards\n",
    "3. Per fan:\n",
    "    a. reponsiveness: 2.b/2.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cf019cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "responsiness_level = labeled_dataset.groupby('fan_id', as_index = False).agg({'reward':'sum', 'fan_id':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b0ce9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "responsiness_level['responsiness_level'] = responsiness_level['reward']/responsiness_level['fan_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e18f839a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06249263614298843"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(responsiness_level.responsiness_level > 0)/responsiness_level.shape[0]\n",
    "#only 6% have responsiveness > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "753c5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "responsiness_level['high_responsiveness'] = responsiness_level.responsiness_level.apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1faaf",
   "metadata": {},
   "source": [
    "# Activity level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4db5e11",
   "metadata": {},
   "source": [
    "1. Use fan activities dataset.\n",
    "2. Per fan:\n",
    "    a. number of activities performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bec0ad24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%% 12sample_comments_received.dta %%%%%%%%%%\n",
      "(21386, 4)\n",
      "%%%%%%%%%% 12sample_reposts_received.dta %%%%%%%%%%\n",
      "(83013, 4)\n",
      "%%%%%%%%%% 12sample_favoritings_received.dta %%%%%%%%%%\n",
      "(286903, 4)\n",
      "%%%%%%%%%% 12sample_messages_received.dta %%%%%%%%%%\n",
      "(17364, 3)\n"
     ]
    }
   ],
   "source": [
    "comments_received = import_dta(path_dir, \"12sample_comments_received.dta\");\n",
    "shares_received = import_dta(path_dir, \"12sample_reposts_received.dta\");\n",
    "likes_received = import_dta(path_dir, \"12sample_favoritings_received.dta\");\n",
    "messages_received = import_dta(path_dir, \"12sample_messages_received.dta\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1ec99f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_received['inbound_activity'] = 'follow'\n",
    "follows_received.columns = ['fan_id', 'user_id', 'date_sent', 'inbound_activity']\n",
    "\n",
    "if 'song_id' in shares_received:\n",
    "        shares_received.drop(columns=[\"song_id\"])\n",
    "shares_received = shares_received[['reposter_id', \"owner_id\", 'created_at']]\n",
    "shares_received['inbound_activity'] = 'share'\n",
    "shares_received.columns = ['fan_id', 'user_id', 'date_sent', 'inbound_activity']\n",
    "\n",
    "if 'track_id' in likes_received:\n",
    "        likes_received = likes_received.drop(columns=[\"track_id\"])\n",
    "likes_received['inbound_activity'] = 'like'\n",
    "likes_received.columns = ['fan_id', 'user_id', 'date_sent', 'inbound_activity']\n",
    "\n",
    "if 'track_id' in comments_received:\n",
    "        comments_received = comments_received.drop(columns=[\"track_id\"])\n",
    "comments_received['inbound_activity'] = 'comment'\n",
    "comments_received.columns = ['fan_id', 'user_id', 'date_sent', 'inbound_activity']\n",
    "\n",
    "messages_received[\"outbound_activity\"] = 'message'\n",
    "messages_received.columns = ['user_id', 'fan_id', 'date_sent', 'inbound_activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c28ce54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_actions_by_fans_and_non_fans = pd.concat([follows_received, shares_received, likes_received, comments_received, messages_received])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f24d78a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_total_actions_by_fans_and_non_fans.inbound_activity != 'follow'\n",
    "activity_level = df_total_actions_by_fans_and_non_fans.loc[mask].groupby('fan_id', as_index = True).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "336daaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_level = activity_level.to_frame()\n",
    "activity_level.columns = ['activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "322f11f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08949111913838163"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(activity_level.activity >= 3)/activity_level.shape[0]\n",
    "#only 9% have activity > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a28f563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_level['high_activity'] = activity_level.activity.apply(lambda x: 1 if x > 3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "13db5a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>high_activity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fan_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163497795</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163710367</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164141210</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164292182</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164819290</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           activity  high_activity\n",
       "fan_id                            \n",
       "1433              2              0\n",
       "1923              1              0\n",
       "2626              1              0\n",
       "2698              3              0\n",
       "3494              1              0\n",
       "...             ...            ...\n",
       "163497795         1              0\n",
       "163710367         1              0\n",
       "164141210         1              0\n",
       "164292182         1              0\n",
       "164819290         1              0\n",
       "\n",
       "[240292 rows x 2 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c9c2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
