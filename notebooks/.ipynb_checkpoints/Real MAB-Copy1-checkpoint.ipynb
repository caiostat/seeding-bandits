{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b80085",
   "metadata": {},
   "source": [
    "Plan:\n",
    "v0.1:\n",
    "Decision makers: creator\n",
    "Focal decision: send a follow to a user\n",
    "Arms: user types\n",
    "\n",
    "Preparation:\n",
    "1. Create primary reward: 1st degree follows within a week of receiving the follow\n",
    "2. Create secondary reward: 2nd degree follows within a week of the primary reward\n",
    "\n",
    "Recipe:\n",
    "1. Loop over follows sent by successful creators\n",
    "2. Use TS to sample the next "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc37bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run parameters\n",
    "#used to control every run. Can be user to perfom sensitivity checks\n",
    "path_dir = r\"/Users/../Volumes/Raw/\"\n",
    "\n",
    "low_success = 0.5 #below the median: unsuccessful\n",
    "high_success = 0.9 #top 10% creators with more followers are deemed successful\n",
    "\n",
    "low_user_outdegree = 0.25 \n",
    "high_user_outdegree = 0.75\n",
    "low_user_activity = 0.25 \n",
    "high_user_activity = 0.75 \n",
    "\n",
    "activity_filter = 0\n",
    "days_delta = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e1ce848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "import pickle\n",
    "sys.path.insert(0, '/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/')\n",
    "import numpy as np\n",
    "import src.utils\n",
    "from collections import Counter\n",
    "from src.utils import import_dta, import_tracks_dta,\\\n",
    "gen_active_relations, get_fan_interactions_per_week, calculate_avg_monthly_valence,\\\n",
    "gen_active_relations_prob, get_fan_interactions_per_week_prob, stripplot_prob,\\\n",
    "reaction_probability, follower_list, filter_quantile, sample_creators_music,\\\n",
    "gen_outbound_creators\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy\n",
    "import os\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfd94097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date(date):\n",
    "    '''convert date format like '2013-w09' to '2013-03-04', i.e. the first day of that week'''\n",
    "    year = date[0:4]\n",
    "    week = date[6:]\n",
    "    day = \"1\"\n",
    "    date = \"{}-{}-1\".format(year, week)\n",
    "    dt = datetime.strptime(date, \"%Y-%W-%w\")\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e37c9a6",
   "metadata": {},
   "source": [
    "# Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad8475d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%% 12sample_tracks.dta %%%%%%%%%%\n",
      "(56262, 7)\n",
      "%%%%%%%%%% 12sample_affiliations_sent.dta %%%%%%%%%%\n",
      "(800913, 3)\n",
      "%%%%%%%%%% 12sample_comments_made.dta %%%%%%%%%%\n",
      "(29258, 4)\n",
      "%%%%%%%%%% 12sample_reposts_made.dta %%%%%%%%%%\n",
      "(179329, 4)\n",
      "%%%%%%%%%% 12sample_favoritings_made.dta %%%%%%%%%%\n",
      "(527701, 4)\n",
      "%%%%%%%%%% 12sample_messages_sent.dta %%%%%%%%%%\n",
      "(11091, 3)\n",
      "%%%%%%%%%% 12sample_1st_deg_user_infos.dta %%%%%%%%%%\n",
      "(670746, 3)\n",
      "%%%%%%%%%% 12sample_user_infos.dta %%%%%%%%%%\n",
      "(35000, 3)\n",
      "%%%%%%%%%% 12sample_affiliations_received.dta %%%%%%%%%%\n",
      "(432503, 3)\n"
     ]
    }
   ],
   "source": [
    "#affiliations :follows\n",
    "#favoritings :likes\n",
    "\n",
    "#used in filtering:\n",
    "path_dir = r\"/Users/../Volumes/Raw/\"\n",
    "tracks = import_tracks_dta(path_dir, \"12sample_tracks.dta\");\n",
    "\n",
    "#these are the actions sent to \n",
    "follows_sent = import_dta(path_dir, \"12sample_affiliations_sent.dta\");\n",
    "comments_sent = import_dta(path_dir, \"12sample_comments_made.dta\");\n",
    "shares_sent = import_dta(path_dir, \"12sample_reposts_made.dta\");\n",
    "likes_sent = import_dta(path_dir, \"12sample_favoritings_made.dta\");\n",
    "messages_sent = import_dta(path_dir, \"12sample_messages_sent.dta\");\n",
    "\n",
    "#Used to track information on the 1st degree connections\n",
    "user_info_1st = import_dta(path_dir, \"12sample_1st_deg_user_infos.dta\");\n",
    "user_info_1st.columns = ['user_id', 'type', 'entered_platform'];\n",
    "user_info = import_dta(path_dir, \"12sample_user_infos.dta\");\n",
    "\n",
    "#Used to compute creator's success measure\n",
    "follows_received = import_dta(path_dir, \"12sample_affiliations_received.dta\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b428febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (tracks.track_available == 1) & (tracks.public == 't')\n",
    "creator_ids = tracks[mask].user_id.unique()\n",
    "\n",
    "creators = tracks[(tracks.track_available == 1) & (tracks.public == 't')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00227a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_actions_sent_df(follows_sent, shares_sent, likes_sent, comments_sent, messages_sent, creator_ids = creator_ids):\n",
    "    '''\n",
    "    Creates dataframe containing the actions that content creators send to users.\n",
    "        Attributes:\n",
    "                    follows_sent:  dataframe with the follows sent by the 35k users.\n",
    "                    shares_sent:   dataframe with the shares sent by the 35k users.\n",
    "                    likes_sent:    dataframe with the likes sent by the 35k users.\n",
    "                    comments_sent: dataframe with the comments sent by the 35k users.\n",
    "                    messages_sent: dataframe with the messages sent by the 35k users.\n",
    "                    creator_ids:   list with content creator ids. If not none, is used to\n",
    "                                   filter out activities from non creators.\n",
    "    '''\n",
    "    \n",
    "    follows_sent['outbound_activity'] = 'follow'\n",
    "    follows_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'song_id' in shares_sent.columns:\n",
    "        shares_sent.drop(columns=[\"song_id\"])\n",
    "    shares_sent = shares_sent[['reposter_id', \"owner_id\", 'created_at']]\n",
    "    shares_sent['outbound_activity'] = 'share'\n",
    "    shares_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'track_id' in likes_sent.columns:\n",
    "        likes_sent.drop(columns=[\"track_id\"], inplace=True)\n",
    "    likes_sent['outbound_activity'] = 'like'\n",
    "    likes_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'track_id' in comments_sent.columns:\n",
    "        comments_sent.drop(columns=[\"track_id\"], inplace=True)\n",
    "    comments_sent['outbound_activity'] = 'comment'\n",
    "    comments_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    messages_sent[\"outbound_activity\"] = 'message'\n",
    "    messages_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "    df = pd.concat([follows_sent, shares_sent, likes_sent, comments_sent, messages_sent])\n",
    "\n",
    "\n",
    "    if type(creator_ids) == numpy.ndarray:\n",
    "        df = df[df['user_id'].isin(creator_ids)]\n",
    "        \n",
    "    df['week_yr'] = df.date_sent.dt.strftime('%Y-w%U')\n",
    "    df = df.loc[df['user_id'] != df['fan_id'],:]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e74a5072",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_sent = gen_actions_sent_df(follows_sent, shares_sent, likes_sent, comments_sent,\n",
    "                                     messages_sent, creator_ids = None)\n",
    "actions_sent = actions_sent.loc[actions_sent.user_id.isin(creators.user_id.unique())]\n",
    "\n",
    "active_users_ids = actions_sent.groupby('user_id', as_index = False).size()\n",
    "mask = active_users_ids['size']>= activity_filter\n",
    "active_users_ids = active_users_ids[mask].user_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4d777a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def successful_creators_followers(follows_received, base_date = datetime(2016, 5, 30, 0, 0), perc1 = None, perc2 = None, subset_creators = None):\n",
    "    '''Classifies content creators in successful or unsuccessfull\n",
    "        Arguments:\n",
    "                    follows_received: dataframe containing the follows received by content creators\n",
    "                    base date:        date, in datetime.datetime(YYYY, M, DD, H, M) format, in which the number \n",
    "                                      of followers per creator is calculated.\n",
    "                    perc1:            the threshold used to classify unsuccessful content creators. Creator having \n",
    "                                      total followers below the number dictated by this threshold, at the base date,\n",
    "                                      are classified as unsuccessful \n",
    "                    perc2:            the threshold used to classify successful content creators. Creator having \n",
    "                                      total followers above the number dictated by this threshold, at the base date,\n",
    "                                      are classified as successful\n",
    "                    subset_creators:  a pd.DataFrame containing the creators. If is it available, it will be used to \n",
    "                                      filter out non creators and to make sure creators with 0 followers are part of\n",
    "                                      the resulting dataset.\n",
    "        \n",
    "    '''\n",
    "    print(base_date)\n",
    "\n",
    "    if 'inbound_activity' not in follows_received.columns:\n",
    "        follows_received.columns = ['fan_id', 'user_id', 'date_sent']\n",
    "\n",
    "    mask = (follows_received['date_sent'] < base_date)\n",
    "\n",
    "    df = follows_received[mask].groupby('user_id', as_index=False).agg({'fan_id': pd.Series.nunique})\n",
    "    df.columns = ['user_id', 'followers']\n",
    "\n",
    "    \n",
    "    if type(subset_creators) == pd.DataFrame:\n",
    "        print('subsetting...')\n",
    "        df.set_index('user_id', inplace = True)\n",
    "        df = df.reindex(subset_creators.user_id.unique())\n",
    "        df.fillna(0, inplace = True)\n",
    "        df.reset_index(inplace = True)\n",
    "        df.columns = ['user_id', 'followers']\n",
    "        \n",
    "    mask = df.user_id.isin(active_users_ids)\n",
    "    df = df[mask]\n",
    "\n",
    "    low = np.quantile(df.followers, perc1)\n",
    "    high = np.quantile(df.followers, perc2)\n",
    "\n",
    "    print(\"High influencer boundary: {}\".format(high))\n",
    "    print(\"Low influencer boundary: {}\".format(low))\n",
    "\n",
    "    mask = (df[\"followers\"] <= low) | (df[\"followers\"] >= high)\n",
    "    \n",
    "    unsuccessful_creator_ids = df.loc[df[\"followers\"] <= low].user_id.unique()\n",
    "    successful_creator_ids = df.loc[df[\"followers\"] >= high].user_id.unique()\n",
    "\n",
    "    return unsuccessful_creator_ids, successful_creator_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "912f56f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-30 00:00:00\n",
      "subsetting...\n",
      "High influencer boundary: 81.0\n",
      "Low influencer boundary: 13.0\n"
     ]
    }
   ],
   "source": [
    "unsuccessful_ids, successful_ids = successful_creators_followers(follows_received, \n",
    "                                                        perc1 = low_success, perc2 = high_success, subset_creators = creators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16409a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_received.columns = ['fan_id', 'user_id', 'date_sent']\n",
    "followers = follows_received[[\"fan_id\", \"user_id\", \"date_sent\"]]\n",
    "followers.columns = [\"fan_id\", \"user_id\", \"follower_since\"]\n",
    "\n",
    "follows_sent = follows_sent.merge(followers, right_on = ['user_id', 'fan_id'],\n",
    "                                      left_on = ['user_id', 'fan_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "698ab7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_sent['week_yr_date'] = follows_sent.date_sent.dt.normalize()\n",
    "mask = (follows_sent.date_sent < follows_sent.follower_since) | (follows_sent.follower_since.isnull())\n",
    "follows_sent_non_fans =  follows_sent[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f11b57",
   "metadata": {},
   "source": [
    "# Attribute 1st and 2nd degree rewards to follows sent by creators to users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af369f25",
   "metadata": {},
   "source": [
    "1st degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023e9b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_sent_non_fans['1st_reward'] = ((follows_sent_non_fans['follower_since']>= follows_sent_non_fans['week_yr_date'])&\n",
    "(follows_sent_non_fans['follower_since'] <=  follows_sent_non_fans['week_yr_date'] + timedelta(days=7))).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb291798",
   "metadata": {},
   "source": [
    "2nd degree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152dfc1d",
   "metadata": {},
   "source": [
    "Recipe:\n",
    "\n",
    "-count fans from target that are not yet fans from the creator\n",
    "\n",
    "-chek how many of those becomes followers of the creator, within a week of the target user becoming a fan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423b09d1",
   "metadata": {},
   "source": [
    "## Helper functions to compute 2nd degree rewards (and failures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec751c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creator_follower_base_at_t(df, user_id, date):\n",
    "    '''creates an array with the followers of creator c at time t'''\n",
    "    \n",
    "    if df.loc[(df.user_id == user_id)&(df.date_sent <= date)].shape[0] == 0:\n",
    "        array = []\n",
    "        \n",
    "    else:\n",
    "        array = df.loc[(df.user_id == user_id)&(df.date_sent <= date)]\\\n",
    "        .groupby('user_id', as_index = False)['fan_id'].apply(np.array)[0] \n",
    "    \n",
    "    return set(array)\n",
    "\n",
    "#unitary test\n",
    "\n",
    "date = datetime(2016, 5, 30, 0, 0)\n",
    "followers['date_sent'] = followers.follower_since.dt.normalize()\n",
    "user_id = 37876767\n",
    "creator_followers = creator_follower_base_at_t(followers, user_id, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5cc030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_follower_base_at_t(df, user_id, date):\n",
    "    '''creates an array with the followers of target u at time t'''\n",
    "    \n",
    "    if df.loc[(df.contact_id == user_id)&(df.created_at <= date)].shape[0] == 0:\n",
    "        array = []\n",
    "        \n",
    "    else:\n",
    "        array = df.loc[(df.contact_id == user_id)&(df.created_at <= date)]\\\n",
    "        .groupby('contact_id', as_index = False)['fan_id'].apply(np.array)[0] \n",
    "    \n",
    "    return set(array)\n",
    "\n",
    "#unit test\n",
    "\n",
    "df_test = pd.read_pickle('/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/indegree/follower_list/user_followers/MAB_pre_aggregations/10362_31300.pkl')\n",
    "date = datetime(2016, 5, 30, 0, 0)\n",
    "df_test['date_sent'] = df_test.created_at.dt.normalize()\n",
    "user_id = 31271\n",
    "target_followers = target_follower_base_at_t(df_test, user_id, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d27099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def followers_in_u_not_in_c_at_t(df_follows_creator, df_follows_target, creator_id, target_id, date):\n",
    "    '''creates an array with the followers of u, at t, that are not yet followers of c'''\n",
    "    creator_followers = creator_follower_base_at_t(df_follows_creator, creator_id, date)\n",
    "    target_followers = target_follower_base_at_t(df_follows_target, target_id, date)\n",
    "\n",
    "    return creator_followers, target_followers, target_followers.difference(creator_set)\n",
    "    \n",
    "#unit test\n",
    "\n",
    "a,b,c =followers_in_u_not_in_c_at_t(followers, df_test,37876767,31271,date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e076b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_followers_from_c(df, user_id, start_date):\n",
    "    '''list the followers that c obtained in week t'''\n",
    "    delta = timedelta(days = 7)\n",
    "    return df.loc[(df.date_sent >= start_date)&(df.date_sent <= start_date + delta)]\\\n",
    "                                       .groupby('user_id', as_index = False)['fan_id'].apply(np.array)[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e625d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_new_followers_of_c_that_follow_u(potential_followers, new_followers):\n",
    "    '''count the number of new followers of c, at week t and t+7, that are followers of u'''\n",
    "    \n",
    "    return len(potential_followers.intersection(new_followers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7f8548",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fdf1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# folder path\n",
    "dir_path = r'/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/indegree/follower_list/user_followers/MAB_pre_aggregations/'\n",
    "\n",
    "# list to store files\n",
    "dict_paths = {}\n",
    "# Iterate directory\n",
    "for path in os.listdir(dir_path):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(dir_path, path)):\n",
    "        if path != '.DS_Store':\n",
    "            dict_paths[(int(path.split(\"_\",1)[0]),int(path.split(\"_\",1)[1][:-4]))] = path\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b0338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_file(user_id):\n",
    "    return dict_paths[[item for item in dicta.keys() if (user_id>= item[0])&(user_id<=item[1])][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a6512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c960218",
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_sent_non_fans['follower_since_day'] = follows_sent_non_fans['follower_since'].dt.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c31f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = follows_sent_non_fans.copy()\n",
    "df = df.loc[df.user_id.isin(successful_ids)]\n",
    "df.sort_values('fan_id', inplace = True)\n",
    "df[\"2nd_degree_successes\"] = np.nan\n",
    "df[\"2nd_degree_failures\"]  = np.nan\n",
    "delta = timedelta(days = 7)\n",
    "user_followers = followers.loc[followers.user_id.isin(successful_ids)]\n",
    "old_filename = 'mock_name'\n",
    "\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    if df.iloc[i]['1st_reward'] == 1:\n",
    "        start_date     = df.iloc[i].follower_since_day\n",
    "        user_id        = df.iloc[i].user_id\n",
    "        fan_id         = df.iloc[i].fan_id\n",
    "        new_filename   = which_file(fan_id)\n",
    "\n",
    "        if old_filename != new_filename:\n",
    "            target_followers = pd.read_pickle(\n",
    "                '/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/indegree/follower_list/user_followers/MAB_pre_aggregations/{}'\\\n",
    "                .format(new_filename))\n",
    "\n",
    "        creator_followers_t, user_followers_t, potential_followers =\\\n",
    "            followers_in_u_not_in_c_at_t(user_followers, target_followers, user_id, fan_id, start_date)\n",
    "\n",
    "        new_followers = get_new_followers_from_c(user_followers, user_id, start_date)\n",
    "\n",
    "        followers_obtained_from_u = count_new_followers_of_c_that_follow_u(potential_followers, new_followers)\n",
    "        #print(followers_obtained_from_u)\n",
    "\n",
    "        df.iloc[i, -2] = followers_obtained_from_u\n",
    "\n",
    "        df.iloc[i, -1] = len(potential_followers) - df.iloc[i][\"2nd_degree_successes\"]\n",
    "\n",
    "        old_filename = new_filename\n",
    "    else:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f5889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_type'] = df.fan_id.apply(lambda x: 'f_a' if x in f_a_ids else \n",
    "                          ('Hermit' if x in hermit_ids else\n",
    "                          ('Observer' if x in observer_ids else\n",
    "                          ('w_a' if x in w_a_ids else 'other'))))\n",
    "\n",
    "df['creator_type'] = df.user_id.apply(\n",
    "                               lambda x: 'successful' if x in successful_ids else \n",
    "                               ('unsuccessful' if x in unsuccessful_ids else 'other'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b62eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('follwers_1st_2nd_reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f8b6f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('follwers_1st_2nd_reward', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa24b183",
   "metadata": {},
   "source": [
    "For i in range(follows_sent):\n",
    "-sample user type from betas:\n",
    "-samples follow from pool:\n",
    "-update arms with sample obs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fc5b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ThompsonSamplingBandit:\n",
    "    def __init__(self, arms, df_pool):\n",
    "        self.df_pool = df_pool\n",
    "        self.arms = arms\n",
    "        self.num_arms = len(arms)\n",
    "        self.alpha1 = {arm: 1 for arm in arms}\n",
    "        self.beta1 = {arm: 10 for arm in arms}\n",
    "        self.alpha2 = {arm: 1 for arm in arms}\n",
    "        self.beta2 = {arm: 20 for arm in arms} \n",
    "        self.combined_alpha = None\n",
    "        self.combined_beta = None\n",
    "\n",
    "    def pull_arm(self):\n",
    "        # Sample a success probability for each arm using Beta distribution\n",
    "        S = {arm: (self.alpha1[arm] * self.alpha2[arm])/(\n",
    "            (self.alpha1[arm]+self.beta1[arm])*(self.alpha2[arm]+self.beta2[arm])\n",
    "            ) for arm in self.arms}\n",
    "        \n",
    "        T ={arm: ((self.alpha1[arm]*self.alpha2[arm]*(self.alpha1[arm]+1)*(self.alpha2[arm]+1))\n",
    "                  /((self.alpha1[arm]+self.beta1[arm])*(self.alpha2[arm]+self.beta2[arm])*\n",
    "                    (self.alpha1[arm]+self.beta1[arm]+1)*(self.alpha2[arm]+self.beta2[arm]+1))\n",
    "                 ) for arm in self.arms}\n",
    "\n",
    "        \n",
    "        self.combined_alpha = {arm : (S[arm]/(T[arm]-S[arm]**2)) for arm in self.arms}\n",
    "        self.combined_beta = {arm : (((1-S[arm])*(S[arm]-T[arm]))/(T[arm]-S[arm]**2)) for arm in self.arms}\n",
    "        \n",
    "        #print(self.combined_alpha)\n",
    "        #print(self.combined_beta)\n",
    "        \n",
    "        success_probs = {\n",
    "            arm: np.random.beta(self.combined_alpha[arm], self.combined_beta[arm])\n",
    "            for arm in self.arms\n",
    "        }\n",
    "\n",
    "        # Choose the arm with the highest success probability\n",
    "        arm = max(success_probs, key=success_probs.get)\n",
    "\n",
    "        # Simulate pulling the chosen arm and getting a reward\n",
    "        reward1, reward2, failure2 = self._get_reward(arm)\n",
    "\n",
    "        # Update success or failure counts based on the reward\n",
    "        if reward1 == 1:\n",
    "            self.alpha1[arm] += 1\n",
    "            self.alpha2[arm] += reward2\n",
    "            self.beta2[arm] += failure2\n",
    "        else:\n",
    "            self.beta1[arm] += 1\n",
    "        \n",
    "\n",
    "        #print('User_type:{} \\n {} follow \\n 2nd follows{}'.format(arm, reward1, reward2))\n",
    "\n",
    "    def _get_reward(self, arm):\n",
    "        # Simulate the reward based on the chosen arm\n",
    "        # You can replace this with your own reward distribution logic\n",
    "        sample = self.df_pool.loc[self.df_pool.user_type == arm].sample(1)\n",
    "\n",
    "        reward1 = sample['1st_reward'].values[0] \n",
    "        reward2 = sample['2nd_degree_successes'].values[0]\n",
    "        failure2 = sample['2nd_degree_failures'].values[0]\n",
    "\n",
    "        return reward1, reward2, failure2\n",
    "    \n",
    "    def _get_moments(self):\n",
    "        #estimate mean and variance\n",
    "        mean_1 = {arm: {'mean_1' : self.alpha1[arm]/(self.alpha1[arm]+self.beta1[arm])} for arm in arms}\n",
    "        var_1  = {arm: {'var_1' : (self.alpha1[arm]*self.beta1[arm])/\n",
    "                                     ((self.alpha1[arm]+self.beta1[arm])**2*\n",
    "                                      (self.alpha1[arm]+self.beta1[arm]+1))} for arm in arms}\n",
    "        \n",
    "        mean_2 = {arm: {'mean_2' : self.alpha2[arm]/(self.alpha2[arm]+self.beta2[arm])} for arm in arms}\n",
    "        var_2  = {arm: {'var_2' :(self.alpha2[arm]*self.beta2[arm])/\n",
    "                                     ((self.alpha2[arm]+self.beta2[arm])**2*\n",
    "                                      (self.alpha2[arm]+self.beta2[arm]+1))} for arm in arms}\n",
    "        \n",
    "        mean_comb = {arm: {'mean_comb' : self.combined_alpha[arm]/(self.combined_alpha[arm]+self.combined_beta[arm])} for arm in arms}\n",
    "        var_comb  = {arm:  {'var_comb' :(self.combined_alpha[arm]*self.combined_beta[arm])/\n",
    "                                     ((self.combined_alpha[arm]+self.combined_beta[arm])**2*\n",
    "                                      (self.combined_alpha[arm]+self.combined_beta[arm]+1))} for arm in arms}\n",
    "        \n",
    "        combined_dict = {}\n",
    "        \n",
    "        for entry in mean_1.keys():\n",
    "            combined_dict[entry] = {**mean_1[entry], **mean_2[entry], **mean_comb[entry],\n",
    "                                **var_1[entry], **var_2[entry], **var_comb[entry]}\n",
    "        \n",
    "        return combined_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1527e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 102855/102855 [13:24<00:00, 127.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a Thompson Sampling Multi-Armed Bandit with 3 arms\n",
    "num_iterations = df.shape[0]\n",
    "arms = [\"f_a\", \"w_a\", \"Observer\", \"Hermit\"]\n",
    "bandit = ThompsonSamplingBandit(arms, df)\n",
    "estimates = {}\n",
    "dfs = {}\n",
    "\n",
    "df_f_a = pd.DataFrame(index=range(num_iterations), columns=[\"mean_1\",\"mean_2\", \"mean_comb\", \"var_1\",\"var_2\",\"var_comb\"])\n",
    "df_hermit = pd.DataFrame(index=range(num_iterations), columns=[\"mean_1\",\"mean_2\", \"mean_comb\", \"var_1\",\"var_2\",\"var_comb\"])\n",
    "df_observer = pd.DataFrame(index=range(num_iterations), columns=[\"mean_1\",\"mean_2\", \"mean_comb\", \"var_1\",\"var_2\",\"var_comb\"])\n",
    "df_w_a = pd.DataFrame(index=range(num_iterations), columns=[\"mean_1\",\"mean_2\", \"mean_comb\", \"var_1\",\"var_2\",\"var_comb\"])\n",
    "\n",
    "# Pull arms for multiple iterations\n",
    "for i in tqdm(range(num_iterations)):\n",
    "    bandit.pull_arm()\n",
    "    estimates_dict = bandit._get_moments()\n",
    "    \n",
    "    for key, values in estimates_dict.items():\n",
    "        data = pd.DataFrame(values, index=[0])\n",
    "        dfs[key] = data\n",
    "\n",
    "    # Access individual DataFrames by key\n",
    "    df_f_a.iloc[i] = dfs['f_a']\n",
    "    df_hermit.iloc[i] = dfs['Observer']\n",
    "    df_observer.iloc[i] = dfs['Hermit']\n",
    "    df_w_a.iloc[i] = dfs['w_a']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a93e10",
   "metadata": {},
   "source": [
    "# Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16acc1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38483077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Assuming you have already loaded the data into the 'df_f_a', 'df_f_b', 'df_f_c', and 'df_f_d' DataFrames\n",
    "dfs = [df_f_a, df_w_a, df_hermit, df_observer]\n",
    "names = ['Focused-Active', 'Widely-Active', 'Hermit', 'Observer']\n",
    "\n",
    "# Set the confidence level (95% in this case)\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Set up the figure with multiple subplots\n",
    "# Set up the figure with multiple subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10), sharex=True, sharey=True)\n",
    "\n",
    "# Flatten the axs array so that we can loop through the subplots in 1D\n",
    "axs = axs.ravel()\n",
    "\n",
    "# Loop through each dataframe and create individual subplots\n",
    "for idx, (ax, df_) in enumerate(zip(axs, dfs)):\n",
    "    mean_values = df_['mean_1']\n",
    "    var_values = df_['var_1']\n",
    "\n",
    "    # Calculate the standard error\n",
    "    standard_error = var_values**(1/2)\n",
    "\n",
    "    # Calculate the critical value for the normal distribution\n",
    "    z_critical = norm.ppf((1 + confidence_level) / 2)\n",
    "\n",
    "    # Calculate the margin of error\n",
    "    margin_of_error = z_critical * standard_error\n",
    "\n",
    "    # Plot the mean values and confidence intervals for each dataframe\n",
    "    color = plt.cm.Paired(2*idx+1)  # Use a different color for each dataframe\n",
    "    color2 = plt.cm.Paired(2*idx)\n",
    "    \n",
    "    ax.plot(mean_values, label='{}'.format(names[idx]), color=color)\n",
    "    ax.errorbar(mean_values.index, mean_values, yerr=margin_of_error,\n",
    "                color=color2, alpha=0.003)\n",
    "    ax.set_ylabel('Mean')\n",
    "    ax.set_xlabel('Actions sent')\n",
    "    ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"labnote5/learning_1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd014cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Assuming you have already loaded the data into the 'df_f_a', 'df_f_b', 'df_f_c', and 'df_f_d' DataFrames\n",
    "dfs = [df_f_a, df_w_a, df_hermit, df_observer]\n",
    "names = ['Focused-Active', 'Widely-Active', 'Hermit', 'Observer']\n",
    "\n",
    "# Set the confidence level (95% in this case)\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Set up the figure with multiple subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10), sharex=True)\n",
    "\n",
    "# Flatten the axs array so that we can loop through the subplots in 1D\n",
    "axs = axs.ravel()\n",
    "\n",
    "# Loop through each dataframe and create individual subplots\n",
    "for idx, (ax, df_) in enumerate(zip(axs, dfs)):\n",
    "    mean_values = df_['mean_2']\n",
    "    var_values = df_['var_2']\n",
    "\n",
    "    # Calculate the standard error\n",
    "    standard_error = var_values**(1/2)\n",
    "\n",
    "    # Calculate the critical value for the normal distribution\n",
    "    z_critical = norm.ppf((1 + confidence_level) / 2)\n",
    "\n",
    "    # Calculate the margin of error\n",
    "    margin_of_error = z_critical * standard_error\n",
    "\n",
    "    # Plot the mean values and confidence intervals for each dataframe\n",
    "    color = plt.cm.Paired(2*idx+1)  # Use a different color for each dataframe\n",
    "    color2 = plt.cm.Paired(2*idx)\n",
    "    \n",
    "    ax.plot(mean_values, label='{}'.format(names[idx]), color=color)\n",
    "    ax.errorbar(mean_values.index, mean_values, yerr=margin_of_error,\n",
    "                color=color2, alpha=0.002)\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_ylabel('Mean')\n",
    "    ax.set_xlabel('Actions sent')\n",
    "    ax.legend()\n",
    "# Show the plot\n",
    "plt.savefig(\"labnote5/learning_2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e7016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Assuming you have already loaded the data into the 'df_f_a', 'df_f_b', 'df_f_c', and 'df_f_d' DataFrames\n",
    "dfs = [df_f_a, df_w_a, df_hermit, df_observer]\n",
    "names = ['Focused-Active', 'Widely-Active', 'Hermit', 'Observer']\n",
    "\n",
    "# Set the confidence level (95% in this case)\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Set up the figure with multiple subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10), sharex=True)\n",
    "\n",
    "# Flatten the axs array so that we can loop through the subplots in 1D\n",
    "axs = axs.ravel()\n",
    "\n",
    "# Loop through each dataframe and create individual subplots\n",
    "for idx, (ax, df_) in enumerate(zip(axs, dfs)):\n",
    "    mean_values = df_['mean_comb']\n",
    "    var_values = df_['var_comb']\n",
    "\n",
    "    # Calculate the standard error\n",
    "    standard_error = var_values**(1/2)\n",
    "\n",
    "    # Calculate the critical value for the normal distribution\n",
    "    z_critical = norm.ppf((1 + confidence_level) / 2)\n",
    "\n",
    "    # Calculate the margin of error\n",
    "    margin_of_error = z_critical * standard_error\n",
    "\n",
    "    # Plot the mean values and confidence intervals for each dataframe\n",
    "    color = plt.cm.Paired(2*idx+1)  # Use a different color for each dataframe\n",
    "    color2 = plt.cm.Paired(2*idx)\n",
    "    \n",
    "    ax.plot(mean_values, label='{}'.format(names[idx]), color=color)\n",
    "    ax.errorbar(mean_values.index, mean_values, yerr=margin_of_error,\n",
    "                color=color2, alpha=0.002)\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_ylabel('Mean')\n",
    "    ax.set_xlabel('Actions sent')\n",
    "    ax.legend()\n",
    "\n",
    "#ax.set_title('Proportion of followers from the target within a week of the follow-back')\n",
    "# Show the plot\n",
    "plt.savefig(\"labnote5/learning_3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67595f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b6620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf52ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_observer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc4a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hermit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ba5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['1st_reward'] == 1\n",
    "max(df.loc[mask, '2nd_degree_failures'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d490d30",
   "metadata": {},
   "source": [
    "# Pure Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b9923e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_strat(user_type):\n",
    "    \n",
    "    data = df.loc[(df.user_type == user_type)\n",
    "                  #&(df['1st_reward']==1)\n",
    "                 ]\n",
    "\n",
    "    num_iterations = df.shape[0]\n",
    "\n",
    "    direct = 0\n",
    "    indirect = 0\n",
    "\n",
    "    for i in tqdm(range(num_iterations)):\n",
    "        row = data.sample(1)\n",
    "        direct += row['1st_reward'].values[0]\n",
    "\n",
    "        if row['1st_reward'].values[0]>0:\n",
    "            indirect += row['2nd_degree_successes'].values[0]\n",
    "            \n",
    "    return direct, indirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be1c9736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 102855/102855 [00:10<00:00, 9443.14it/s]\n"
     ]
    }
   ],
   "source": [
    "direct_fa, indirect_fa = pure_strat('f_a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d34bd5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 102855/102855 [00:19<00:00, 5215.15it/s]\n"
     ]
    }
   ],
   "source": [
    "direct_wa, indirect_wa = pure_strat('w_a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2612825e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 102855/102855 [00:10<00:00, 9514.48it/s]\n"
     ]
    }
   ],
   "source": [
    "direct_hermit, indirect_hermit = pure_strat('Hermit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a00223f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 102855/102855 [00:10<00:00, 9561.52it/s]\n"
     ]
    }
   ],
   "source": [
    "direct_observer, indirect_observer = pure_strat('Observer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a69f1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102855\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(direct_fa)\n",
    "print(indirect_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db27585a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102855\n",
      "1898.0\n"
     ]
    }
   ],
   "source": [
    "print(direct_wa)\n",
    "print(indirect_wa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9b4de5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102855\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(direct_hermit)\n",
    "print(indirect_hermit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e86533d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102855\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(direct_observer)\n",
    "print(indirect_observer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee26eb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    50\n",
       "Name: 2nd_degree_successes, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df.user_type == 'Observer')]['2nd_degree_successes'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59bb171",
   "metadata": {},
   "source": [
    "indirect return:\n",
    "\n",
    "return from followers following the creator of content once target user repost the content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
