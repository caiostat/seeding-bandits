{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeeb4572",
   "metadata": {},
   "source": [
    "This notebook is the executionable version of Seeding bandits. It performs the following:\n",
    "1. Data import and preprocessing;\n",
    "2. Estimate creator level expected reward per receiver type;\n",
    "3. Displays creator level behavior (per creator distribution of actions per receiver type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f459c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run parameters\n",
    "\n",
    "path_dir = r\"/Users/../Volumes/Raw/\"\n",
    "music_before = 1500 # all creators kept, regardless of when they made content available\n",
    "low_success = 0.5 #below the median: unsuccessful\n",
    "high_success = 0.9 #top 10% creators with more followers are deemed successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37a758ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "import pickle\n",
    "sys.path.insert(0, '/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/')\n",
    "import numpy as np\n",
    "import src.utils\n",
    "from collections import Counter\n",
    "from src.utils import import_dta, import_tracks_dta, successful_creators_followers,\\\n",
    "gen_active_relations, get_fan_interactions_per_week, calculate_avg_monthly_valence,\\\n",
    "gen_active_relations_prob, get_fan_interactions_per_week_prob, stripplot_prob,\\\n",
    "reaction_probability, follower_list, filter_quantile, sample_creators_music,\\\n",
    "gen_outbound_creators\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5605a3",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2d1bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date(date):\n",
    "    '''convert date format like '2013-w09' to '2013-03-04', i.e. the first day of that week'''\n",
    "    year = date[0:4]\n",
    "    week = date[6:]\n",
    "    day = \"1\"\n",
    "    date = \"{}-{}-1\".format(year, week)\n",
    "    dt = datetime.datetime.strptime(date, \"%Y-%W-%w\")\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f8fad",
   "metadata": {},
   "source": [
    "# Data Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2605f798",
   "metadata": {},
   "source": [
    "We start by importing the raw data.  `follows_sent`, `comments_sent`, `shares_sent`, `likes_sent` and `messages_sent` contains data pn the promotional activities that the 35k users tracked in the dataset directed to other users. It includes the `user_id`, the `fan_id` and the `date_sent` which identifies the date when the prom. activity was sent. `users_info_1st` shows the type of user (creator or non-creator, which is identified by a blank) and the date the user entered the platform, for every user that sent or received prom. activities from any of the 35k users tracked in this dataset, while `users_info` contains the same information, but pertaining to the 35k users themselves.\n",
    "\n",
    "`follows_received` contains information on the follows received by the 35k users and will be used to generate the successful/unsuccessful groups of content creators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f61585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%% 12sample_tracks.dta %%%%%%%%%%\n",
      "(56262, 7)\n",
      "%%%%%%%%%% 12sample_affiliations_sent.dta %%%%%%%%%%\n",
      "(800913, 3)\n",
      "%%%%%%%%%% 12sample_comments_made.dta %%%%%%%%%%\n",
      "(29258, 4)\n",
      "%%%%%%%%%% 12sample_reposts_made.dta %%%%%%%%%%\n",
      "(179329, 4)\n",
      "%%%%%%%%%% 12sample_favoritings_made.dta %%%%%%%%%%\n",
      "(527701, 4)\n",
      "%%%%%%%%%% 12sample_messages_sent.dta %%%%%%%%%%\n",
      "(11091, 3)\n",
      "%%%%%%%%%% 12sample_1st_deg_user_infos.dta %%%%%%%%%%\n",
      "(670746, 3)\n",
      "%%%%%%%%%% 12sample_user_infos.dta %%%%%%%%%%\n",
      "(35000, 3)\n",
      "%%%%%%%%%% 12sample_affiliations_received.dta %%%%%%%%%%\n",
      "(432503, 3)\n"
     ]
    }
   ],
   "source": [
    "#affiliations :follows\n",
    "#favoritings :likes\n",
    "\n",
    "#used in filtering:\n",
    "path_dir = r\"/Users/../Volumes/Raw/\"\n",
    "tracks = import_tracks_dta(path_dir, \"12sample_tracks.dta\");\n",
    "\n",
    "#these are the actions sent to \n",
    "follows_sent = import_dta(path_dir, \"12sample_affiliations_sent.dta\");\n",
    "comments_sent = import_dta(path_dir, \"12sample_comments_made.dta\");\n",
    "shares_sent = import_dta(path_dir, \"12sample_reposts_made.dta\");\n",
    "likes_sent = import_dta(path_dir, \"12sample_favoritings_made.dta\");\n",
    "messages_sent = import_dta(path_dir, \"12sample_messages_sent.dta\");\n",
    "\n",
    "#Used to track information on the 1st degree connections\n",
    "user_info_1st = import_dta(path_dir, \"12sample_1st_deg_user_infos.dta\");\n",
    "user_info_1st.columns = ['user_id', 'type', 'entered_platform'];\n",
    "user_info = import_dta(path_dir, \"12sample_user_infos.dta\");\n",
    "\n",
    "#Used to compute creator's success measure\n",
    "follows_received = import_dta(path_dir, \"12sample_affiliations_received.dta\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35300c65",
   "metadata": {},
   "source": [
    "Indegree and outdegree information.\n",
    "\n",
    "The functions below import the indegree and outdegree dataset. Because the raw version of those dataset are too large to be processed in memory, we preprocessed them in a separate script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbc279c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the preprocessed indegree data.\n",
    "# the data was previously split in 9 pickeld pd.dataframes for memory reasons\n",
    "def import_indegree_dask(path='/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/indegree/'):\n",
    "    df = pd.read_pickle('{}df0.pkl'.format(path))\n",
    "    df1 = pd.read_pickle('{}df1.pkl'.format(path))\n",
    "    df2 = pd.read_pickle('{}df2.pkl'.format(path))\n",
    "    df3 = pd.read_pickle('{}df3.pkl'.format(path))\n",
    "    df4 = pd.read_pickle('{}df4.pkl'.format(path))\n",
    "    df5 = pd.read_pickle('{}df5.pkl'.format(path))\n",
    "    df6 = pd.read_pickle('{}df6.pkl'.format(path))\n",
    "    df7 = pd.read_pickle('{}df7.pkl'.format(path))\n",
    "    df8 = pd.read_pickle('{}df8.pkl'.format(path))\n",
    "    df9 = pd.read_pickle('{}df9.pkl'.format(path))\n",
    "     \n",
    "    #convert pd.dataframe to dask.dataframe, which better suits big data.\n",
    "    ddf = dd.from_pandas(df, npartitions = 3)\n",
    "    ddf1 = dd.from_pandas(df1, npartitions = 3)\n",
    "    ddf2 = dd.from_pandas(df2, npartitions = 3)\n",
    "    ddf3 = dd.from_pandas(df3, npartitions = 3)\n",
    "    ddf4 = dd.from_pandas(df4, npartitions = 3)\n",
    "    ddf5 = dd.from_pandas(df5, npartitions = 3)\n",
    "    ddf6 = dd.from_pandas(df6, npartitions = 3)\n",
    "    ddf7 = dd.from_pandas(df7, npartitions = 3)\n",
    "    ddf8 = dd.from_pandas(df8, npartitions = 3)\n",
    "    ddf9 = dd.from_pandas(df9, npartitions = 3)\n",
    "    \n",
    "    concatdf = dd.multi.concat([ddf,ddf1,ddf2,ddf3,ddf4,ddf5,ddf6,ddf7,ddf8,ddf9])\n",
    "    \n",
    "    return concatdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cca037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregates preprocessed outdegree of 1st degree users\n",
    "def import_outdegree(path='/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/'):\n",
    "    d = {}\n",
    "    for i in range(6):\n",
    "       d[str(i)] = pd.read_pickle(os.path.join(file_path,'{}.pkl'.format(i))) \n",
    "       d[str(i)]['created_at'] =  pd.to_datetime(d[str(i)]['created_at'])\n",
    "    \n",
    "    data_outdegree = pd.concat([d['0'], d['1'], d['2'], d['3'], d['4'], d['5']])\n",
    "    data_outdegree.set_index('created_at', inplace = True)\n",
    "    return data_outdegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ded8277",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_indegree = import_indegree_dask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64e1a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outdegree = import_outdegree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb3d51",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a358956e",
   "metadata": {},
   "source": [
    "## Creator ids, successful and unsucessful creators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb7bc74",
   "metadata": {},
   "source": [
    "Next, we define three lists of ids: one with the ids from the content creators, according to the `users_info` table, one with the ids of successful creators and the last one with the ids of the unsuccessful ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77715356",
   "metadata": {},
   "source": [
    "Let's start with a list of the id of creators. We also create a dataset with containing information on creators only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd634fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = user_info.type == 'creator'\n",
    "creator_ids = user_info[mask].user_id.unique()\n",
    "\n",
    "creators = user_info[user_info.type == 'creator']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300423d0",
   "metadata": {},
   "source": [
    "Now we create a function that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "923ca719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def successful_creators_followers(follows_received, base_date = datetime.datetime(2016, 5, 30, 0, 0), perc1 = None, perc2 = None, subset_creators = None):\n",
    "    '''Classifies content creators in successful or unsuccessfull\n",
    "        Arguments:\n",
    "                    follows_received: dataframe containing the follows received by content creators\n",
    "                    base date:        date, in datetime.datetime(YYYY, M, DD, H, M) format, in which the number \n",
    "                                      of followers per creator is calculated.\n",
    "                    perc1:            the threshold used to classify unsuccessful content creators. Creator having \n",
    "                                      total followers below the number dictated by this threshold, at the base date,\n",
    "                                      are classified as unsuccessful \n",
    "                    perc2:            the threshold used to classify successful content creators. Creator having \n",
    "                                      total followers above the number dictated by this threshold, at the base date,\n",
    "                                      are classified as successful\n",
    "                    subset_creators:  a pd.DataFrame containing the creators. If is it available, it will be used to \n",
    "                                      filter out non creators and to make sure creators with 0 followers are part of\n",
    "                                      the resulting dataset.\n",
    "        \n",
    "    '''\n",
    "    print(base_date)\n",
    "\n",
    "    if 'inbound_activity' not in follows_received.columns:\n",
    "        follows_received.columns = ['fan_id', 'user_id', 'date_sent']\n",
    "\n",
    "    mask = (follows_received['date_sent'] < base_date)\n",
    "\n",
    "    df = follows_received[mask].groupby('user_id', as_index=False).agg({'fan_id': pd.Series.nunique})\n",
    "    df.columns = ['user_id', 'followers']\n",
    "\n",
    "    if type(subset_creators) == pd.DataFrame:\n",
    "        subset_creators = pd.DataFrame(subset_creators.user_id.unique(), columns = ['user_id'])\n",
    "        df = subset_creators.merge(df, on = 'user_id', how = 'left')\n",
    "        df.fillna(0, inplace = True)\n",
    "\n",
    "    low = np.quantile(df.followers, perc1)\n",
    "    high = np.quantile(df.followers, perc2)\n",
    "\n",
    "    print(\"High influencer boundary: {}\".format(high))\n",
    "    print(\"Low influencer boundary: {}\".format(low))\n",
    "\n",
    "    mask = (df[\"followers\"] <= low) | (df[\"followers\"] >= high)\n",
    "    \n",
    "    unsuccessful_creator_ids = df.loc[df[\"followers\"] <= low].user_id.unique()\n",
    "    successful_creator_ids = df.loc[df[\"followers\"] >= high].user_id.unique()\n",
    "\n",
    "    return unsuccessful_creator_ids, successful_creator_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c75277a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-30 00:00:00\n",
      "High influencer boundary: 66.0\n",
      "Low influencer boundary: 9.0\n"
     ]
    }
   ],
   "source": [
    "unsuccessful_ids, successful_ids = successful_creators_followers(follows_received, \n",
    "                                                        perc1 = low_success, perc2 = high_success, subset_creators = creators)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b06476a",
   "metadata": {},
   "source": [
    "## Putting together a dataset with the promotional activities made by content creators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b8a09",
   "metadata": {},
   "source": [
    "The function `gen_actions_sent_df` creates a dataframe with all the promotional activities that content creators sent to users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8fff0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_actions_sent_df(follows_sent, shares_sent, likes_sent, comments_sent, messages_sent, creator_ids = creator_ids):\n",
    "    '''\n",
    "    Creates dataframe containing the actions that content creators send to users.\n",
    "        Attributes:\n",
    "                    follows_sent:  dataframe with the follows sent by the 35k users.\n",
    "                    shares_sent:   dataframe with the shares sent by the 35k users.\n",
    "                    likes_sent:    dataframe with the likes sent by the 35k users.\n",
    "                    comments_sent: dataframe with the comments sent by the 35k users.\n",
    "                    messages_sent: dataframe with the messages sent by the 35k users.\n",
    "                    creator_ids:   list with content creator ids. If not none, is used to\n",
    "                                   filter out activities from non creators.\n",
    "    '''\n",
    "    \n",
    "    follows_sent['outbound_activity'] = 'follow'\n",
    "    follows_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'song_id' in shares_sent.columns:\n",
    "        shares_sent.drop(columns=[\"song_id\"])\n",
    "    shares_sent = shares_sent[['reposter_id', \"owner_id\", 'created_at']]\n",
    "    shares_sent['outbound_activity'] = 'share'\n",
    "    shares_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'track_id' in likes_sent.columns:\n",
    "        likes_sent.drop(columns=[\"track_id\"], inplace=True)\n",
    "    likes_sent['outbound_activity'] = 'like'\n",
    "    likes_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'track_id' in comments_sent.columns:\n",
    "        comments_sent.drop(columns=[\"track_id\"], inplace=True)\n",
    "    comments_sent['outbound_activity'] = 'comment'\n",
    "    comments_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    messages_sent[\"outbound_activity\"] = 'message'\n",
    "    messages_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "    df = pd.concat([follows_sent, shares_sent, likes_sent, comments_sent, messages_sent])\n",
    "\n",
    "\n",
    "    if type(creator_ids) == numpy.ndarray:\n",
    "        df = df[df['user_id'].isin(creator_ids)]\n",
    "        \n",
    "    df['week_yr'] = df.date_sent.dt.strftime('%Y-w%U')\n",
    "    df = df.loc[df['user_id'] != df['fan_id'],:]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6c6b8f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering creators\n"
     ]
    }
   ],
   "source": [
    "actions_sent = gen_actions_sent_df(follows_sent, shares_sent, likes_sent, comments_sent,\n",
    "                                     messages_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6f8c4",
   "metadata": {},
   "source": [
    "## Filter only actions that were sent to non-fans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2688cf1e",
   "metadata": {},
   "source": [
    "Since are interested in acquisition of fans, we must filter the `actions_sent` to contain only the promotional activities sent to non-fans. \n",
    "We start by selecting only the necessary columns of the `follows_received` table and merging it to the `actions_sent` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b904f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_received.columns = ['fan_id', 'user_id', 'date_sent']\n",
    "followers = follows_received[[\"fan_id\", \"user_id\", \"date_sent\"]]\n",
    "followers.columns = [\"fan_id\", \"user_id\", \"follower_since\"]\n",
    "\n",
    "actions_sent = actions_sent.merge(followers, right_on = ['user_id', 'fan_id'],\n",
    "                                      left_on = ['user_id', 'fan_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dbf162",
   "metadata": {},
   "source": [
    "We then filter only actions that happened before the user follows the content creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c957f00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/cgjzt69n5hlgmtsm36p1pztw0000gn/T/ipykernel_88165/3898105865.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  actions_sent_non_followers['week_yr_date'] = actions_sent_non_followers.week_yr.apply(lambda x: process_date(x))\n"
     ]
    }
   ],
   "source": [
    "mask = (actions_sent.date_sent < actions_sent.follower_since) | (actions_sent.follower_since.isnull())\n",
    "actions_sent_non_followers =  actions_sent[mask]\n",
    "actions_sent_non_followers['week_yr_date'] = actions_sent_non_followers.week_yr.apply(lambda x: process_date(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "464d3381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403066, 7)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_sent_non_followers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0693f2a0",
   "metadata": {},
   "source": [
    "## Create rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b3adb1",
   "metadata": {},
   "source": [
    "The last step in the data preprocessing is the creation of the rewards column. We do it with the function below. It adds some flexibility to the process by allowing us to change the definition of a reward with the parameter `interval`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cee2a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reward(data_actions_sent, interval):\n",
    "    # Target Creation\n",
    "    delta = datetime.timedelta(days = interval)\n",
    "    mask = (data_actions_sent['follower_since'] <= (data_actions_sent['date_sent'] + delta).dt.floor('d'))\n",
    "\n",
    "    data_actions_sent.loc[mask, 'reward'] = 1\n",
    "    mask = data_actions_sent['reward'].isnull()\n",
    "    data_actions_sent.loc[mask, 'reward'] = 0\n",
    "    return data_actions_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a6e8d2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/cgjzt69n5hlgmtsm36p1pztw0000gn/T/ipykernel_88165/4196489213.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_actions_sent.loc[mask, 'reward'] = 1\n"
     ]
    }
   ],
   "source": [
    "labeled_dateset = create_reward(actions_sent_non_followers,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63678f17",
   "metadata": {},
   "source": [
    "# The multiarmed bandit estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec7852",
   "metadata": {},
   "source": [
    "Below, we implement `MultiArmedBandits` class. This class is used to track exploration and exploitation of agents facing a multi armed problem. It is initialized with arms' names and the content creator id as arguments. \n",
    "It's methods enable us to track each arm's trials and rewards, aswell as estimate the mean reward and reward variance.\n",
    "The `update_batch` method allows for batched updates on the multiarmed bandits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154858ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiArmedBandit:\n",
    "    \n",
    "    def __init__(self, arm_names, user_id):\n",
    "        self.user_id = user_id\n",
    "        self.arm_names = arm_names\n",
    "        self.arms = {k:{'Sent':0,'Reward':0} for k in arm_names}\n",
    "        self.batch = {k:{'Sent':0,'Reward':0} for k in arm_names}\n",
    "        self.means = np.array(len(arm_names))\n",
    "        self.variances = np.array(len(arm_names))\n",
    "        self.last_arm_pulled = None\n",
    "        self.arm_switches = 0\n",
    "        self.total_trials = 0 \n",
    "        self.trials_at_day = 0\n",
    "        self.rewards = 0\n",
    "    \n",
    "    def initialize_priors(self):\n",
    "        pass\n",
    "    \n",
    "    def update_batch(self, target, outcome):\n",
    "        self.batch[target]['Sent'] += 1\n",
    "        self.batch[target]['Reward'] += outcome\n",
    "        self.arm_switches += self.arm_switches + (self.last_arm_pulled != str(target))\n",
    "        self.last_arm_pulled = str(target)\n",
    "        self.total_trials += 1\n",
    "        self.trials_at_day += 1\n",
    "        self.rewards += outcome\n",
    "    \n",
    "    def update_arms(self):\n",
    "        for k in self.batch.keys():\n",
    "            for j in self.batch[k]:\n",
    "                self.arms[k][j] += self.batch[k][j]\n",
    "        self.batch = {k:{'Sent':0,'Reward':0} for k in self.arm_names}\n",
    "        self.trials_at_day = 0\n",
    "                \n",
    "    def estimate_moments(self):\n",
    "        \n",
    "        Sent = np.array([a[1]['Sent'] for a in self.arms.items()])\n",
    "        Reward = np.array([a[1]['Reward'] for a in self.arms.items()])\n",
    "        \n",
    "        alpha = Reward + 1 \n",
    "        beta = (Sent-Reward)+1\n",
    "\n",
    "        mean = alpha/(alpha+beta)\n",
    "        variance = (alpha*beta)/((alpha+beta+1)*((alpha+beta)**2))\n",
    "        \n",
    "        self.means = np.transpose(np.around(mean,3))\n",
    "        self.variances = np.transpose(np.around(np.sqrt(variance),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d9b9e",
   "metadata": {},
   "source": [
    "## Updating the membership table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a61f1",
   "metadata": {},
   "source": [
    "The arms of the multiarmed bandit used in the notebook are based on user types. The user types are based on the indegree of the receivers, and are, therefore, dynamic. The function below receives a date and generates the user types at that date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_membership_table_dask(data, date, user_info = user_info_1st, d_percentiles = 10):\n",
    "    \n",
    "    '''\n",
    "    This function returns the membership table at date equals `date`. Every user that interacted with the 35k tracked \n",
    "    users and entered the platform before `date` is present in the table, even if it has indegree 0.\n",
    "    arguments:\n",
    "              data:           the indegree dataset.\n",
    "              user_info:      the dataset containing all the users that interacted with the 35k users tracked.\n",
    "              d_percentiles:  the percentiles breaks e.g. d_percentiles = 25 means that user types are the quartiles\n",
    "                              of the indegree distribution.\n",
    "    '''\n",
    "    \n",
    "    data = data[data.created_at.dt.floor('d')<=upper_limit]\n",
    "    data = data.groupby('contact_id').agg({'size':'sum'}).compute()\n",
    "    steps = 100//d_percentiles\n",
    "    \n",
    "    #merge with user info to obtain users that are not followed by anyone at the current date\n",
    "    data = user_info_1st.merge(data, left_on = 'user_id', right_on = 'contact_id', how= 'outer')\n",
    "    data.loc[data['size'].isnull(), 'size'] = 0\n",
    "    data = data[['user_id', 'size', 'entered_platform']].set_index('user_id')\n",
    "    \n",
    "    #filter out users that didnt exist in the current date\n",
    "    mask = data['entered_platform'].dt.floor('d') <= date\n",
    "    data = data.loc[mask]\n",
    "    \n",
    "    mask = (data['size']>0)\n",
    "    data.loc[~mask, 'type'] = 0 \n",
    "    \n",
    "    #cutpoints ignore users with 0 followers as they will appear in their own category\n",
    "    cutpoints = np.percentile(data['size'], np.arange(0,100, steps)) \n",
    "\n",
    "    for i in range(len(cutpoints)):\n",
    "        low = cutpoints[i]\n",
    "        try:\n",
    "            high = cutpoints[i+1]\n",
    "        except:\n",
    "            high = 100000\n",
    "        \n",
    "        mask2 = (data[mask]['size']>=low) & (data[mask]['size'] <high) & (data['size']>0)\n",
    "        data.loc[mask2,'type'] = i + 1 \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b675be3",
   "metadata": {},
   "source": [
    "Now we are ready to run the mabs that simulate the content creators exploration/exploitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6110ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create arm names that will be used in the MultiArmedBandit instances.\n",
    "arm_names = [i for i in range(0,11)]\n",
    "\n",
    "# filter out content creators that are neither successful or unsuccessful.\n",
    "mask = (actions_sent_non_followers.user_id.isin(successful_ids) | actions_sent_non_followers.user_id.isin(unsuccessful_ids))\n",
    "df = actions_sent_non_followers[mask]\n",
    "\n",
    "# initializes dictionaries that will store the values.\n",
    "#d will store the MultiArmedBandit instances\n",
    "#e will store the estimated mean and variances.\n",
    "d = {}\n",
    "e = {}\n",
    "\n",
    "#initialize parameters\n",
    "first_day = min(actions_sent_non_followers.date_sent.dt.floor('d').unique())\n",
    "last_day =  max(actions_sent_non_followers.date_sent.dt.floor('d').unique())\n",
    "membership = update_membership_table_dask(data_in, first_day, d_percentiles = 10)\n",
    "fan_not_found = [] #list that stores fans that were not found in the membership table.\n",
    "user_ids = df.user_id.unique()\n",
    "\n",
    "#initialize MABs and auxiliary datasets.\n",
    "for user_id in df.user_id.unique():\n",
    "    d[user_id] = MultiArmedBandit(arm_names, user_id)\n",
    "\n",
    "    dataset_mean = pd.DataFrame({**{'date':pd.date_range(start = first_day, end=last_day)},\n",
    "                                 **{str(k):0 for k in range(0,11)}}) \n",
    "    dataset_std = pd.DataFrame({**{'date':pd.date_range(start = first_day, end=last_day)},\n",
    "                                 **{str(k):0 for k in range(0,11)}}) \n",
    "    trials = pd.DataFrame({**{'date':pd.date_range(start = first_day, end=last_day)},\n",
    "                                 **{'trials_at_date':np.nan}}) \n",
    "    \n",
    "    e[user_id] = {'dataset_std': dataset_std, 'dataset_mean': dataset_mean, 'trials' : trials}\n",
    "\n",
    "#update MABs\n",
    "for day in tqdm(actions_sent_non_followers.date_sent.dt.floor('d').unique()):\n",
    "    for user_id in df.loc[df['date_sent'].dt.floor('d') == day].user_id.unique():\n",
    "        df_subset = df.loc[(df['date_sent'].dt.floor('d') == day)&(df['user_id'] == user_id)]\n",
    "        for action in range(len(df_subset)):\n",
    "            fan_id = df_subset.iloc[action].fan_id\n",
    "            try:\n",
    "                user_type = membership.loc[membership.index == fan_id].type.values[0]\n",
    "                d[user_id].update_batch(user_type, df_subset.iloc[action].reward)\n",
    "            except KeyError:\n",
    "                fan_not_found.append([fan_id, day, df_subset.iloc[action].outbound_activity])\n",
    "            except IndexError:\n",
    "                fan_not_found.append([fan_id, day, df_subset.iloc[action].outbound_activity])\n",
    "  #REWRITE THIS AS A LOOP OVER ALL USER_IDS          \n",
    "    for user_id in user_ids:\n",
    "        e[user_id]['trials'].loc[e[user_id]['trials'].date == day, 'trials_at_date'] = d[user_id].trials_at_day\n",
    "        d[user_id].update_arms()\n",
    "        d[user_id].estimate_moments()\n",
    "        e[user_id]['dataset_mean'].loc[e[user_id]['dataset_mean'].date == day, '0':] = np.transpose(d[user_id].means)\n",
    "        e[user_id]['dataset_std'].loc[e[user_id]['dataset_mean'].date == day, '0':] = np.transpose(d[user_id].variances)\n",
    "      \n",
    "   #update membership table at the end of each day \n",
    "    membership = update_membership_table_dask(data_in, day, d_percentiles = 10)\n",
    "    \n",
    "for user_id in df.user_id.unique():\n",
    "    e[user_id]['total_trials'] = d[user_id].total_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab7df7",
   "metadata": {},
   "source": [
    "Now that we have the MAB estimates, it is time to check content creators behavior.\n",
    "The following code is outdated, as tracks the behavior of all individuals in the `df` dataframe. It was initially intended to compare the behavior of successful and unsuccessful creators, but it might be more informative to track the behavior of individual creators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2d7239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekly_membership(df, data_in):\n",
    "    '''\n",
    "    Function receives the actions performed data frame and the indegree data. Returns the df with an extra columns,\n",
    "    identifying the user type that received an action.\n",
    "        Arguments:\n",
    "                    df:      dataframe containing the actions sent by content creators.\n",
    "                    data_in: indegree dataset\n",
    "    '''\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    df_copy['type'] = 0\n",
    "    \n",
    "    first_date = min(df_copy.date_sent)\n",
    "    membership = update_membership_table_dask(data_in, first_day, d_percentiles = 10)\n",
    "    \n",
    "    for day in tqdm(df_copy.date_sent.dt.floor('d').unique()):\n",
    "        mask = (df_copy['date_sent'].dt.floor('d') == day)\n",
    "        df_subset = df_copy[mask]\n",
    "        for i in range(df_copy[mask].shape[0]):\n",
    "            fan_id = df_subset.iloc[i].fan_id\n",
    "            try:\n",
    "                df_subset.iloc[i,-1] = (int(membership.loc[membership.index == fan_id]['type']))\n",
    "                print('.', end='')\n",
    "        \n",
    "            except:\n",
    "                \n",
    "                df_subset.iloc[i,-1] = 'Fan not found'\n",
    "                print('x', end ='')\n",
    "                \n",
    "        df_copy[mask] = df_subset\n",
    "        membership = update_membership_table_dask(data_in, day, d_percentiles = 10)\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af29f2a",
   "metadata": {},
   "source": [
    "The function below plots the behavior information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448192f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning(data, number, title):\n",
    "    '''\n",
    "    Plots the targeting behavior of content creators\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    data_grouped = data.groupby('week_yr_date', as_index = False).size()\n",
    "    data.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity',\n",
    "       'interaction_week', 'interaction_year', 'week_yr',\n",
    "       'follower_since', 'week_yr_date', 'reward',\n",
    "       'Receiver Type']\n",
    "    \n",
    "    lim_inf = min(data.date_sent)\n",
    "    lim_sup = max(data.date_sent)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 9))\n",
    "\n",
    "    hue_order_l = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "\n",
    "    sns.set(rc={'figure.figsize':(12,8)})\n",
    "    sns.set_style(\"white\")\n",
    "    sns.kdeplot(data=data,\n",
    "            x=\"week_yr_date\",\n",
    "            hue='Receiver Type',\n",
    "            hue_order= hue_order_l,\n",
    "            multiple=\"fill\",\n",
    "            #weights=\"Val\",\n",
    "            bw_adjust = 1)\\\n",
    "    .set(xlim=(lim_inf, lim_sup), title='Figure {}: {} - Share of trials per receiver type.'.format(number, title), xlabel='Week',\n",
    "     ylabel='Share')\n",
    "    \n",
    "    ax2 = plt.twinx()\n",
    "    sns.lineplot(data=data_grouped,\n",
    "                 x = \"week_yr_date\", \n",
    "                 y = \"size\", \n",
    "                 color=\"black\", \n",
    "                 ax=ax2, \n",
    "                 legend = 'auto',\n",
    "                 linewidth = 2)\\\n",
    "    .set(ylabel='Total Promotional Actions', yscale=\"log\")\n",
    "    plt.annotate('''Note: each color corresponds to a receiver type. The black line is the total number of actions per week.'''\n",
    "             , (0,0), (0, -35), xycoords='axes fraction', textcoords='offset points', va='top', fontsize=14);\n",
    "\n",
    "    #ax.legend(title='Receiver type', loc='best', labels = ['10', '9', '8', '7', '6', '5', '4', '3', '2', '1', '0']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d93c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (actions_sent_non_followers.user_id.isin(successful_ids) | actions_sent_non_followers.user_id.isin(unsuccessful_ids))\n",
    "df = actions_sent_non_followers[mask]\n",
    "dynamics = weekly_membership(df, data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b43467",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (dynamics.user_id.isin(successful_ids)) & (dynamics['Receiver Type'] != 'Fan not found')\n",
    "success_dynamics = dynamics[mask]\n",
    "plot_learning(success_dynamics, 21, 'Successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83a9b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (dynamics.user_id.isin(unsuccessful_ids)) & (dynamics['Receiver Type'] != 'Fan not found')\n",
    "unsuccess_dynamics = dynamics[mask]\n",
    "plot_learning(unsuccess_dynamics, 22, 'Unsuccessful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9b693748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_estimates(df, arm_names):\n",
    "\n",
    "    '''\n",
    "    Summarizes all the infomration present in dictionarys d and e into tables with the MABs` information\n",
    "    '''\n",
    "    \n",
    "    dataset_last_mean = pd.DataFrame(index = df.user_id.unique(), columns = arm_names)\n",
    "    dataset_last_std = pd.DataFrame(index = df.user_id.unique(), columns = arm_names)\n",
    "    df_trial_info = pd.DataFrame(index = df.user_id.unique(), columns = ['total_trials'])\n",
    "    df_summary_rewards = pd.DataFrame(index = df.user_id.unique(), columns = ['Rewards'])\n",
    "    arm_names = [i for i in range(0,11)]\n",
    "\n",
    "    for user_id in df.user_id.unique():\n",
    "        try:\n",
    "            dataset_last_mean.loc[user_id, :] = list(e[user_id]['dataset_mean'].iloc[-1,1:])\n",
    "            dataset_last_std.loc[user_id, :] = list(e[user_id]['dataset_std'].iloc[-1,1:])\n",
    "            df_trial_info.loc[user_id, :] = d[user_id].total_trials\n",
    "            df_summary_rewards.loc[user_id, :] = d[user_id].rewards\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    init = 0\n",
    "      \n",
    "    df_trial_info = pd.DataFrame(index = arm_names , columns = ['Rewards', 'Unique_creators', 'trials'])\n",
    "    for j in range(len(arm_names)):\n",
    "        df_trial_info.iloc[j-init]['trials'] = list()\n",
    "        df_trial_info.iloc[j-init]['Unique_creators'] = 0\n",
    "        df_trial_info.iloc[j-init]['Rewards'] = 0\n",
    "    for key in df.user_id.unique():\n",
    "        for j in range(len(arm_names)):\n",
    "            df_trial_info.iloc[j-init]['Rewards'] += d[key].arms[j]['Reward']\n",
    "            if d[key].arms[j]['Sent'] != 0:\n",
    "                df_trial_info.iloc[j-init]['Unique_creators'] = df_trial_info.iloc[j-init]['Unique_creators']+1\n",
    "            df_trial_info.iloc[j-init]['trials'].extend([d[key].arms[j]['Sent']])\n",
    "    df_trial_info['Total_trials'] = df_trial_info.trials.apply(lambda x: np.sum(x))\n",
    "    df_trial_info['Median_trials'] = df_trial_info.trials.apply(lambda x: np.median(x))\n",
    "    df_trial_info['Mean_trials'] = df_trial_info.trials.apply(lambda x: np.mean(x))\n",
    "    df_trial_info['Std_trials'] = df_trial_info.trials.apply(lambda x: np.std(x))\n",
    "\n",
    "    summary = pd.DataFrame(dataset_last_mean[arm_names].mean(), columns = ['Mean Estimate']).merge(\n",
    "            pd.DataFrame(dataset_last_std[arm_names].mean(), columns = ['Std Estimate']), left_index=True, right_index=True).merge(\n",
    "        df_trial_info[['Rewards','Unique_creators','Total_trials','Median_trials', 'Mean_trials', 'Std_trials']\n",
    "            ],left_index=True, right_index=True).reindex(arm_names)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (actions_sent_non_followers.user_id.isin(successful_ids))\n",
    "df = actions_sent_non_followers[mask]\n",
    "print('Unique successful creators:', df.user_id.nunique())\n",
    "successful_summary = gen_estimates(df, arm_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44438cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a4e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_summary.to_excel('tables/sucessful.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f8d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (actions_sent_non_followers.user_id.isin(unsuccessful_ids))\n",
    "df = actions_sent_non_followers[mask]\n",
    "print('Unique unsuccessful creators:', df.user_id.nunique())\n",
    "unsuccessful_summary = gen_estimates(df, arm_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c09f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsuccessful_summary.to_excel('tables/unsucessful.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd96c95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
