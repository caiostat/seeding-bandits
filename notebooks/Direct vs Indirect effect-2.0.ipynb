{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7de64a06",
   "metadata": {},
   "source": [
    "**This notebook is the executable version of lab note 3.\n",
    "It answers the following questions:**\n",
    "\n",
    "Finally, we answer 4 items:\n",
    "\n",
    "    1. Are successful creators more connected to high-outdegree users than do unsuccessful creators?\n",
    "    2. Are mavens more connected to successful creators than to unsuccessful creators?\n",
    "    3. Do successful creators send more non-follow actions towards mavens than to zombies?\n",
    "    4. Do successful creators send more non-follow actions towards mavens than to stars?\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f459c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run parameters\n",
    "#used to control every run. Can be user to perfom sensitivity checks\n",
    "path_dir = r\"/Users/../Volumes/Raw/\"\n",
    "\n",
    "low_success = 0.5 #below the median: unsuccessful\n",
    "high_success = 0.9 #top 10% creators with more followers are deemed successful\n",
    "\n",
    "low_user_outdegree = 0.25 \n",
    "high_user_outdegree = 0.75\n",
    "low_user_activity = 0.25 \n",
    "high_user_activity = 0.75 \n",
    "\n",
    "activity_filter = 0\n",
    "days_delta = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a758ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "import pickle\n",
    "sys.path.insert(0, '/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/')\n",
    "import numpy as np\n",
    "import src.utils\n",
    "from collections import Counter\n",
    "from src.utils import import_dta, import_tracks_dta,\\\n",
    "gen_active_relations, get_fan_interactions_per_week, calculate_avg_monthly_valence,\\\n",
    "gen_active_relations_prob, get_fan_interactions_per_week_prob, stripplot_prob,\\\n",
    "reaction_probability, follower_list, filter_quantile, sample_creators_music,\\\n",
    "gen_outbound_creators\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy\n",
    "import os\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2d1bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date(date):\n",
    "    '''convert date format like '2013-w09' to '2013-03-04', i.e. the first day of that week'''\n",
    "    year = date[0:4]\n",
    "    week = date[6:]\n",
    "    day = \"1\"\n",
    "    date = \"{}-{}-1\".format(year, week)\n",
    "    dt = datetime.strptime(date, \"%Y-%W-%w\")\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f8fad",
   "metadata": {},
   "source": [
    "# Data Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2605f798",
   "metadata": {},
   "source": [
    "We start by importing the raw data.  `follows_sent`, `comments_sent`, `shares_sent`, `likes_sent` and `messages_sent` contains data pn the promotional activities that the 35k users tracked in the dataset directed to other users. It includes the `user_id`, the `fan_id` and the `date_sent` which identifies the date when the prom. activity was sent. `users_info_1st` shows the type of user (creator or non-creator, which is identified by a blank) and the date the user entered the platform, for every user that sent or received prom. activities from any of the 35k users tracked in this dataset, while `users_info` contains the same information, but pertaining to the 35k users themselves.\n",
    "\n",
    "`follows_received` contains information on the follows received by the 35k users and will be used to generate the successful/unsuccessful groups of content creators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03f61585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%% 12sample_tracks.dta %%%%%%%%%%\n",
      "(56262, 7)\n",
      "%%%%%%%%%% 12sample_affiliations_sent.dta %%%%%%%%%%\n",
      "(800913, 3)\n",
      "%%%%%%%%%% 12sample_comments_made.dta %%%%%%%%%%\n",
      "(29258, 4)\n",
      "%%%%%%%%%% 12sample_reposts_made.dta %%%%%%%%%%\n",
      "(179329, 4)\n",
      "%%%%%%%%%% 12sample_favoritings_made.dta %%%%%%%%%%\n",
      "(527701, 4)\n",
      "%%%%%%%%%% 12sample_messages_sent.dta %%%%%%%%%%\n",
      "(11091, 3)\n",
      "%%%%%%%%%% 12sample_1st_deg_user_infos.dta %%%%%%%%%%\n",
      "(670746, 3)\n",
      "%%%%%%%%%% 12sample_user_infos.dta %%%%%%%%%%\n",
      "(35000, 3)\n",
      "%%%%%%%%%% 12sample_affiliations_received.dta %%%%%%%%%%\n",
      "(432503, 3)\n"
     ]
    }
   ],
   "source": [
    "#affiliations :follows\n",
    "#favoritings :likes\n",
    "\n",
    "#used in filtering:\n",
    "path_dir = r\"/Users/../Volumes/Raw/\"\n",
    "tracks = import_tracks_dta(path_dir, \"12sample_tracks.dta\");\n",
    "\n",
    "#these are the actions sent to \n",
    "follows_sent = import_dta(path_dir, \"12sample_affiliations_sent.dta\");\n",
    "comments_sent = import_dta(path_dir, \"12sample_comments_made.dta\");\n",
    "shares_sent = import_dta(path_dir, \"12sample_reposts_made.dta\");\n",
    "likes_sent = import_dta(path_dir, \"12sample_favoritings_made.dta\");\n",
    "messages_sent = import_dta(path_dir, \"12sample_messages_sent.dta\");\n",
    "\n",
    "#Used to track information on the 1st degree connections\n",
    "user_info_1st = import_dta(path_dir, \"12sample_1st_deg_user_infos.dta\");\n",
    "user_info_1st.columns = ['user_id', 'type', 'entered_platform'];\n",
    "user_info = import_dta(path_dir, \"12sample_user_infos.dta\");\n",
    "\n",
    "#Used to compute creator's success measure\n",
    "follows_received = import_dta(path_dir, \"12sample_affiliations_received.dta\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35300c65",
   "metadata": {},
   "source": [
    "Indegree and outdegree information.\n",
    "\n",
    "The function below import the outdegree dataset. Because the raw version of those dataset are too large to be processed in memory, we preprocessed them in a separate script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cca037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregates preprocessed outdegree of 1st degree users\n",
    "def import_outdegree(path='/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/'):\n",
    "    d = {}\n",
    "    for i in range(6):\n",
    "       d[str(i)] = pd.read_pickle(os.path.join(path,'{}.pkl'.format(i))) \n",
    "       d[str(i)]['created_at'] =  pd.to_datetime(d[str(i)]['created_at'])\n",
    "       d[str(i)]['created_at'] = pd.to_datetime(d[str(i)]['created_at']).dt.floor('d')\n",
    "       d[str(i)] = d[str(i)].groupby(['sender_id', 'created_at'], as_index = False).size() \n",
    "    \n",
    "    data_outdegree = pd.concat([d['0'], d['1'], d['2'], d['3'], d['4'], d['5']])\n",
    "    #data_outdegree.set_index('created_at', inplace = True)\n",
    "    return data_outdegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e03d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outdegree = import_outdegree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a2e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_outdegree = data_outdegree.groupby(['sender_id','created_at'], as_index = False).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb3d51",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a358956e",
   "metadata": {},
   "source": [
    "## Creator ids, successful and unsucessful creators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb7bc74",
   "metadata": {},
   "source": [
    "Next, we define three lists of ids: one with the ids from the content creators, according to the `users_info` table, one with the ids of successful creators and the last one with the ids of the unsuccessful ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77715356",
   "metadata": {},
   "source": [
    "Let's start with a list of the id of creators. We also create a dataset with containing information on creators only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd634fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (tracks.track_available == 1) & (tracks.public == 't')\n",
    "creator_ids = tracks[mask].user_id.unique()\n",
    "\n",
    "creators = tracks[(tracks.track_available == 1) & (tracks.public == 't')]\n",
    "\n",
    "#mask = user_info.type == 'creator'\n",
    "#creator_ids = user_info[mask].user_id.unique()\n",
    "\n",
    "#creators = user_info[user_info.type == 'creator']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b06476a",
   "metadata": {},
   "source": [
    "## Putting together a dataset with the promotional activities made by content creators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b8a09",
   "metadata": {},
   "source": [
    "The function `gen_actions_sent_df` creates a dataframe with all the promotional activities that content creators sent to users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_actions_sent_df(follows_sent, shares_sent, likes_sent, comments_sent, messages_sent, creator_ids = creator_ids):\n",
    "    '''\n",
    "    Creates dataframe containing the actions that content creators send to users.\n",
    "        Attributes:\n",
    "                    follows_sent:  dataframe with the follows sent by the 35k users.\n",
    "                    shares_sent:   dataframe with the shares sent by the 35k users.\n",
    "                    likes_sent:    dataframe with the likes sent by the 35k users.\n",
    "                    comments_sent: dataframe with the comments sent by the 35k users.\n",
    "                    messages_sent: dataframe with the messages sent by the 35k users.\n",
    "                    creator_ids:   list with content creator ids. If not none, is used to\n",
    "                                   filter out activities from non creators.\n",
    "    '''\n",
    "    \n",
    "    follows_sent['outbound_activity'] = 'follow'\n",
    "    follows_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'song_id' in shares_sent.columns:\n",
    "        shares_sent.drop(columns=[\"song_id\"])\n",
    "    shares_sent = shares_sent[['reposter_id', \"owner_id\", 'created_at']]\n",
    "    shares_sent['outbound_activity'] = 'share'\n",
    "    shares_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'track_id' in likes_sent.columns:\n",
    "        likes_sent.drop(columns=[\"track_id\"], inplace=True)\n",
    "    likes_sent['outbound_activity'] = 'like'\n",
    "    likes_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'track_id' in comments_sent.columns:\n",
    "        comments_sent.drop(columns=[\"track_id\"], inplace=True)\n",
    "    comments_sent['outbound_activity'] = 'comment'\n",
    "    comments_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    messages_sent[\"outbound_activity\"] = 'message'\n",
    "    messages_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "    df = pd.concat([follows_sent, shares_sent, likes_sent, comments_sent, messages_sent])\n",
    "\n",
    "\n",
    "    if type(creator_ids) == numpy.ndarray:\n",
    "        df = df[df['user_id'].isin(creator_ids)]\n",
    "        \n",
    "    df['week_yr'] = df.date_sent.dt.strftime('%Y-w%U')\n",
    "    df = df.loc[df['user_id'] != df['fan_id'],:]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_sent = gen_actions_sent_df(follows_sent, shares_sent, likes_sent, comments_sent,\n",
    "                                     messages_sent, creator_ids = None)\n",
    "actions_sent = actions_sent.loc[actions_sent.user_id.isin(creators.user_id.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6462039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_users_ids = actions_sent.groupby('user_id', as_index = False).size()\n",
    "mask = active_users_ids['size']>= activity_filter\n",
    "active_users_ids = active_users_ids[mask].user_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58e13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def successful_creators_followers(follows_received, base_date = datetime(2016, 5, 30, 0, 0), perc1 = None, perc2 = None, subset_creators = None):\n",
    "    '''Classifies content creators in successful or unsuccessfull\n",
    "        Arguments:\n",
    "                    follows_received: dataframe containing the follows received by content creators\n",
    "                    base date:        date, in datetime.datetime(YYYY, M, DD, H, M) format, in which the number \n",
    "                                      of followers per creator is calculated.\n",
    "                    perc1:            the threshold used to classify unsuccessful content creators. Creator having \n",
    "                                      total followers below the number dictated by this threshold, at the base date,\n",
    "                                      are classified as unsuccessful \n",
    "                    perc2:            the threshold used to classify successful content creators. Creator having \n",
    "                                      total followers above the number dictated by this threshold, at the base date,\n",
    "                                      are classified as successful\n",
    "                    subset_creators:  a pd.DataFrame containing the creators. If is it available, it will be used to \n",
    "                                      filter out non creators and to make sure creators with 0 followers are part of\n",
    "                                      the resulting dataset.\n",
    "        \n",
    "    '''\n",
    "    print(base_date)\n",
    "\n",
    "    if 'inbound_activity' not in follows_received.columns:\n",
    "        follows_received.columns = ['fan_id', 'user_id', 'date_sent']\n",
    "\n",
    "    mask = (follows_received['date_sent'] < base_date)\n",
    "\n",
    "    df = follows_received[mask].groupby('user_id', as_index=False).agg({'fan_id': pd.Series.nunique})\n",
    "    df.columns = ['user_id', 'followers']\n",
    "\n",
    "    \n",
    "    if type(subset_creators) == pd.DataFrame:\n",
    "        print('subsetting...')\n",
    "        df.set_index('user_id', inplace = True)\n",
    "        df = df.reindex(subset_creators.user_id.unique())\n",
    "        df.fillna(0, inplace = True)\n",
    "        df.reset_index(inplace = True)\n",
    "        df.columns = ['user_id', 'followers']\n",
    "        \n",
    "    mask = df.user_id.isin(active_users_ids)\n",
    "    df = df[mask]\n",
    "\n",
    "    low = np.quantile(df.followers, perc1)\n",
    "    high = np.quantile(df.followers, perc2)\n",
    "\n",
    "    print(\"High influencer boundary: {}\".format(high))\n",
    "    print(\"Low influencer boundary: {}\".format(low))\n",
    "\n",
    "    mask = (df[\"followers\"] <= low) | (df[\"followers\"] >= high)\n",
    "    \n",
    "    unsuccessful_creator_ids = df.loc[df[\"followers\"] <= low].user_id.unique()\n",
    "    successful_creator_ids = df.loc[df[\"followers\"] >= high].user_id.unique()\n",
    "\n",
    "    return unsuccessful_creator_ids, successful_creator_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee655c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsuccessful_ids, successful_ids = successful_creators_followers(follows_received, \n",
    "                                                        perc1 = low_success, perc2 = high_success, subset_creators = creators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc85a0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(unsuccessful_ids))\n",
    "print(len(successful_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d8980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "creators.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6f8c4",
   "metadata": {},
   "source": [
    "## Filter only actions that were sent to non-fans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a67b459",
   "metadata": {},
   "source": [
    "We merge the `actions_sent` dataset with a table containing the date each fan started following the creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b904f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_received.columns = ['fan_id', 'user_id', 'date_sent']\n",
    "followers = follows_received[[\"fan_id\", \"user_id\", \"date_sent\"]]\n",
    "followers.columns = [\"fan_id\", \"user_id\", \"follower_since\"]\n",
    "\n",
    "actions_sent = actions_sent.merge(followers, right_on = ['user_id', 'fan_id'],\n",
    "                                      left_on = ['user_id', 'fan_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973ebc19",
   "metadata": {},
   "source": [
    "Since we are interested in acquisition campaings, we need to produce a dataset that exclude actions targetting fans.\n",
    "We do that using filters based on the date of the action and the date that the user became a fan of the content creator. The resulting dataframe is named `actions_sent_non_fans`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dbf162",
   "metadata": {},
   "source": [
    "We then filter only actions that happened before the user follows the content creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c957f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (actions_sent.date_sent < actions_sent.follower_since) | (actions_sent.follower_since.isnull())\n",
    "actions_sent_non_fans =  actions_sent[mask]\n",
    "actions_sent_non_fans['week_yr_date'] = actions_sent_non_fans.week_yr.apply(lambda x: process_date(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d9b9e",
   "metadata": {},
   "source": [
    "## Outdegree level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a61f1",
   "metadata": {},
   "source": [
    "Originally, we only have outdegree information on users that follow at least one user. The function below inputs an outdegree of 0 to users that are following anyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1083a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGE DOCUMENTATION\n",
    "def outdegree_level(data, date, user_info = user_info_1st):\n",
    "    \n",
    "    '''\n",
    "    This function returns the membership table at date equals `date`. Every user that interacted with the 35k tracked \n",
    "    users and entered the platform before `date` is present in the table, even if it has indegree 0.\n",
    "    arguments:\n",
    "              data:           the indegree dataset.\n",
    "              user_info:      the dataset containing all the users that interacted with the 35k users tracked.\n",
    "    '''\n",
    "    \n",
    "    data = data[data.created_at.dt.floor('d')<=date]\n",
    "    data = data.groupby('sender_id').agg({'size':'sum'}).compute()\n",
    "    \n",
    "    #merge with user info to obtain users that are not followed by anyone at the current date\n",
    "    data = user_info_1st.merge(data, left_on = 'user_id', right_on = 'sender_id', how= 'outer')\n",
    "    data.loc[data['size'].isnull(), 'size'] = 0\n",
    "    data = data[['user_id', 'size', 'entered_platform']].set_index('user_id')\n",
    "    \n",
    "    #filter out users that didnt exist in the current date\n",
    "    mask = data['entered_platform'].dt.floor('d') <= date\n",
    "    data = data.loc[mask]\n",
    "    \n",
    "    mask = (data['size']>0)\n",
    "    data.loc[~mask, 'size'] = 0 \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a49e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dask is a python api with objects optimized for big data (user directed acyclic graphs). \n",
    "dask_outdegree = dd.from_pandas(data_outdegree, npartitions = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21950961",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_day =  max(actions_sent.date_sent.dt.floor('d').unique())\n",
    "user_outdegree = outdegree_level(dask_outdegree, last_day, user_info = user_info_1st)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b5931",
   "metadata": {},
   "source": [
    "Now we classify the creator in successful and unsuccessful, according to the threshold defined in the beggining of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d85729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_outdegree_level(oudegree_data, perc1 = None, perc2 = None):\n",
    "    '''Classifies content creators in successful or unsuccessfull\n",
    "        Arguments:\n",
    "                    oudegree_data:    dataframe containing the fans followers at \n",
    "                    perc1:            the threshold used to classify unsuccessful content creators. Creator having \n",
    "                                      total followers below the number dictated by this threshold, at the base date,\n",
    "                                      are classified as unsuccessful \n",
    "                    perc2:            the threshold used to classify successful content creators. Creator having \n",
    "                                      total followers above the number dictated by this threshold, at the base date,\n",
    "                                      are classified as successful\n",
    "    '''\n",
    "\n",
    "    df = oudegree_data.reset_index().iloc[:,:2]\n",
    "    df.columns = ['user_id', 'followers']\n",
    "\n",
    "    low = np.quantile(df.followers, perc1)\n",
    "    high = np.quantile(df.followers, perc2)\n",
    "\n",
    "    print(\"High outdegree boundary: {}\".format(high))\n",
    "    print(\"Low outdegree boundary: {}\".format(low))\n",
    "    \n",
    "    low_outdegree_ids = df.loc[df[\"followers\"] <= low].user_id.unique()\n",
    "    high_outdegree_ids = df.loc[df[\"followers\"] >= high].user_id.unique()\n",
    "    \n",
    "    \n",
    "    df['outdegree_level'] = df.user_id.apply(\n",
    "        lambda x: 'high' if x in high_outdegree_ids else ('low' if x in low_outdegree_ids else None))\n",
    "\n",
    "    \n",
    "    return df, low_outdegree_ids, high_outdegree_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b4271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_outdegree_df, low_outdegree_ids, high_outdegree_ids = user_outdegree_level(user_outdegree,\n",
    "                perc1 = low_user_outdegree, perc2 = high_user_outdegree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc7f983",
   "metadata": {},
   "source": [
    "In the cell below, we create a list with unique ids from users that appear in the oudegree level table. This will later be uses to construct a flow-chart indicating how we lose data based on filters and operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406e4e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "receiver_ids = user_outdegree.index.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1faaf",
   "metadata": {},
   "source": [
    "## Non-follow Actions level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4db5e11",
   "metadata": {},
   "source": [
    "The activity level is defined as the number of actions performed by users. It is important to notice that we only observe actions targeting the 35k users that joined in march 2012. We consider this measure a proxy for the real activity level.\n",
    "\n",
    "Let's begin by creating a dataset with all action received by those 35k users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82504b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_received_35k = import_dta(path_dir, \"12sample_comments_received.dta\");\n",
    "shares_received_35k = import_dta(path_dir, \"12sample_reposts_received.dta\");\n",
    "likes_received_35k = import_dta(path_dir, \"12sample_favoritings_received.dta\");\n",
    "messages_received_35k = import_dta(path_dir, \"12sample_messages_received.dta\");\n",
    "\n",
    "if 'song_id' in shares_received_35k:\n",
    "        shares_received_35k.drop(columns=[\"song_id\"])\n",
    "shares_received_35k = shares_received_35k[['reposter_id', \"owner_id\", 'created_at']]\n",
    "shares_received_35k['outbound_activity'] = 'share'\n",
    "shares_received_35k.columns = ['fan_id', 'user_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "if 'track_id' in likes_received_35k:\n",
    "        likes_received_35k = likes_received_35k.drop(columns=[\"track_id\"])\n",
    "likes_received_35k['outbound_activity'] = 'like'\n",
    "likes_received_35k.columns = ['fan_id', 'user_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "if 'track_id' in comments_received_35k:\n",
    "        comments_received_35k = comments_received_35k.drop(columns=[\"track_id\"])\n",
    "comments_received_35k['outbound_activity'] = 'comment'\n",
    "comments_received_35k.columns = ['fan_id', 'user_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "messages_received_35k[\"outbound_activity\"] = 'message'\n",
    "messages_received_35k.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "user_activity_data_35k = pd.concat([shares_received_35k, likes_received_35k, comments_received_35k, messages_received_35k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec0ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir_2 = r'/Users/../Volumes/Alter_outbound_activities/'\n",
    "\n",
    "comments_received_c = import_dta(path_dir_2, \"12sample_1st_deg_comments_made.dta\");\n",
    "shares_received_c = import_dta(path_dir_2, \"12sample_1st_deg_reposts_made.dta\");\n",
    "likes_received_c = import_dta(path_dir_2, \"12sample_1st_deg_favoritings_made.dta\");\n",
    "messages_received_c = import_dta(path_dir_2, \"12sample_1st_deg_messages_sent.dta\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec99f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'song_id' in shares_received_c:\n",
    "        shares_received_c.drop(columns=[\"song_id\"])\n",
    "shares_received_c = shares_received_c[['reposter_id', \"owner_id\", 'created_at']]\n",
    "shares_received_c['inbound_activity'] = 'share'\n",
    "shares_received_c.columns = ['fan_id', 'user_id', 'date_sent', 'inbound_activity']\n",
    "\n",
    "if 'track_id' in likes_received_c:\n",
    "        likes_received_c = likes_received_c.drop(columns=[\"track_id\"])\n",
    "likes_received_c['inbound_activity'] = 'like'\n",
    "likes_received_c.columns = ['fan_id', 'user_id', 'date_sent', 'inbound_activity']\n",
    "\n",
    "if 'track_id' in comments_received_c:\n",
    "        comments_received_c = comments_received_c.drop(columns=[\"track_id\"])\n",
    "comments_received_c['inbound_activity'] = 'comment'\n",
    "comments_received_c.columns_c = ['fan_id', 'user_id', 'date_sent', 'inbound_activity']\n",
    "\n",
    "messages_received_c[\"outbound_activity\"] = 'message'\n",
    "messages_received_c.columns = ['user_id', 'fan_id', 'date_sent', 'inbound_activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ce54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity_data_c = pd.concat([shares_received_c, likes_received_c, comments_received_c, messages_received_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_activity_level(user_activity_data, receiver_ids, perc1 = None, perc2 = None):\n",
    "    '''Classifies users based on the amount of non-follow activities\n",
    "        Arguments:\n",
    "                    user_activity_data:   dataframe containing the user activities \n",
    "                    base date:             date, in datetime.datetime(YYYY, M, DD, H, M) format, in which the number \n",
    "                                           of followers per creator is calculated.\n",
    "                    perc1:                 the threshold used to classify unsuccessful content creators. Creator having \n",
    "                                           total followers below the number dictated by this threshold, at the base date,\n",
    "                                           are classified as unsuccessful \n",
    "                    perc2:                 the threshold used to classify successful content creators. Creator having \n",
    "                                           total followers above the number dictated by this threshold, at the base date,\n",
    "                                           are classified as successful\n",
    "    '''\n",
    "\n",
    "    df = user_activity_data.groupby('fan_id', as_index = True).size()\n",
    "    df = df.reindex(receiver_ids)\n",
    "    print(df.shape)\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['user_id', 'activities_performed']\n",
    "    \n",
    "    df.loc[df.activities_performed.isna(), 'activities_performed'] = 0\n",
    "    #classification should happen after this\n",
    "\n",
    "    low = np.quantile(df.activities_performed, perc1)\n",
    "    high = np.quantile(df.activities_performed, perc2)\n",
    "\n",
    "    print(\"High activity boundary: {}\".format(high))\n",
    "    print(\"Low activity boundary: {}\".format(low))\n",
    "    \n",
    "    low_activity_ids = df.loc[df[\"activities_performed\"] <= low].user_id.unique()\n",
    "    high_activity_ids = df.loc[df[\"activities_performed\"] > high].user_id.unique()\n",
    "    \n",
    "    df['activity_level'] = df.user_id.apply(\n",
    "    lambda x: 'high' if x in high_activity_ids else ('low' if x in low_activity_ids else None))\n",
    "\n",
    "    return df, low_activity_ids, high_activity_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3367a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_level, low_activity_ids, high_activity_ids = user_activity_level(user_activity_data_c, receiver_ids, \n",
    "                perc1 = low_user_activity, perc2 = high_user_activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a392a41",
   "metadata": {},
   "source": [
    "Once more we create an object containing the unique ids of users in the resulting dataset. This will be used in a flow-chart, as explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972bf9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_ids = np.append(low_activity_ids, high_activity_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf24ca28",
   "metadata": {},
   "source": [
    "# Priori response probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004cd597",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data = user_outdegree_df.merge(activity_level, left_on = 'user_id', right_on = 'user_id', how = 'inner')\n",
    "table_data.groupby(['outdegree_level', 'activity_level']).size()\n",
    "table_data['Type'] = table_data.apply(lambda x: \n",
    "    'f_a' if (x.outdegree_level == 'low') & (x.activity_level == 'high')\n",
    "     else ('Hermit' if (x.outdegree_level == 'low') & (x.activity_level == 'low')\n",
    "     else ('Observer' if (x.outdegree_level == 'high') & (x.activity_level == 'low')\n",
    "     else ('w_a' if (x.outdegree_level == 'high') & (x.activity_level == 'high')\n",
    "     else 'other'))), axis=1)\n",
    "\n",
    "hermit_ids = table_data.loc[table_data.Type =='Hermit'].user_id.unique()\n",
    "w_a_ids = table_data.loc[table_data.Type =='w_a'].user_id.unique()\n",
    "f_a_ids = table_data.loc[table_data.Type =='f_a'].user_id.unique()\n",
    "observer_ids = table_data.loc[table_data.Type =='Observer'].user_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb38cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_sent['user_type'] = actions_sent.fan_id.apply(lambda x: 'f_a' if x in f_a_ids else \n",
    "                          ('Hermit' if x in hermit_ids else\n",
    "                          ('Observer' if x in observer_ids else\n",
    "                          ('w_a' if x in w_a_ids else 'other'))))\n",
    "\n",
    "## classify content creators\n",
    "actions_sent['creator_type'] = actions_sent.user_id.apply(\n",
    "                               lambda x: 'successful' if x in successful_ids else \n",
    "                               ('unsuccessful' if x in unsuccessful_ids else 'other'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a8f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_sent_non_fans['user_type'] = actions_sent_non_fans.fan_id.apply(lambda x: 'f_a' if x in f_a_ids else \n",
    "                          ('Hermit' if x in hermit_ids else\n",
    "                          ('Observer' if x in observer_ids else\n",
    "                          ('w_a' if x in w_a_ids else 'other'))))\n",
    "\n",
    "## classify content creators\n",
    "actions_sent_non_fans['creator_type'] = actions_sent_non_fans.user_id.apply(\n",
    "                                            lambda x: 'successful' if x in successful_ids else \n",
    "                                            ('unsuccessful' if x in unsuccessful_ids else 'other'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba561a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Target Creation\n",
    "delta = timedelta(days = days_delta)\n",
    "mask = (actions_sent_non_fans['follower_since'] <= (actions_sent_non_fans['date_sent'] + delta))\n",
    "\n",
    "response_df = actions_sent_non_fans.copy()\n",
    "response_df.loc[mask, 'reward'] = 1\n",
    "mask = response_df['reward'].isnull()\n",
    "response_df.loc[mask, 'reward'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51ac7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts = response_df.groupby(['creator_type', 'user_type'], as_index = False).size()\n",
    "rewards = response_df.groupby(['creator_type', 'user_type'], as_index = False).agg({'reward' : 'sum'})\n",
    "\n",
    "priori_prob_df = rewards.merge(attempts)\n",
    "priori_prob_df['P_resp_prob'] = priori_prob_df['reward']/priori_prob_df['size']\n",
    "priori_prob_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0402ce5b",
   "metadata": {},
   "source": [
    "# Indirect Return from Friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a091f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the files below contain the followers for targets that:\n",
    "#1. shared creator content, \n",
    "#2. performed any action towards a creator, or\n",
    "#3. followed a creator\n",
    "#it was necessary do split the data because it was too large to in memory.\n",
    "#on a future interaction it can be made better\n",
    "import pickle as pkl\n",
    "share_follower_lists = pd.read_pickle('/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/Data/alter_follower_lists.pkl')\n",
    "action_follower_lists = pd.read_pickle('/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/Data/alter_follower_lists_2.pkl')\n",
    "follow_follower_lists = pd.read_pickle('/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/Data/alter_follower_lists_3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c22ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#different approach, probably also good\n",
    "def compute_indirect_return(df, follower_list):    \n",
    "    follower_lists = follower_list\n",
    "    data = df\n",
    "    data = data.loc[data.user_id.isin(creators.user_id)]\n",
    "\n",
    "    data = data.loc[data.fan_id.isin(follower_lists.index.unique())]\n",
    "    data['expec_followers'] = np.nan\n",
    "    data.sort_values(['user_id', 'fan_id'], inplace = True)\n",
    "    \n",
    "    df.date_sent = df.date_sent.dt.normalize()\n",
    "\n",
    "    for user_id in tqdm(data.user_id.unique()):\n",
    "        df_j = df.loc[df.user_id == user_id]\n",
    "        for fan_id in data.loc[data.user_id == user_id].fan_id.unique():\n",
    "            fan_followers = follower_lists.loc[follower_lists.index == fan_id].values[0]\n",
    "            data.loc[(data.user_id == user_id)&\n",
    "                                      (data.fan_id == fan_id),'expec_followers'] =\\\n",
    "            data.loc[(data.user_id == user_id)&\n",
    "                                      (data.fan_id == fan_id)].date_sent.apply(\n",
    "                lambda x : \n",
    "                np.sum(np.in1d(\n",
    "                               df_j.loc[(x <= df_j.date_sent) & \n",
    "                                                      (df_j.date_sent<= x + \n",
    "                                                       timedelta(days=days_delta))\n",
    "                                                     ].values,\n",
    "                    fan_followers)\n",
    "            ))                   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675abe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(df):\n",
    "    df['user_type'] = df.fan_id.apply(lambda x: 'f_a' if x in f_a_ids else \n",
    "                              ('Hermit' if x in hermit_ids else\n",
    "                              ('Observer' if x in observer_ids else\n",
    "                              ('w_a' if x in w_a_ids else 'other'))))\n",
    "\n",
    "    ## classify content creators\n",
    "\n",
    "    df['creator_type'] = df.user_id.apply(lambda x: 'successful' if x in successful_ids else \n",
    "                                                ('unsuccessful' if x in unsuccessful_ids else 'other'))\n",
    "    attempts = df.groupby(['creator_type', 'user_type'], as_index = False).size()\n",
    "    desc = df.groupby(['creator_type', 'user_type'], as_index = False).agg(expected_followers=('expec_followers', 'mean'),\n",
    "                                   std_expected_followers=('expec_followers', 'std'),\n",
    "                                   max_followers=('expec_followers', 'max'))\n",
    "\n",
    "    return attempts.merge(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398a15a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "expec_followers_given_follow_df = compute_indirect_return(follows_received, follow_follower_lists)\n",
    "indirect_return_follows = compute_stats(expec_followers_given_follow_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad741e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "indirect_return_follows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = user_activity_data_35k.outbound_activity == 'share'\n",
    "\n",
    "expec_followers_given_share_df = compute_indirect_return(user_activity_data_35k.loc[mask], share_follower_lists)\n",
    "indirect_return_share = compute_stats(expec_followers_given_share_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dbf2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "indirect_return_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7ed48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = user_activity_data_35k.outbound_activity == 'like'\n",
    "\n",
    "expec_followers_given_like_df = compute_indirect_return(user_activity_data_35k.loc[mask], action_follower_lists)\n",
    "indirect_return_like = compute_stats(expec_followers_given_like_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "indirect_return_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5ca2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = user_activity_data_35k.outbound_activity == 'comment'\n",
    "\n",
    "expec_followers_given_comment_df = compute_indirect_return(user_activity_data_35k.loc[mask], action_follower_lists)\n",
    "indirect_return_comment = compute_stats(expec_followers_given_comment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fa7edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indirect_return_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba673a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_received_alters_succ = pd.read_pickle('/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/Data/follows_received_by_alters_of_successful_creators.pkl')\n",
    "\n",
    "def get_partitions(start_date, end_date, interval = 7):\n",
    "    partitions = []\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date < end_date:\n",
    "        partitions.append(current_date)\n",
    "        current_date += timedelta(days=interval)\n",
    "\n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc94d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_j previo\n",
    "def compute_indirect_returns_week(df_j, week_start, fan_followers):\n",
    "        array1 = df_j.loc[(week_start <= df_j.date_sent) & (df_j.date_sent <= week_start \n",
    "                    + timedelta(days=7))]\n",
    "        if array1.shape[0] != 0:\n",
    "            return np.sum(np.in1d(array1.fan_id.values, fan_followers))\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9262f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_received['user_type'] = follows_received.fan_id.apply(lambda x: 'f_a' if x in f_a_ids else \n",
    "                          ('Hermit' if x in hermit_ids else\n",
    "                          ('Observer' if x in observer_ids else\n",
    "                          ('w_a' if x in w_a_ids else 'other'))))\n",
    "\n",
    "## classify content creators\n",
    "follows_received['creator_type'] = follows_received.user_id.apply(\n",
    "                               lambda x: 'successful' if x in successful_ids else \n",
    "                               ('unsuccessful' if x in unsuccessful_ids else 'other'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b98767",
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_received_filtered = follows_received.loc[(follows_received.creator_type == 'successful')\n",
    "                                                 &(follows_received.user_type != 'other')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f756d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data should be \n",
    "def followers_up_to(user_id, date, data):\n",
    "    data = data.loc[(data.contact_id==user_id)&(data.created_at <= date)].groupby('contact_id').fan_id.apply(np.array)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_indirect_return_v2(data, follower_lists, follows_received): \n",
    "    \n",
    "#     indirect_return_df = data[['user_id', 'fan_id']].drop_duplicates(subset=['user_id', 'fan_id'])\n",
    "#     follows_received['date_sent'] = follows_received['date_sent'].dt.normalize()\n",
    "    \n",
    "#     follows_received = follows_received.loc[follows_received.user_id.isin(successful_ids)]\n",
    "#     follows_received = follows_received.loc[follows_received.fan_id.isin(follower_lists.index.unique())]\n",
    "#     data = data.loc[data.user_id.isin(creators.user_id)]\n",
    "#     #data = data.loc[data.fan_id.isin(follower_lists.index.unique())]\n",
    "#     for user_id in tqdm(follows_received.user_id.unique()):\n",
    "#         indirect_return_list = []\n",
    "#         df_j = data.loc[data.user_id == user_id]\n",
    "        \n",
    "#         for fan_id in follows_received.loc[follows_received.user_id == user_id].fan_id.unique():\n",
    "#             fan_followers = follower_lists.loc[follower_lists.index == fan_id].values[0]\n",
    "            \n",
    "#             start_date = follows_received.loc[(follows_received.user_id == user_id)&\n",
    "#                                               (follows_received.fan_id == fan_id)].date_sent.iloc[0]\n",
    "#             end_date = datetime(2015, 5, 30)\n",
    "            \n",
    "#             for week_start in get_partitions(start_date, end_date):\n",
    "#                 indirect_return_list.append(\n",
    "#                     compute_indirect_returns_week(df_j, week_start, fan_followers)\n",
    "#                 )\n",
    "                \n",
    "#             indirect_return_df.loc[(indirect_return_df['user_id'] == user_id)\n",
    "#                                    & (indirect_return_df['fan_id'] == fan_id), 'Indirect_return'] =\\\n",
    "#             sum(indirect_return_list)\n",
    "                                 \n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_indirect_return_v2(data, follower_lists, follows_received): \n",
    "    \n",
    "    indirect_return_df = data[['user_id', 'fan_id']].drop_duplicates(subset=['user_id', 'fan_id'])\n",
    "    follows_received['date_sent'] = follows_received['date_sent'].dt.normalize()\n",
    "    end_date = datetime(2015, 5, 30)\n",
    "    \n",
    "    follows_received = follows_received.loc[follows_received.user_id.isin(successful_ids)]\n",
    "    follows_received = follows_received.loc[follows_received.fan_id.isin(follower_lists.index.unique())]\n",
    "    data = data.loc[data.user_id.isin(creators.user_id)]\n",
    "    #data = data.loc[data.fan_id.isin(follower_lists.index.unique())]\n",
    "    for user_id in tqdm(follows_received.user_id.unique()):\n",
    "        indirect_return_list = []\n",
    "        df_j = data.loc[data.user_id == user_id]\n",
    "        \n",
    "        for fan_id in tqdm(follows_received.loc[follows_received.user_id == user_id].fan_id.unique()):\n",
    "            \n",
    "            start_date = follows_received.loc[(follows_received.user_id == user_id)&\n",
    "                                              (follows_received.fan_id == fan_id)].date_sent.iloc[0]\n",
    "            \n",
    "            for week_start in get_partitions(start_date, end_date):\n",
    "                #print(fan_id)\n",
    "                #print(week_start)\n",
    "                try:\n",
    "                    fan_followers = followers_up_to(fan_id, week_start\n",
    "                            ,follows_received_alters_succ).values[0]\n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "                indirect_return_list.append(\n",
    "                    compute_indirect_returns_week(df_j, week_start, fan_followers)\n",
    "                )\n",
    "                \n",
    "            indirect_return_df.loc[(indirect_return_df['user_id'] == user_id)\n",
    "                                   & (indirect_return_df['fan_id'] == fan_id), 'Indirect_return'] =\\\n",
    "            sum(indirect_return_list)\n",
    "                                 \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d5c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indirect_return_follow_df = compute_indirect_return_v2(follows_received, follow_follower_lists, follows_received_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14601670",
   "metadata": {},
   "outputs": [],
   "source": [
    "indirect_return_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!!!!! drop fan_id == user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9971e571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f931f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72caab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def compute_indirect_return_v2(data, follower_lists, follows_received):\n",
    "\n",
    "    indirect_return_df = data[['user_id', 'fan_id']].drop_duplicates(subset=['user_id', 'fan_id'])\n",
    "    follows_received['date_sent'] = follows_received['date_sent'].dt.normalize()\n",
    "\n",
    "    follows_received = follows_received.loc[follows_received.user_id.isin(successful_ids)]\n",
    "    follows_received = follows_received.loc[follows_received.fan_id.isin(follower_lists.index.unique())]\n",
    "    data = data.loc[data.user_id.isin(creators.user_id)]\n",
    "    # data = data.loc[data.fan_id.isin(follower_lists.index.unique())]\n",
    "\n",
    "    def process_user(user_id):\n",
    "        indirect_return_list = []\n",
    "        df_j = data.loc[data.user_id == user_id]\n",
    "\n",
    "        for fan_id in tqdm(follows_received.loc[follows_received.user_id == user_id].fan_id.unique()):\n",
    "            start_date = follows_received.loc[(follows_received.user_id == user_id) &\n",
    "                                              (follows_received.fan_id == fan_id)].date_sent.iloc[0]\n",
    "            end_date = datetime(2015, 5, 30)\n",
    "\n",
    "            for week_start in get_partitions(start_date, end_date):\n",
    "                try:\n",
    "                    fan_followers = followers_up_to(fan_id, week_start\n",
    "                            ,follows_received_alters_succ).values[0]\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    indirect_return_list.append(\n",
    "                        compute_indirect_returns_week(df_j, week_start, fan_followers)\n",
    "                    )\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            \n",
    "            try:\n",
    "                indirect_return_df.loc[(indirect_return_df['user_id'] == user_id) &\n",
    "                                   (indirect_return_df['fan_id'] == fan_id), 'Indirect_return'] = \\\n",
    "                sum(indirect_return_list)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    Parallel(n_jobs=7)(delayed(process_user)(user_id) for user_id in tqdm(follows_received.user_id.unique()))\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be63eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def compute_indirect_return_v1(data, follower_lists, follows_received, indirect_return_df):\n",
    "\n",
    "    follows_received['date_sent'] = follows_received['date_sent'].dt.normalize()\n",
    "\n",
    "    follows_received = follows_received.loc[follows_received.user_id.isin(successful_ids)]\n",
    "    follows_received = follows_received.loc[follows_received.fan_id.isin(follower_lists.index.unique())]\n",
    "    data = data.loc[data.user_id.isin(creators.user_id)]\n",
    "    # data = data.loc[data.fan_id.isin(follower_lists.index.unique())]\n",
    "\n",
    "    def process_user(user_id):\n",
    "        indirect_return_list = []\n",
    "        df_j = data.loc[data.user_id == user_id]\n",
    "\n",
    "        for fan_id in tqdm(follows_received.loc[follows_received.user_id == user_id].fan_id.unique()):\n",
    "            start_date = follows_received.loc[(follows_received.user_id == user_id) &\n",
    "                                              (follows_received.fan_id == fan_id)].date_sent.iloc[0]\n",
    "            end_date = datetime(2015, 5, 30)\n",
    "            fan_followers = follower_lists.loc[follower_lists.index == fan_id].values[0]\n",
    "        \n",
    "            for week_start in get_partitions(start_date, end_date):\n",
    "                \n",
    "                indirect_return_list.append(\n",
    "                        compute_indirect_returns_week(df_j, week_start, fan_followers)\n",
    "                    )\n",
    "\n",
    "            indirect_return_df.loc[(indirect_return_df['user_id'] == user_id) &\n",
    "                                   (indirect_return_df['fan_id'] == fan_id), 'Indirect_return'] = \\\n",
    "            sum(indirect_return_list)\n",
    "\n",
    "    Parallel(n_jobs=5)(delayed(process_user)(user_id) for user_id in tqdm(follows_received.user_id.unique()))\n",
    "\n",
    "    #return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b55f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_indirect_return_v3(data, follower_lists, follows_received_df, indirect_return_df): \n",
    "    \n",
    "    follows_received_df['date_sent'] = follows_received_df['date_sent'].dt.normalize()\n",
    "    data = data.loc[data.user_id != data.fan_id]\n",
    "    \n",
    "    follows_received_df = follows_received_df.loc[follows_received_df.user_id.isin(successful_ids)]\n",
    "    follows_received_df = follows_received_df.loc[follows_received_df.fan_id.isin(follower_lists.index.unique())]\n",
    "    data = data.loc[data.user_id.isin(creators.user_id)]\n",
    "    #data = data.loc[data.fan_id.isin(follower_lists.index.unique())]\n",
    "    for user_id in tqdm(follows_received_df.user_id.unique()):\n",
    "        df_j = data.loc[data.user_id == user_id]\n",
    "        \n",
    "        for fan_id in tqdm(follows_received_df.loc[follows_received_df.user_id == user_id].fan_id.unique()):\n",
    "            \n",
    "            indirect_return_list = []\n",
    "            \n",
    "            fan_followers = follower_lists.loc[follower_lists.index == fan_id].values[0]\n",
    "            \n",
    "            start_date = follows_received_df.loc[(follows_received_df.user_id == user_id)&\n",
    "                                              (follows_received_df.fan_id == fan_id)].date_sent.iloc[0]\n",
    "            end_date = datetime(2015, 5, 30)\n",
    "            \n",
    "            for week_start in get_partitions(start_date, end_date):\n",
    "                indirect_return_list.append(\n",
    "                    compute_indirect_returns_week(df_j, week_start, fan_followers)\n",
    "                )\n",
    "\n",
    "                \n",
    "            indirect_return_df.loc[(indirect_return_df['user_id'] == user_id)\n",
    "                                   & (indirect_return_df['fan_id'] == fan_id), 'Indirect_return'] =\\\n",
    "            sum(indirect_return_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23564ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "indirect_return_df = follows_received.loc[(follows_received.user_id.isin(successful_ids))&\n",
    "                                          (follows_received.fan_id.isin(follow_follower_lists.index.unique()))\n",
    "                                          ,['user_id', 'fan_id']].drop_duplicates(subset=['user_id', 'fan_id'])\n",
    "\n",
    "compute_indirect_return_v3(follows_received, follow_follower_lists, follows_received_filtered, indirect_return_df)\n",
    "\n",
    "indirect_return_df\n",
    "\n",
    "indirect_return_df['user_type'] = indirect_return_df.fan_id.apply(lambda x: 'f_a' if x in f_a_ids else \n",
    "                          ('Hermit' if x in hermit_ids else\n",
    "                          ('Observer' if x in observer_ids else\n",
    "                          ('w_a' if x in w_a_ids else 'other'))))\n",
    "\n",
    "## classify content creators\n",
    "indirect_return_df['creator_type'] = indirect_return_df.user_id.apply(\n",
    "                               lambda x: 'successful' if x in successful_ids else \n",
    "                               ('unsuccessful' if x in unsuccessful_ids else 'other'))\n",
    "\n",
    "indirect_return_df.dropna(inplace = True)\n",
    "\n",
    "indirect_return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indirect_return_df.groupby('user_type', as_index = False).agg({'Indirect_return': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b732af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = user_activity_data_35k.outbound_activity == 'share'\n",
    "df = user_activity_data_35k.loc[mask]\n",
    "\n",
    "indirect_return_share_df = df.loc[(df.user_id.isin(successful_ids))&\n",
    "                                          (df.fan_id.isin(share_follower_lists.index.unique()))\n",
    "                                          ,['user_id', 'fan_id']].drop_duplicates(subset=['user_id', 'fan_id'])\n",
    "\n",
    "compute_indirect_return_v3(df, share_follower_lists, follows_received_filtered, indirect_return_share_df)\n",
    "\n",
    "indirect_return_share_df['user_type'] = indirect_return_share_df.fan_id.apply(lambda x: 'f_a' if x in f_a_ids else \n",
    "                          ('Hermit' if x in hermit_ids else\n",
    "                          ('Observer' if x in observer_ids else\n",
    "                          ('w_a' if x in w_a_ids else 'other'))))\n",
    "\n",
    "## classify content creators\n",
    "indirect_return_share_df['creator_type'] = indirect_return_share_df.user_id.apply(\n",
    "                               lambda x: 'successful' if x in successful_ids else \n",
    "                               ('unsuccessful' if x in unsuccessful_ids else 'other'))\n",
    "\n",
    "indirect_return_share_df.dropna(inplace = True)\n",
    "\n",
    "indirect_return_share_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d2467",
   "metadata": {},
   "outputs": [],
   "source": [
    "indirect_return_share_df.groupby('user_type', as_index = False).agg({'Indirect_return': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15206d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = user_activity_data_35k.outbound_activity == 'like'\n",
    "df = user_activity_data_35k.loc[mask]\n",
    "\n",
    "indirect_return_like_df = df.loc[(df.user_id.isin(successful_ids))&\n",
    "                                          (df.fan_id.isin(action_follower_lists.index.unique()))\n",
    "                                          ,['user_id', 'fan_id']].drop_duplicates(subset=['user_id', 'fan_id'])\n",
    "\n",
    "compute_indirect_return_v3(df, action_follower_lists, follows_received_filtered, indirect_return_like_df)\n",
    "\n",
    "indirect_return_like_df['user_type'] = indirect_return_like_df.fan_id.apply(lambda x: 'f_a' if x in f_a_ids else \n",
    "                          ('Hermit' if x in hermit_ids else\n",
    "                          ('Observer' if x in observer_ids else\n",
    "                          ('w_a' if x in w_a_ids else 'other'))))\n",
    "\n",
    "## classify content creators\n",
    "indirect_return_like_df['creator_type'] = indirect_return_like_df.user_id.apply(\n",
    "                               lambda x: 'successful' if x in successful_ids else \n",
    "                               ('unsuccessful' if x in unsuccessful_ids else 'other'))\n",
    "\n",
    "indirect_return_like_df.dropna(inplace = True)\n",
    "\n",
    "indirect_return_like_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309bb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indirect_return_like_df.groupby('user_type', as_index = False).agg({'Indirect_return': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be46042",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = user_activity_data_35k.outbound_activity == 'comment'\n",
    "df = user_activity_data_35k.loc[mask]\n",
    "df = df.loc[df.user_id != df.fan_id]\n",
    "\n",
    "indirect_return_comment_df = df.loc[(df.user_id.isin(successful_ids))&\n",
    "                                          (df.fan_id.isin(action_follower_lists.index.unique()))\n",
    "                                          ,['user_id', 'fan_id']].drop_duplicates(subset=['user_id', 'fan_id'])\n",
    "\n",
    "compute_indirect_return_v3(df, action_follower_lists, follows_received_filtered, indirect_return_comment_df)\n",
    "\n",
    "indirect_return_comment_df['user_type'] = indirect_return_comment_df.fan_id.apply(lambda x: 'f_a' if x in f_a_ids else \n",
    "                          ('Hermit' if x in hermit_ids else\n",
    "                          ('Observer' if x in observer_ids else\n",
    "                          ('w_a' if x in w_a_ids else 'other'))))\n",
    "\n",
    "## classify content creators\n",
    "indirect_return_comment_df['creator_type'] = indirect_return_comment_df.user_id.apply(\n",
    "                               lambda x: 'successful' if x in successful_ids else \n",
    "                               ('unsuccessful' if x in unsuccessful_ids else 'other'))\n",
    "\n",
    "indirect_return_comment_df.dropna(inplace = True)\n",
    "\n",
    "indirect_return_comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b91cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "indirect_return_comment_df.groupby('user_type', as_index = False).agg({'Indirect_return': 'mean', 'median', 'std'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e85f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "compute_indirect_return_v3(follows_received, follow_follower_lists, follows_received_filtered, indirect_return_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a065201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = follows_received\n",
    "follows_received_df = follows_received\n",
    "follower_lists = follow_follower_lists\n",
    "\n",
    "follows_received_df['date_sent'] = follows_received_df['date_sent'].dt.normalize()\n",
    "    \n",
    "follows_received_df = follows_received_df.loc[follows_received_df.user_id.isin(successful_ids)]\n",
    "follows_received_df = follows_received_df.loc[follows_received_df.fan_id.isin(follower_lists.index.unique())]\n",
    "data = data.loc[data.user_id.isin(creators.user_id)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846bccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_received_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485dabd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 38393304\n",
    "\n",
    "df_j = data.loc[data.user_id == user_id]\n",
    "\n",
    "for fan_id in follows_received_df.loc[follows_received_df.user_id == user_id].fan_id.unique():\n",
    "\n",
    "    indirect_return_list = []\n",
    "\n",
    "    fan_followers = follower_lists.loc[follower_lists.index == fan_id].values[0]\n",
    "\n",
    "    start_date = follows_received_df.loc[(follows_received_df.user_id == user_id)&\n",
    "                                      (follows_received_df.fan_id == fan_id)].date_sent.iloc[0]\n",
    "    end_date = datetime(2015, 5, 30)\n",
    "\n",
    "    for week_start in get_partitions(start_date, end_date):\n",
    "        indirect_return_list.append(\n",
    "            compute_indirect_returns_week(df_j, week_start, fan_followers)\n",
    "        )\n",
    "\n",
    "\n",
    "    indirect_return_df.loc[(indirect_return_df['user_id'] == user_id)\n",
    "                           & (indirect_return_df['fan_id'] == fan_id), 'Indirect_return'] =\\\n",
    "    sum(indirect_return_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ec7ebc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "indirect_return_list = []\n",
    "user_id = 38027041\n",
    "\n",
    "fan_id = 1540436\n",
    "df_j = data.loc[data.user_id == user_id]\n",
    "fan_followers = follower_lists.loc[follower_lists.index == fan_id].values[0]\n",
    "\n",
    "start_date = follows_received_df.loc[(follows_received_df.user_id == user_id)&\n",
    "                                      (follows_received_df.fan_id == fan_id)].date_sent.iloc[0]\n",
    "end_date = datetime(2015, 6, 30)\n",
    "\n",
    "for week_start in get_partitions(start_date, end_date):\n",
    "    \n",
    "    print(week_start)\n",
    "    print(compute_indirect_returns_week(df_j, week_start, fan_followers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06190552",
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_received_df.loc[(follows_received_df.user_id == user_id)&\n",
    "                                      (follows_received_df.fan_id == fan_id)].date_sent.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4157d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_j.loc[(datetime(2013, 5, 30) <= df_j.date_sent) & (datetime(2013, 5, 30) <= week_start \n",
    "                    + timedelta(days=7))].fan_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e064a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime(2013, 4, 27)\n",
    "\n",
    "a = df_j.loc[(date <= df_j.date_sent) & (date <= week_start \n",
    "                    + timedelta(days=7))].fan_id.values\n",
    "a[np.in1d(a,fan_followers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966e0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime(2013, 3, 2)\n",
    "\n",
    "a = df_j.loc[(date <= df_j.date_sent) & (date <= week_start \n",
    "                    + timedelta(days=7))].fan_id.values\n",
    "a[np.in1d(a,fan_followers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b540f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime(2013, 3, 9)\n",
    "\n",
    "a = df_j.loc[(date <= df_j.date_sent) & (date <= week_start \n",
    "                    + timedelta(days=7))].fan_id.values\n",
    "a[np.in1d(a,fan_followers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime(2015, 3, 20)\n",
    "\n",
    "a = df_j.loc[(date <= df_j.date_sent) & (date <= week_start \n",
    "                    + timedelta(days=7))].fan_id.values\n",
    "a[np.in1d(a,fan_followers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00acd55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_received.loc[(follows_received.user_id == 37918716)&(follows_received.fan_id == 2023723)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f31ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
