{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7de64a06",
   "metadata": {},
   "source": [
    "**This notebook is the executable version of lab note 3.\n",
    "It answers the following questions:**\n",
    "\n",
    "Finally, we answer 4 items:\n",
    "\n",
    "    1. Are successful creators more connected to high-outdegree users than do unsuccessful creators?\n",
    "    2. Are mavens more connected to successful creators than to unsuccessful creators?\n",
    "    3. Do successful creators send more non-follow actions towards mavens than to zombies?\n",
    "    4. Do successful creators send more non-follow actions towards mavens than to stars?\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f459c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run parameters\n",
    "#used to control every run. Can be user to perfom sensitivity checks\n",
    "path_dir = r\"/Users/../Volumes/Raw/\"\n",
    "\n",
    "low_success = 0.5 #below the median: unsuccessful\n",
    "high_success = 0.9 #top 10% creators with more followers are deemed successful\n",
    "\n",
    "low_user_outdegree = 0.25 \n",
    "high_user_outdegree = 0.75\n",
    "low_user_activity = 0.25 \n",
    "high_user_activity = 0.75 \n",
    "\n",
    "activity_filter = 0\n",
    "days_delta = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a899b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data = pd.read_csv('user_types_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a758ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "import pickle\n",
    "sys.path.insert(0, '/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/')\n",
    "import numpy as np\n",
    "import src.utils\n",
    "from collections import Counter\n",
    "from src.utils import import_dta, import_tracks_dta,\\\n",
    "gen_active_relations, get_fan_interactions_per_week, calculate_avg_monthly_valence,\\\n",
    "gen_active_relations_prob, get_fan_interactions_per_week_prob, stripplot_prob,\\\n",
    "reaction_probability, follower_list, filter_quantile, sample_creators_music,\\\n",
    "gen_outbound_creators\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy\n",
    "import os\n",
    "from statsmodels.stats.proportion import proportions_ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d1bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date(date):\n",
    "    '''convert date format like '2013-w09' to '2013-03-04', i.e. the first day of that week'''\n",
    "    year = date[0:4]\n",
    "    week = date[6:]\n",
    "    day = \"1\"\n",
    "    date = \"{}-{}-1\".format(year, week)\n",
    "    dt = datetime.datetime.strptime(date, \"%Y-%W-%w\")\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f8fad",
   "metadata": {},
   "source": [
    "# Data Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2605f798",
   "metadata": {},
   "source": [
    "We start by importing the raw data.  `follows_sent`, `comments_sent`, `shares_sent`, `likes_sent` and `messages_sent` contains data pn the promotional activities that the 35k users tracked in the dataset directed to other users. It includes the `user_id`, the `fan_id` and the `date_sent` which identifies the date when the prom. activity was sent. `users_info_1st` shows the type of user (creator or non-creator, which is identified by a blank) and the date the user entered the platform, for every user that sent or received prom. activities from any of the 35k users tracked in this dataset, while `users_info` contains the same information, but pertaining to the 35k users themselves.\n",
    "\n",
    "`follows_received` contains information on the follows received by the 35k users and will be used to generate the successful/unsuccessful groups of content creators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03f61585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%% 12sample_tracks.dta %%%%%%%%%%\n",
      "(56262, 7)\n",
      "%%%%%%%%%% 12sample_affiliations_sent.dta %%%%%%%%%%\n",
      "(800913, 3)\n",
      "%%%%%%%%%% 12sample_comments_made.dta %%%%%%%%%%\n",
      "(29258, 4)\n",
      "%%%%%%%%%% 12sample_reposts_made.dta %%%%%%%%%%\n",
      "(179329, 4)\n",
      "%%%%%%%%%% 12sample_favoritings_made.dta %%%%%%%%%%\n",
      "(527701, 4)\n",
      "%%%%%%%%%% 12sample_messages_sent.dta %%%%%%%%%%\n",
      "(11091, 3)\n",
      "%%%%%%%%%% 12sample_1st_deg_user_infos.dta %%%%%%%%%%\n",
      "(670746, 3)\n",
      "%%%%%%%%%% 12sample_user_infos.dta %%%%%%%%%%\n",
      "(35000, 3)\n",
      "%%%%%%%%%% 12sample_affiliations_received.dta %%%%%%%%%%\n",
      "(432503, 3)\n"
     ]
    }
   ],
   "source": [
    "#affiliations :follows\n",
    "#favoritings :likes\n",
    "\n",
    "#used in filtering:\n",
    "path_dir = r\"/Users/../Volumes/Raw/\"\n",
    "tracks = import_tracks_dta(path_dir, \"12sample_tracks.dta\");\n",
    "\n",
    "#these are the actions sent to \n",
    "follows_sent = import_dta(path_dir, \"12sample_affiliations_sent.dta\");\n",
    "comments_sent = import_dta(path_dir, \"12sample_comments_made.dta\");\n",
    "shares_sent = import_dta(path_dir, \"12sample_reposts_made.dta\");\n",
    "likes_sent = import_dta(path_dir, \"12sample_favoritings_made.dta\");\n",
    "messages_sent = import_dta(path_dir, \"12sample_messages_sent.dta\");\n",
    "\n",
    "#Used to track information on the 1st degree connections\n",
    "user_info_1st = import_dta(path_dir, \"12sample_1st_deg_user_infos.dta\");\n",
    "user_info_1st.columns = ['user_id', 'type', 'entered_platform'];\n",
    "user_info = import_dta(path_dir, \"12sample_user_infos.dta\");\n",
    "\n",
    "#Used to compute creator's success measure\n",
    "follows_received = import_dta(path_dir, \"12sample_affiliations_received.dta\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35300c65",
   "metadata": {},
   "source": [
    "Indegree and outdegree information.\n",
    "\n",
    "The function below import the outdegree dataset. Because the raw version of those dataset are too large to be processed in memory, we preprocessed them in a separate script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cca037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregates preprocessed outdegree of 1st degree users\n",
    "def import_outdegree(path='/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/'):\n",
    "    d = {}\n",
    "    for i in range(6):\n",
    "       d[str(i)] = pd.read_pickle(os.path.join(path,'{}.pkl'.format(i))) \n",
    "       d[str(i)]['created_at'] =  pd.to_datetime(d[str(i)]['created_at'])\n",
    "       d[str(i)]['created_at'] = pd.to_datetime(d[str(i)]['created_at']).dt.floor('d')\n",
    "       d[str(i)] = d[str(i)].groupby(['sender_id', 'created_at'], as_index = False).size() \n",
    "    \n",
    "    data_outdegree = pd.concat([d['0'], d['1'], d['2'], d['3'], d['4'], d['5']])\n",
    "    #data_outdegree.set_index('created_at', inplace = True)\n",
    "    return data_outdegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e03d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outdegree = import_outdegree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed0a2e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_outdegree = data_outdegree.groupby(['sender_id','created_at'], as_index = False).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb3d51",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a358956e",
   "metadata": {},
   "source": [
    "## Creator ids, successful and unsucessful creators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb7bc74",
   "metadata": {},
   "source": [
    "Next, we define three lists of ids: one with the ids from the content creators, according to the `users_info` table, one with the ids of successful creators and the last one with the ids of the unsuccessful ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77715356",
   "metadata": {},
   "source": [
    "Let's start with a list of the id of creators. We also create a dataset with containing information on creators only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd634fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (tracks.track_available == 1) & (tracks.public == 't')\n",
    "creator_ids = tracks[mask].user_id.unique()\n",
    "\n",
    "creators = tracks[(tracks.track_available == 1) & (tracks.public == 't')]\n",
    "\n",
    "#mask = user_info.type == 'creator'\n",
    "#creator_ids = user_info[mask].user_id.unique()\n",
    "\n",
    "#creators = user_info[user_info.type == 'creator']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b06476a",
   "metadata": {},
   "source": [
    "## Putting together a dataset with the promotional activities made by content creators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b8a09",
   "metadata": {},
   "source": [
    "The function `gen_actions_sent_df` creates a dataframe with all the promotional activities that content creators sent to users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fff0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_actions_sent_df(follows_sent, shares_sent, likes_sent, comments_sent, messages_sent, creator_ids = creator_ids):\n",
    "    '''\n",
    "    Creates dataframe containing the actions that content creators send to users.\n",
    "        Attributes:\n",
    "                    follows_sent:  dataframe with the follows sent by the 35k users.\n",
    "                    shares_sent:   dataframe with the shares sent by the 35k users.\n",
    "                    likes_sent:    dataframe with the likes sent by the 35k users.\n",
    "                    comments_sent: dataframe with the comments sent by the 35k users.\n",
    "                    messages_sent: dataframe with the messages sent by the 35k users.\n",
    "                    creator_ids:   list with content creator ids. If not none, is used to\n",
    "                                   filter out activities from non creators.\n",
    "    '''\n",
    "    \n",
    "    follows_sent['outbound_activity'] = 'follow'\n",
    "    follows_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'song_id' in shares_sent.columns:\n",
    "        shares_sent.drop(columns=[\"song_id\"])\n",
    "    shares_sent = shares_sent[['reposter_id', \"owner_id\", 'created_at']]\n",
    "    shares_sent['outbound_activity'] = 'share'\n",
    "    shares_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'track_id' in likes_sent.columns:\n",
    "        likes_sent.drop(columns=[\"track_id\"], inplace=True)\n",
    "    likes_sent['outbound_activity'] = 'like'\n",
    "    likes_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'track_id' in comments_sent.columns:\n",
    "        comments_sent.drop(columns=[\"track_id\"], inplace=True)\n",
    "    comments_sent['outbound_activity'] = 'comment'\n",
    "    comments_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    messages_sent[\"outbound_activity\"] = 'message'\n",
    "    messages_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "    df = pd.concat([follows_sent, shares_sent, likes_sent, comments_sent, messages_sent])\n",
    "\n",
    "\n",
    "    if type(creator_ids) == numpy.ndarray:\n",
    "        df = df[df['user_id'].isin(creator_ids)]\n",
    "        \n",
    "    df['week_yr'] = df.date_sent.dt.strftime('%Y-w%U')\n",
    "    df = df.loc[df['user_id'] != df['fan_id'],:]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c6b8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_sent = gen_actions_sent_df(follows_sent, shares_sent, likes_sent, comments_sent,\n",
    "                                     messages_sent, creator_ids = None)\n",
    "actions_sent = actions_sent.loc[actions_sent.user_id.isin(creators.user_id.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6462039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_users_ids = actions_sent.groupby('user_id', as_index = False).size()\n",
    "mask = active_users_ids['size']>= activity_filter\n",
    "active_users_ids = active_users_ids[mask].user_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d58e13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def successful_creators_followers(follows_received, base_date = datetime.datetime(2016, 5, 30, 0, 0), perc1 = None, perc2 = None, subset_creators = None):\n",
    "    '''Classifies content creators in successful or unsuccessfull\n",
    "        Arguments:\n",
    "                    follows_received: dataframe containing the follows received by content creators\n",
    "                    base date:        date, in datetime.datetime(YYYY, M, DD, H, M) format, in which the number \n",
    "                                      of followers per creator is calculated.\n",
    "                    perc1:            the threshold used to classify unsuccessful content creators. Creator having \n",
    "                                      total followers below the number dictated by this threshold, at the base date,\n",
    "                                      are classified as unsuccessful \n",
    "                    perc2:            the threshold used to classify successful content creators. Creator having \n",
    "                                      total followers above the number dictated by this threshold, at the base date,\n",
    "                                      are classified as successful\n",
    "                    subset_creators:  a pd.DataFrame containing the creators. If is it available, it will be used to \n",
    "                                      filter out non creators and to make sure creators with 0 followers are part of\n",
    "                                      the resulting dataset.\n",
    "        \n",
    "    '''\n",
    "    print(base_date)\n",
    "\n",
    "    if 'inbound_activity' not in follows_received.columns:\n",
    "        follows_received.columns = ['fan_id', 'user_id', 'date_sent']\n",
    "\n",
    "    mask = (follows_received['date_sent'] < base_date)\n",
    "\n",
    "    df = follows_received[mask].groupby('user_id', as_index=False).agg({'fan_id': pd.Series.nunique})\n",
    "    df.columns = ['user_id', 'followers']\n",
    "\n",
    "    \n",
    "    if type(subset_creators) == pd.DataFrame:\n",
    "        print('subsetting...')\n",
    "        df.set_index('user_id', inplace = True)\n",
    "        df = df.reindex(subset_creators.user_id.unique())\n",
    "        df.fillna(0, inplace = True)\n",
    "        df.reset_index(inplace = True)\n",
    "        df.columns = ['user_id', 'followers']\n",
    "        \n",
    "    mask = df.user_id.isin(active_users_ids)\n",
    "    df = df[mask]\n",
    "\n",
    "    low = np.quantile(df.followers, perc1)\n",
    "    high = np.quantile(df.followers, perc2)\n",
    "\n",
    "    print(\"High influencer boundary: {}\".format(high))\n",
    "    print(\"Low influencer boundary: {}\".format(low))\n",
    "\n",
    "    mask = (df[\"followers\"] <= low) | (df[\"followers\"] >= high)\n",
    "    \n",
    "    unsuccessful_creator_ids = df.loc[df[\"followers\"] <= low].user_id.unique()\n",
    "    successful_creator_ids = df.loc[df[\"followers\"] >= high].user_id.unique()\n",
    "\n",
    "    return unsuccessful_creator_ids, successful_creator_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ee655c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-30 00:00:00\n",
      "subsetting...\n",
      "High influencer boundary: 81.0\n",
      "Low influencer boundary: 13.0\n"
     ]
    }
   ],
   "source": [
    "unsuccessful_ids, successful_ids = successful_creators_followers(follows_received, \n",
    "                                                        perc1 = low_success, perc2 = high_success, subset_creators = creators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc85a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1959\n",
      "389\n"
     ]
    }
   ],
   "source": [
    "print(len(unsuccessful_ids))\n",
    "print(len(successful_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8d8980c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4604"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creators.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6f8c4",
   "metadata": {},
   "source": [
    "## Filter only actions that were sent to non-fans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a67b459",
   "metadata": {},
   "source": [
    "We merge the `actions_sent` dataset with a table containing the date each fan started following the creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b904f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_received.columns = ['fan_id', 'user_id', 'date_sent']\n",
    "followers = follows_received[[\"fan_id\", \"user_id\", \"date_sent\"]]\n",
    "followers.columns = [\"fan_id\", \"user_id\", \"follower_since\"]\n",
    "\n",
    "actions_sent = actions_sent.merge(followers, right_on = ['user_id', 'fan_id'],\n",
    "                                      left_on = ['user_id', 'fan_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973ebc19",
   "metadata": {},
   "source": [
    "Since we are interested in acquisition campaings, we need to produce a dataset that exclude actions targetting fans.\n",
    "We do that using filters based on the date of the action and the date that the user became a fan of the content creator. The resulting dataframe is named `actions_sent_non_fans`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dbf162",
   "metadata": {},
   "source": [
    "We then filter only actions that happened before the user follows the content creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c957f00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/cgjzt69n5hlgmtsm36p1pztw0000gn/T/ipykernel_67304/3855957735.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  actions_sent_non_fans['week_yr_date'] = actions_sent_non_fans.week_yr.apply(lambda x: process_date(x))\n"
     ]
    }
   ],
   "source": [
    "mask = (actions_sent.date_sent < actions_sent.follower_since) | (actions_sent.follower_since.isnull())\n",
    "actions_sent_non_fans =  actions_sent[mask]\n",
    "actions_sent_non_fans['week_yr_date'] = actions_sent_non_fans.week_yr.apply(lambda x: process_date(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d9b9e",
   "metadata": {},
   "source": [
    "## Outdegree level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a61f1",
   "metadata": {},
   "source": [
    "Originally, we only have outdegree information on users that follow at least one user. The function below inputs an outdegree of 0 to users that are following anyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1083a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGE DOCUMENTATION\n",
    "def outdegree_level(data, date, user_info = user_info_1st):\n",
    "    \n",
    "    '''\n",
    "    This function returns the membership table at date equals `date`. Every user that interacted with the 35k tracked \n",
    "    users and entered the platform before `date` is present in the table, even if it has indegree 0.\n",
    "    arguments:\n",
    "              data:           the indegree dataset.\n",
    "              user_info:      the dataset containing all the users that interacted with the 35k users tracked.\n",
    "    '''\n",
    "    \n",
    "    data = data[data.created_at.dt.floor('d')<=date]\n",
    "    data = data.groupby('sender_id').agg({'size':'sum'}).compute()\n",
    "    \n",
    "    #merge with user info to obtain users that are not followed by anyone at the current date\n",
    "    data = user_info_1st.merge(data, left_on = 'user_id', right_on = 'sender_id', how= 'outer')\n",
    "    data.loc[data['size'].isnull(), 'size'] = 0\n",
    "    data = data[['user_id', 'size', 'entered_platform']].set_index('user_id')\n",
    "    \n",
    "    #filter out users that didnt exist in the current date\n",
    "    mask = data['entered_platform'].dt.floor('d') <= date\n",
    "    data = data.loc[mask]\n",
    "    \n",
    "    mask = (data['size']>0)\n",
    "    data.loc[~mask, 'size'] = 0 \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63a49e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dask is a python api with objects optimized for big data (user directed acyclic graphs). \n",
    "dask_outdegree = dd.from_pandas(data_outdegree, npartitions = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21950961",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_day =  max(actions_sent.date_sent.dt.floor('d').unique())\n",
    "user_outdegree = outdegree_level(dask_outdegree, last_day, user_info = user_info_1st)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b5931",
   "metadata": {},
   "source": [
    "Now we classify the creator in successful and unsuccessful, according to the threshold defined in the beggining of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52d85729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_outdegree_level(oudegree_data, perc1 = None, perc2 = None):\n",
    "    '''Classifies content creators in successful or unsuccessfull\n",
    "        Arguments:\n",
    "                    oudegree_data:    dataframe containing the fans followers at \n",
    "                    perc1:            the threshold used to classify unsuccessful content creators. Creator having \n",
    "                                      total followers below the number dictated by this threshold, at the base date,\n",
    "                                      are classified as unsuccessful \n",
    "                    perc2:            the threshold used to classify successful content creators. Creator having \n",
    "                                      total followers above the number dictated by this threshold, at the base date,\n",
    "                                      are classified as successful\n",
    "    '''\n",
    "\n",
    "    df = oudegree_data.reset_index().iloc[:,:2]\n",
    "    df.columns = ['user_id', 'followers']\n",
    "\n",
    "    low = np.quantile(df.followers, perc1)\n",
    "    high = np.quantile(df.followers, perc2)\n",
    "\n",
    "    print(\"High outdegree boundary: {}\".format(high))\n",
    "    print(\"Low outdegree boundary: {}\".format(low))\n",
    "    \n",
    "    low_outdegree_ids = df.loc[df[\"followers\"] <= low].user_id.unique()\n",
    "    high_outdegree_ids = df.loc[df[\"followers\"] >= high].user_id.unique()\n",
    "    \n",
    "    \n",
    "    df['outdegree_level'] = df.user_id.apply(\n",
    "        lambda x: 'high' if x in high_outdegree_ids else ('low' if x in low_outdegree_ids else None))\n",
    "\n",
    "    \n",
    "    return df, low_outdegree_ids, high_outdegree_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87b4271a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High outdegree boundary: 162.0\n",
      "Low outdegree boundary: 17.0\n"
     ]
    }
   ],
   "source": [
    "user_outdegree_df, low_outdegree_ids, high_outdegree_ids = user_outdegree_level(user_outdegree,\n",
    "                perc1 = low_user_outdegree, perc2 = high_user_outdegree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc7f983",
   "metadata": {},
   "source": [
    "In the cell below, we create a list with unique ids from users that appear in the oudegree level table. This will later be uses to construct a flow-chart indicating how we lose data based on filters and operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "406e4e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "receiver_ids = user_outdegree.index.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1faaf",
   "metadata": {},
   "source": [
    "## Non-follow Actions level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4db5e11",
   "metadata": {},
   "source": [
    "The activity level is defined as the number of actions performed by users. It is important to notice that we only observe actions targeting the 35k users that joined in march 2012. We consider this measure a proxy for the real activity level.\n",
    "\n",
    "Let's begin by creating a dataset with all action received by those 35k users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82504b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%% 12sample_comments_received.dta %%%%%%%%%%\n",
      "(21386, 4)\n",
      "%%%%%%%%%% 12sample_reposts_received.dta %%%%%%%%%%\n",
      "(83013, 4)\n",
      "%%%%%%%%%% 12sample_favoritings_received.dta %%%%%%%%%%\n",
      "(286903, 4)\n",
      "%%%%%%%%%% 12sample_messages_received.dta %%%%%%%%%%\n",
      "(17364, 3)\n"
     ]
    }
   ],
   "source": [
    "comments_received_35k = import_dta(path_dir, \"12sample_comments_received.dta\");\n",
    "shares_received_35k = import_dta(path_dir, \"12sample_reposts_received.dta\");\n",
    "likes_received_35k = import_dta(path_dir, \"12sample_favoritings_received.dta\");\n",
    "messages_received_35k = import_dta(path_dir, \"12sample_messages_received.dta\");\n",
    "\n",
    "if 'song_id' in shares_received_35k:\n",
    "        shares_received_35k.drop(columns=[\"song_id\"])\n",
    "shares_received_35k = shares_received_35k[['reposter_id', \"owner_id\", 'created_at']]\n",
    "shares_received_35k['outbound_activity'] = 'share'\n",
    "shares_received_35k.columns = ['fan_id', 'user_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "if 'track_id' in likes_received_35k:\n",
    "        likes_received_35k = likes_received_35k.drop(columns=[\"track_id\"])\n",
    "likes_received_35k['outbound_activity'] = 'like'\n",
    "likes_received_35k.columns = ['fan_id', 'user_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "if 'track_id' in comments_received_35k:\n",
    "        comments_received_35k = comments_received_35k.drop(columns=[\"track_id\"])\n",
    "comments_received_35k['outbound_activity'] = 'comment'\n",
    "comments_received_35k.columns = ['fan_id', 'user_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "messages_received_35k[\"outbound_activity\"] = 'message'\n",
    "messages_received_35k.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "user_activity_data_35k = pd.concat([shares_received_35k, likes_received_35k, comments_received_35k, messages_received_35k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bec0ad24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%% 12sample_1st_deg_comments_made.dta %%%%%%%%%%\n",
      "(21463011, 4)\n",
      "%%%%%%%%%% 12sample_1st_deg_reposts_made.dta %%%%%%%%%%\n",
      "(18953640, 4)\n",
      "%%%%%%%%%% 12sample_1st_deg_favoritings_made.dta %%%%%%%%%%\n",
      "(86793370, 4)\n",
      "%%%%%%%%%% 12sample_1st_deg_messages_sent.dta %%%%%%%%%%\n",
      "(16824074, 3)\n"
     ]
    }
   ],
   "source": [
    "path_dir_2 = r'/Users/../Volumes/Alter_outbound_activities/'\n",
    "\n",
    "comments_received_c = import_dta(path_dir_2, \"12sample_1st_deg_comments_made.dta\");\n",
    "shares_received_c = import_dta(path_dir_2, \"12sample_1st_deg_reposts_made.dta\");\n",
    "likes_received_c = import_dta(path_dir_2, \"12sample_1st_deg_favoritings_made.dta\");\n",
    "messages_received_c = import_dta(path_dir_2, \"12sample_1st_deg_messages_sent.dta\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ec99f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/cgjzt69n5hlgmtsm36p1pztw0000gn/T/ipykernel_64965/1613121866.py:15: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  comments_received_c.columns_c = ['fan_id', 'user_id', 'date_sent', 'inbound_activity']\n"
     ]
    }
   ],
   "source": [
    "if 'song_id' in shares_received_c:\n",
    "        shares_received_c.drop(columns=[\"song_id\"])\n",
    "shares_received_c = shares_received_c[['reposter_id', \"owner_id\", 'created_at']]\n",
    "shares_received_c['inbound_activity'] = 'share'\n",
    "shares_received_c.columns = ['fan_id', 'user_id', 'date_sent', 'inbound_activity']\n",
    "\n",
    "if 'track_id' in likes_received_c:\n",
    "        likes_received_c = likes_received_c.drop(columns=[\"track_id\"])\n",
    "likes_received_c['inbound_activity'] = 'like'\n",
    "likes_received_c.columns = ['fan_id', 'user_id', 'date_sent', 'inbound_activity']\n",
    "\n",
    "if 'track_id' in comments_received_c:\n",
    "        comments_received_c = comments_received_c.drop(columns=[\"track_id\"])\n",
    "comments_received_c['inbound_activity'] = 'comment'\n",
    "comments_received_c.columns_c = ['fan_id', 'user_id', 'date_sent', 'inbound_activity']\n",
    "\n",
    "messages_received_c[\"outbound_activity\"] = 'message'\n",
    "messages_received_c.columns = ['user_id', 'fan_id', 'date_sent', 'inbound_activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c28ce54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity_data_c = pd.concat([shares_received_c, likes_received_c, comments_received_c, messages_received_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e789958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_activity_level(user_activity_data, receiver_ids, perc1 = None, perc2 = None):\n",
    "    '''Classifies users based on the amount of non-follow activities\n",
    "        Arguments:\n",
    "                    user_activity_data:   dataframe containing the user activities \n",
    "                    base date:             date, in datetime.datetime(YYYY, M, DD, H, M) format, in which the number \n",
    "                                           of followers per creator is calculated.\n",
    "                    perc1:                 the threshold used to classify unsuccessful content creators. Creator having \n",
    "                                           total followers below the number dictated by this threshold, at the base date,\n",
    "                                           are classified as unsuccessful \n",
    "                    perc2:                 the threshold used to classify successful content creators. Creator having \n",
    "                                           total followers above the number dictated by this threshold, at the base date,\n",
    "                                           are classified as successful\n",
    "    '''\n",
    "\n",
    "    df = user_activity_data.groupby('fan_id', as_index = True).size()\n",
    "    df = df.reindex(receiver_ids)\n",
    "    print(df.shape)\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['user_id', 'activities_performed']\n",
    "    \n",
    "    df.loc[df.activities_performed.isna(), 'activities_performed'] = 0\n",
    "    #classification should happen after this\n",
    "\n",
    "    low = np.quantile(df.activities_performed, perc1)\n",
    "    high = np.quantile(df.activities_performed, perc2)\n",
    "\n",
    "    print(\"High activity boundary: {}\".format(high))\n",
    "    print(\"Low activity boundary: {}\".format(low))\n",
    "    \n",
    "    low_activity_ids = df.loc[df[\"activities_performed\"] <= low].user_id.unique()\n",
    "    high_activity_ids = df.loc[df[\"activities_performed\"] > high].user_id.unique()\n",
    "    \n",
    "    df['activity_level'] = df.user_id.apply(\n",
    "    lambda x: 'high' if x in high_activity_ids else ('low' if x in low_activity_ids else None))\n",
    "\n",
    "    return df, low_activity_ids, high_activity_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f3367a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(670746,)\n",
      "High activity boundary: 70.0\n",
      "Low activity boundary: 1.0\n"
     ]
    }
   ],
   "source": [
    "activity_level, low_activity_ids, high_activity_ids = user_activity_level(user_activity_data_c, receiver_ids, \n",
    "                perc1 = low_user_activity, perc2 = high_user_activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a392a41",
   "metadata": {},
   "source": [
    "Once more we create an object containing the unique ids of users in the resulting dataset. This will be used in a flow-chart, as explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "972bf9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_ids = np.append(low_activity_ids, high_activity_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf24ca28",
   "metadata": {},
   "source": [
    "# Priori response probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "004cd597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_data = user_outdegree_df.merge(activity_level, left_on = 'user_id', right_on = 'user_id', how = 'inner')\n",
    "# table_data.groupby(['outdegree_level', 'activity_level']).size()\n",
    "# table_data['Type'] = table_data.apply(lambda x: \n",
    "#     'f_a' if (x.outdegree_level == 'low') & (x.activity_level == 'high')\n",
    "#      else ('Hermit' if (x.outdegree_level == 'low') & (x.activity_level == 'low')\n",
    "#      else ('Observer' if (x.outdegree_level == 'high') & (x.activity_level == 'low')\n",
    "#      else ('w_a' if (x.outdegree_level == 'high') & (x.activity_level == 'high')\n",
    "#      else 'other'))), axis=1)\n",
    "\n",
    "hermit_ids = table_data.loc[table_data.Type =='Hermit'].user_id.unique()\n",
    "w_a_ids = table_data.loc[table_data.Type =='w_a'].user_id.unique()\n",
    "f_a_ids = table_data.loc[table_data.Type =='f_a'].user_id.unique()\n",
    "observer_ids = table_data.loc[table_data.Type =='Observer'].user_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cb38cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_sent['user_type'] = actions_sent.fan_id.apply(lambda x: 'f_a' if x in f_a_ids else \n",
    "                          ('Hermit' if x in hermit_ids else\n",
    "                          ('Observer' if x in observer_ids else\n",
    "                          ('w_a' if x in w_a_ids else 'other'))))\n",
    "\n",
    "## classify content creators\n",
    "actions_sent['creator_type'] = actions_sent.user_id.apply(\n",
    "                               lambda x: 'successful' if x in successful_ids else \n",
    "                               ('unsuccessful' if x in unsuccessful_ids else 'other'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ba561a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Target Creation\n",
    "delta = datetime.timedelta(days = days_delta)\n",
    "mask = (actions_sent_non_fans['follower_since'] <= (actions_sent_non_fans['date_sent'] + delta))\n",
    "\n",
    "response_df = actions_sent_non_fans.copy()\n",
    "response_df.loc[mask, 'reward'] = 1\n",
    "mask = response_df['reward'].isnull()\n",
    "response_df.loc[mask, 'reward'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b51ac7a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'creator_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m attempts \u001b[38;5;241m=\u001b[39m \u001b[43mresponse_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreator_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m      2\u001b[0m rewards \u001b[38;5;241m=\u001b[39m response_df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreator_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_type\u001b[39m\u001b[38;5;124m'\u001b[39m], as_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m      4\u001b[0m priori_prob_df \u001b[38;5;241m=\u001b[39m rewards\u001b[38;5;241m.\u001b[39mmerge(attempts)\n",
      "File \u001b[0;32m~/Desktop/BDS/RA/Seeding-Bandits/venv/lib/python3.8/site-packages/pandas/core/frame.py:7712\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   7707\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m   7709\u001b[0m \u001b[38;5;66;03m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[1;32m   7710\u001b[0m \u001b[38;5;66;03m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[1;32m   7711\u001b[0m \u001b[38;5;66;03m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[0;32m-> 7712\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   7713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7715\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7718\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7720\u001b[0m \u001b[43m    \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   7721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/BDS/RA/Seeding-Bandits/venv/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_grouper\n\u001b[0;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/Desktop/BDS/RA/Seeding-Bandits/venv/lib/python3.8/site-packages/pandas/core/groupby/grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    880\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 882\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'creator_type'"
     ]
    }
   ],
   "source": [
    "attempts = response_df.groupby(['creator_type', 'user_type'], as_index = False).size()\n",
    "rewards = response_df.groupby(['creator_type', 'user_type'], as_index = False).agg({'reward' : 'sum'})\n",
    "\n",
    "priori_prob_df = rewards.merge(attempts)\n",
    "priori_prob_df['P_resp_prob'] = priori_prob_df['reward']/priori_prob_df['size']\n",
    "priori_prob_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1748a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0402ce5b",
   "metadata": {},
   "source": [
    "# Priori repost probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4516dffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fan_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date_sent</th>\n",
       "      <th>outbound_activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33635491</td>\n",
       "      <td>38135744</td>\n",
       "      <td>2013-03-05 05:50:34</td>\n",
       "      <td>share</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38321910</td>\n",
       "      <td>38123852</td>\n",
       "      <td>2013-03-05 23:11:40</td>\n",
       "      <td>share</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38263941</td>\n",
       "      <td>38263941</td>\n",
       "      <td>2013-03-06 17:43:46</td>\n",
       "      <td>share</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38470533</td>\n",
       "      <td>38470533</td>\n",
       "      <td>2013-03-09 13:10:51</td>\n",
       "      <td>share</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6746343</td>\n",
       "      <td>38145276</td>\n",
       "      <td>2013-03-11 06:32:23</td>\n",
       "      <td>share</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17359</th>\n",
       "      <td>38454344</td>\n",
       "      <td>45734072</td>\n",
       "      <td>2015-06-25 12:58:18</td>\n",
       "      <td>message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17360</th>\n",
       "      <td>38247575</td>\n",
       "      <td>160132541</td>\n",
       "      <td>2015-06-27 18:11:42</td>\n",
       "      <td>message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17361</th>\n",
       "      <td>37923935</td>\n",
       "      <td>160510643</td>\n",
       "      <td>2015-06-30 05:25:18</td>\n",
       "      <td>message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17362</th>\n",
       "      <td>37875920</td>\n",
       "      <td>160559068</td>\n",
       "      <td>2015-06-30 10:46:04</td>\n",
       "      <td>message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17363</th>\n",
       "      <td>38455179</td>\n",
       "      <td>20136791</td>\n",
       "      <td>2015-07-02 02:05:07</td>\n",
       "      <td>message</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408666 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fan_id    user_id           date_sent outbound_activity\n",
       "0      33635491   38135744 2013-03-05 05:50:34             share\n",
       "1      38321910   38123852 2013-03-05 23:11:40             share\n",
       "2      38263941   38263941 2013-03-06 17:43:46             share\n",
       "3      38470533   38470533 2013-03-09 13:10:51             share\n",
       "4       6746343   38145276 2013-03-11 06:32:23             share\n",
       "...         ...        ...                 ...               ...\n",
       "17359  38454344   45734072 2015-06-25 12:58:18           message\n",
       "17360  38247575  160132541 2015-06-27 18:11:42           message\n",
       "17361  37923935  160510643 2015-06-30 05:25:18           message\n",
       "17362  37875920  160559068 2015-06-30 10:46:04           message\n",
       "17363  38455179   20136791 2015-07-02 02:05:07           message\n",
       "\n",
       "[408666 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_activity_data_35k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a86dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity_data_35k['day_yr_date'] = user_activity_data_35k.date_sent.dt.normalize()\n",
    "\n",
    "reposts_df = user_activity_data_35k.loc[user_activity_data_35k.outbound_activity == 'share']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "796e1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_sent['user_type'] = actions_sent.fan_id.apply(lambda x: 'f_a' if x in f_a_ids else \n",
    "                          ('Hermit' if x in hermit_ids else\n",
    "                          ('Observer' if x in observer_ids else\n",
    "                          ('w_a' if x in w_a_ids else 'other'))))\n",
    "\n",
    "## classify content creators\n",
    "actions_sent['creator_type'] = actions_sent.user_id.apply(\n",
    "                                            lambda x: 'successful' if x in successful_ids else \n",
    "                                            ('unsuccessful' if x in unsuccessful_ids else 'other'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "036dc025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/cgjzt69n5hlgmtsm36p1pztw0000gn/T/ipykernel_67304/699805651.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  actions_sent_to_fans['week_yr_date'] = actions_sent_to_fans.week_yr.apply(lambda x: process_date(x))\n",
      "/var/folders/f2/cgjzt69n5hlgmtsm36p1pztw0000gn/T/ipykernel_67304/699805651.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  repost_prob_df.sort_values(['user_id', 'fan_id'], inplace = True)\n",
      "/var/folders/f2/cgjzt69n5hlgmtsm36p1pztw0000gn/T/ipykernel_67304/699805651.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  repost_prob_df['reward_repost'] = np.nan\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2351/2351 [00:53<00:00, 44.15it/s]\n",
      "/var/folders/f2/cgjzt69n5hlgmtsm36p1pztw0000gn/T/ipykernel_67304/699805651.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  repost_prob_df.sort_values(by='date_sent', inplace = True)\n"
     ]
    }
   ],
   "source": [
    "mask = (actions_sent.date_sent >= actions_sent.follower_since)\n",
    "actions_sent_to_fans = actions_sent[mask]\n",
    "actions_sent_to_fans['week_yr_date'] = actions_sent_to_fans.week_yr.apply(lambda x: process_date(x))\n",
    "\n",
    "repost_prob_df = actions_sent_to_fans # filter for follower only\n",
    "repost_prob_df.sort_values(['user_id', 'fan_id'], inplace = True)\n",
    "repost_prob_df['reward_repost'] = np.nan\n",
    "for user_id in tqdm(repost_prob_df.user_id.unique()):\n",
    "    for fan_id in repost_prob_df.loc[repost_prob_df.user_id == user_id].fan_id.unique():\n",
    "        repost_prob_df.loc[(repost_prob_df.user_id == user_id)&\n",
    "                              (repost_prob_df.fan_id == fan_id),'reward_repost'] =\\\n",
    "        repost_prob_df.loc[(repost_prob_df.user_id == user_id)&\n",
    "                              (repost_prob_df.fan_id == fan_id)].date_sent.apply(\n",
    "        lambda x : 1 if \n",
    "    (reposts_df.loc[\n",
    "    (reposts_df.user_id == user_id)&\n",
    "    (reposts_df.fan_id == fan_id)&\n",
    "    (reposts_df.day_yr_date > x)&   \n",
    "    (reposts_df.day_yr_date <= x + datetime.timedelta(days=days_delta))]).shape[0]>0 else 0)\n",
    "                                          \n",
    "repost_prob_df.sort_values(by='date_sent', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea24f9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "like       286903\n",
       "share       83013\n",
       "comment     21386\n",
       "message     17364\n",
       "Name: outbound_activity, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_activity_data_35k.outbound_activity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "507c1f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator_type</th>\n",
       "      <th>user_type</th>\n",
       "      <th>reward_repost</th>\n",
       "      <th>size</th>\n",
       "      <th>P_rep_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other</td>\n",
       "      <td>Hermit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>624</td>\n",
       "      <td>0.001603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>Observer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other</td>\n",
       "      <td>f_a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>77.0</td>\n",
       "      <td>12259</td>\n",
       "      <td>0.006281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other</td>\n",
       "      <td>w_a</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2728</td>\n",
       "      <td>0.006232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>successful</td>\n",
       "      <td>Hermit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>successful</td>\n",
       "      <td>Observer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>successful</td>\n",
       "      <td>f_a</td>\n",
       "      <td>13.0</td>\n",
       "      <td>194</td>\n",
       "      <td>0.067010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>successful</td>\n",
       "      <td>other</td>\n",
       "      <td>100.0</td>\n",
       "      <td>13856</td>\n",
       "      <td>0.007217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>successful</td>\n",
       "      <td>w_a</td>\n",
       "      <td>372.0</td>\n",
       "      <td>11533</td>\n",
       "      <td>0.032255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>unsuccessful</td>\n",
       "      <td>Hermit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>unsuccessful</td>\n",
       "      <td>Observer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>unsuccessful</td>\n",
       "      <td>f_a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>unsuccessful</td>\n",
       "      <td>other</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2106</td>\n",
       "      <td>0.005698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>unsuccessful</td>\n",
       "      <td>w_a</td>\n",
       "      <td>2.0</td>\n",
       "      <td>373</td>\n",
       "      <td>0.005362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    creator_type user_type  reward_repost   size  P_rep_prob\n",
       "0          other    Hermit            1.0    624    0.001603\n",
       "1          other  Observer            0.0    173    0.000000\n",
       "2          other       f_a            0.0     73    0.000000\n",
       "3          other     other           77.0  12259    0.006281\n",
       "4          other       w_a           17.0   2728    0.006232\n",
       "5     successful    Hermit            0.0    335    0.000000\n",
       "6     successful  Observer            0.0    252    0.000000\n",
       "7     successful       f_a           13.0    194    0.067010\n",
       "8     successful     other          100.0  13856    0.007217\n",
       "9     successful       w_a          372.0  11533    0.032255\n",
       "10  unsuccessful    Hermit            0.0    220    0.000000\n",
       "11  unsuccessful  Observer            0.0     20    0.000000\n",
       "12  unsuccessful       f_a            0.0     23    0.000000\n",
       "13  unsuccessful     other           12.0   2106    0.005698\n",
       "14  unsuccessful       w_a            2.0    373    0.005362"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attempts = repost_prob_df.groupby(['creator_type', 'user_type'], as_index = False).size()\n",
    "rewards = repost_prob_df.groupby(['creator_type', 'user_type'], as_index = False).agg({'reward_repost' : 'sum'})\n",
    "\n",
    "priori_rep_df = rewards.merge(attempts)\n",
    "priori_rep_df['P_rep_prob'] = priori_rep_df['reward_repost']/priori_rep_df['size']\n",
    "priori_rep_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79321672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44769"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(priori_rep_df['size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "33a38b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator_type</th>\n",
       "      <th>user_type</th>\n",
       "      <th>reward_repost</th>\n",
       "      <th>size</th>\n",
       "      <th>P_rep_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>successful</td>\n",
       "      <td>Hermit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>successful</td>\n",
       "      <td>Observer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>successful</td>\n",
       "      <td>f_a</td>\n",
       "      <td>13.0</td>\n",
       "      <td>194</td>\n",
       "      <td>0.067010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>successful</td>\n",
       "      <td>other</td>\n",
       "      <td>100.0</td>\n",
       "      <td>13856</td>\n",
       "      <td>0.007217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>successful</td>\n",
       "      <td>w_a</td>\n",
       "      <td>372.0</td>\n",
       "      <td>11533</td>\n",
       "      <td>0.032255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  creator_type user_type  reward_repost   size  P_rep_prob\n",
       "5   successful    Hermit            0.0    335    0.000000\n",
       "6   successful  Observer            0.0    252    0.000000\n",
       "7   successful       f_a           13.0    194    0.067010\n",
       "8   successful     other          100.0  13856    0.007217\n",
       "9   successful       w_a          372.0  11533    0.032255"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priori_rep_df.loc[priori_rep_df.creator_type == 'successful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e0631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "repost_avg_df = actions_sent.copy()\n",
    "repost_avg_df.sort_values(['user_id', 'fan_id'], inplace = True)\n",
    "repost_avg_df['reward_repost'] = np.nan\n",
    "for user_id in tqdm(repost_avg_df.user_id.unique()):\n",
    "    for fan_id in repost_avg_df.loc[repost_avg_df.user_id == user_id].fan_id.unique():\n",
    "        repost_avg_df.loc[(repost_avg_df.user_id == user_id)&\n",
    "                              (repost_avg_df.fan_id == fan_id),'reward_repost'] =\\\n",
    "        repost_avg_df.loc[(repost_avg_df.user_id == user_id)&\n",
    "                              (repost_avg_df.fan_id == fan_id)].date_sent.apply(\n",
    "        lambda x : \n",
    "    (reposts_df.loc[\n",
    "    (reposts_df.user_id == user_id)&\n",
    "    (reposts_df.fan_id == fan_id)&\n",
    "    (reposts_df.day_yr_date > x)&   \n",
    "    (reposts_df.day_yr_date <= x + datetime.timedelta(days=days_delta))]).shape[0])\n",
    "                                          \n",
    "repost_avg_df.sort_values(by='date_sent', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92324229",
   "metadata": {},
   "source": [
    "# Expected (Indirect) Returns Associated with a Song-Repost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d831e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "share_follower_lists = pd.read_pickle('/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/Data/alter_follower_lists.pkl')\n",
    "action_follower_lists = pd.read_pickle('/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/Data/alter_follower_lists_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85106451",
   "metadata": {},
   "outputs": [],
   "source": [
    "follower_lists = share_follower_lists\n",
    "expec_followers = user_activity_data_35k.loc[user_activity_data_35k.outbound_activity == 'share']\n",
    "expec_followers = expec_followers.loc[expec_followers.user_id.isin(creators.user_id)]\n",
    "\n",
    "expec_followers = expec_followers.loc[expec_followers.fan_id.isin(follower_lists.index.unique())]\n",
    "expec_followers['expec_followers'] = np.nan\n",
    "expec_followers.sort_values(['user_id', 'fan_id'], inplace = True)\n",
    "\n",
    "follows_received.date_sent = follows_received.date_sent.dt.normalize()\n",
    "\n",
    "for user_id in tqdm(expec_followers.user_id.unique()):\n",
    "    follows_received_j = follows_received.loc[follows_received.user_id == user_id]\n",
    "    for fan_id in expec_followers.loc[expec_followers.user_id == user_id].fan_id.unique():\n",
    "        fan_follows = follower_lists.loc[follower_lists.index == fan_id].values[0]\n",
    "        expec_followers.loc[(expec_followers.user_id == user_id)&\n",
    "                                  (expec_followers.fan_id == fan_id),'expec_followers'] =\\\n",
    "        expec_followers.loc[(expec_followers.user_id == user_id)&\n",
    "                                  (expec_followers.fan_id == fan_id)].date_sent.apply(\n",
    "            lambda x : \n",
    "            np.sum(np.in1d(\n",
    "                           follows_received_j.loc[(x <= follows_received_j.date_sent) & \n",
    "                                                  (follows_received_j.date_sent<= x + \n",
    "                                                   datetime.timedelta(days=days_delta))\n",
    "                                                 ].values,\n",
    "                fan_follows)\n",
    "        ))                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17e2ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "expec_followers['user_type'] = expec_followers.fan_id.apply(lambda x: 'f_a' if x in f_a_ids else \n",
    "                          ('Hermit' if x in hermit_ids else\n",
    "                          ('Observer' if x in observer_ids else\n",
    "                          ('w_a' if x in w_a_ids else 'other'))))\n",
    "\n",
    "## classify content creators\n",
    "\n",
    "expec_followers['creator_type'] = expec_followers.user_id.apply(\n",
    "                                            lambda x: 'successful' if x in successful_ids else \n",
    "                                            ('unsuccessful' if x in unsuccessful_ids else 'other'))\n",
    "attempts = expec_followers.groupby(['creator_type', 'user_type'], as_index = False).size()\n",
    "desc = expec_followers.groupby(['creator_type', 'user_type'], as_index = False).agg(expected_followers=('expec_followers', 'mean'),\n",
    "                               std_expected_followers=('expec_followers', 'std'),\n",
    "                               max_followers=('expec_followers', 'max'))\n",
    "\n",
    "expect_return = attempts.merge(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d645d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "reposts_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d67414",
   "metadata": {},
   "outputs": [],
   "source": [
    "priori_act_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac9aeb4",
   "metadata": {},
   "source": [
    "# All activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af5d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now using all activities\n",
    "user_activity_data_35k['day_yr_date'] = user_activity_data_35k.date_sent.dt.normalize()\n",
    "\n",
    "activities_df = user_activity_data_35k.loc[user_activity_data_35k.outbound_activity.isin(['share', 'comment', 'like'])]\n",
    "\n",
    "act_prob_df = actions_sent.copy()\n",
    "act_prob_df.sort_values(['user_id', 'fan_id'], inplace = True)\n",
    "act_prob_df['reward_repost'] = np.nan\n",
    "for user_id in tqdm(act_prob_df.user_id.unique()):\n",
    "    for fan_id in act_prob_df.loc[act_prob_df.user_id == user_id].fan_id.unique():\n",
    "        act_prob_df.loc[(act_prob_df.user_id == user_id)&\n",
    "                              (act_prob_df.fan_id == fan_id),'reward_repost'] =\\\n",
    "        act_prob_df.loc[(act_prob_df.user_id == user_id)&\n",
    "                              (act_prob_df.fan_id == fan_id)].date_sent.apply(\n",
    "        lambda x : 1 if \n",
    "    (activities_df.loc[\n",
    "    (activities_df.user_id == user_id)&\n",
    "    (activities_df.fan_id == fan_id)&\n",
    "    (activities_df.day_yr_date > x)&   \n",
    "    (activities_df.day_yr_date <= x + datetime.timedelta(days=days_delta))]).shape[0]>0 else 0)\n",
    "                                          \n",
    "act_prob_df.sort_values(by='date_sent', inplace = True)\n",
    "\n",
    "attempts = act_prob_df.groupby(['creator_type', 'user_type'], as_index = False).size()\n",
    "rewards = act_prob_df.groupby(['creator_type', 'user_type'], as_index = False).agg({'reward_repost' : 'sum'})\n",
    " \n",
    "priori_act_df = rewards.merge(attempts)\n",
    "priori_act_df['P_rep_prob'] = priori_act_df['reward_repost']/priori_act_df['size']\n",
    "priori_act_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c08bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "expec_followers2 = user_activity_data_35k.loc[user_activity_data_35k.outbound_activity.isin(['share', 'comment', 'like'])]\n",
    "expec_followers2 = expec_followers2.loc[expec_followers2.user_id.isin(creators.user_id)]\n",
    "follower_list = action_follower_lists\n",
    "\n",
    "expec_followers2 = expec_followers2.loc[expec_followers2.fan_id.isin(follower_lists.index.unique())]\n",
    "expec_followers2['expec_followers'] = np.nan\n",
    "expec_followers2.sort_values(['user_id', 'fan_id'], inplace = True)\n",
    "\n",
    "for user_id in tqdm(expec_followers2.user_id.unique()):\n",
    "    follows_received_j = follows_received.loc[follows_received.user_id == user_id]\n",
    "    for fan_id in expec_followers2.loc[expec_followers2.user_id == user_id].fan_id.unique():\n",
    "        fan_follows = follower_lists.loc[follower_lists.index == fan_id].values[0]\n",
    "        expec_followers2.loc[(expec_followers2.user_id == user_id)&\n",
    "                                  (expec_followers2.fan_id == fan_id),'expec_followers'] =\\\n",
    "        expec_followers2.loc[(expec_followers2.user_id == user_id)&\n",
    "                                  (expec_followers2.fan_id == fan_id)].date_sent.apply(\n",
    "            lambda x : \n",
    "            np.sum(np.in1d(\n",
    "                           follows_received_j.loc[(x <= follows_received_j.date_sent) & \n",
    "                                                  (follows_received_j.date_sent<= x + \n",
    "                                                   datetime.timedelta(days=days_delta))\n",
    "                                                 ].values,\n",
    "                fan_follows)\n",
    "        ))                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cfd7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "expec_followers2['user_type'] = expec_followers2.fan_id.apply(lambda x: 'f_a' if x in f_a_ids else \n",
    "                          ('Hermit' if x in hermit_ids else\n",
    "                          ('Observer' if x in observer_ids else\n",
    "                          ('w_a' if x in w_a_ids else 'other'))))\n",
    "\n",
    "## classify content creators\n",
    "\n",
    "expec_followers2['creator_type'] = expec_followers2.user_id.apply(\n",
    "                                            lambda x: 'successful' if x in successful_ids else \n",
    "                                            ('unsuccessful' if x in unsuccessful_ids else 'other'))\n",
    "attempts = expec_followers2.groupby(['creator_type', 'user_type'], as_index = False).size()\n",
    "desc = expec_followers2.groupby(['creator_type', 'user_type'], as_index = False).agg(expected_followers=('expec_followers', 'mean'),\n",
    "                               std_expected_followers=('expec_followers', 'std'),\n",
    "                               max_followers=('expec_followers', 'max'))\n",
    "\n",
    "expect_return2 = attempts.merge(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472c9151",
   "metadata": {},
   "outputs": [],
   "source": [
    "expect_return2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047b1d64",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535841a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_table = priori_prob_df[['creator_type', 'user_type', 'P_resp_prob']].\\\n",
    "merge(priori_rep_df[['creator_type', 'user_type', 'P_rep_prob']]).\\\n",
    "merge(expect_return[['creator_type', 'user_type', 'expected_followers']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083af3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_table['Expected_direct_return'] = returns_table['P_resp_prob']\n",
    "returns_table['Expected_indirect_return'] = returns_table['P_rep_prob']*returns_table['expected_followers']\n",
    "returns_table['Total_expected_return'] = returns_table['Expected_direct_return'] + returns_table['Expected_indirect_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aaf691",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_table[['creator_type', 'user_type', 'P_resp_prob', 'P_rep_prob',\n",
    "       'expected_followers',\n",
    "       'Expected_direct_return', 'Expected_indirect_return',\n",
    "       'Total_expected_return']].loc[(returns_table.creator_type == 'successful')] #& (returns_table.user_type.isin(['Hermit', 'f_a']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb25b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg outbound activities from successful creators to the same user\n",
    "mask = actions_sent.creator_type == 'successful'\n",
    "size = actions_sent.loc[mask].groupby(['user_id', 'fan_id','user_type'], as_index = False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d768cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "size.groupby('user_type')['size'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43386e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Response (Follow-Back) Probabilities\n",
    "df = priori_prob_df\n",
    "\n",
    "pivoted_df = round(df.pivot(index='creator_type', columns='user_type', values=['P_resp_prob'])*100,3)\n",
    "\n",
    "# Display the pivoted DataFrame\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d753e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Response (Follow-Back) Probabilities\n",
    "df = priori_rep_df\n",
    "\n",
    "pivoted_df = round(df.pivot(index='creator_type', columns='user_type', values=['P_rep_prob'])*100,2)\n",
    "\n",
    "# Display the pivoted DataFrame\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6fc2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Response (Follow-Back) Probabilities\n",
    "df = expect_return\n",
    "\n",
    "pivoted_df = round(df.pivot(index='creator_type', columns='user_type', values=['expected_followers']),2)\n",
    "\n",
    "# Display the pivoted DataFrame\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e691a5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Response (Follow-Back) Probabilities\n",
    "df = expect_return\n",
    "\n",
    "pivoted_df = round(df.pivot(index='creator_type', columns='user_type', values=['std_expected_followers']),2)\n",
    "\n",
    "# Display the pivoted DataFrame\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52664f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = returns_table\n",
    "\n",
    "pivoted_df = round(df.pivot(index='creator_type', columns='user_type', values=['Total_expected_return']),4)\n",
    "\n",
    "# Display the pivoted DataFrame\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f473c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = returns_table\n",
    "\n",
    "pivoted_df = round(df.pivot(index='creator_type', columns='user_type', values=['Expected_indirect_return']),4)\n",
    "\n",
    "# Display the pivoted DataFrame\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10def744",
   "metadata": {},
   "outputs": [],
   "source": [
    "make a table wit all rewards: follows, reposts and # of followers. I think I can simply join the tables that I already havefrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50951799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#table non fans\n",
    "\n",
    "response_df.merge(reposts_df).merge(expec_followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb584302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#table fans\n",
    "\n",
    "reposts_df.merge(expec_followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a89417",
   "metadata": {},
   "outputs": [],
   "source": [
    "repost_avg_df.reward_repost.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8aea7f",
   "metadata": {},
   "source": [
    "# Second One Pager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f6934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Response (Follow-Back) Probabilities\n",
    "df = priori_act_df\n",
    "\n",
    "pivoted_df = round(df.pivot(index='creator_type', columns='user_type', values=['P_rep_prob'])*100,2)\n",
    "\n",
    "# Display the pivoted DataFrame\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f8745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Response (Follow-Back) Probabilities\n",
    "df = expect_return2\n",
    "\n",
    "pivoted_df = round(df.pivot(index='creator_type', columns='user_type', values=['expected_followers']),2)\n",
    "\n",
    "# Display the pivoted DataFrame\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ee505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Response (Follow-Back) Probabilities\n",
    "df = expect_return2\n",
    "\n",
    "pivoted_df = round(df.pivot(index='creator_type', columns='user_type', values=['std_expected_followers']),2)\n",
    "\n",
    "# Display the pivoted DataFrame\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa171a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_table2 = priori_prob_df[['creator_type', 'user_type', 'P_resp_prob']].\\\n",
    "merge(priori_act_df[['creator_type', 'user_type', 'P_rep_prob']]).\\\n",
    "merge(expect_return2[['creator_type', 'user_type', 'expected_followers']])\n",
    "\n",
    "returns_table2['Expected_direct_return'] = returns_table2['P_resp_prob']\n",
    "returns_table2['Expected_indirect_return'] = returns_table2['P_rep_prob']*returns_table2['expected_followers']\n",
    "returns_table2['Total_expected_return'] = returns_table2['Expected_direct_return'] + returns_table2['Expected_indirect_return']\n",
    "\n",
    "returns_table2[['creator_type', 'user_type', 'P_resp_prob', 'P_rep_prob',\n",
    "       'expected_followers',\n",
    "       'Expected_direct_return', 'Expected_indirect_return',\n",
    "       'Total_expected_return']].loc[(returns_table2.creator_type == 'successful')] #& (returns_table.user_type.isin(['Hermit', 'f_a']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1d23e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = returns_table2\n",
    "\n",
    "pivoted_df = round(df.pivot(index='creator_type', columns='user_type', values=['Total_expected_return']),4)\n",
    "\n",
    "# Display the pivoted DataFrame\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb8bf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = returns_table2\n",
    "\n",
    "pivoted_df = round(df.pivot(index='creator_type', columns='user_type', values=['Expected_indirect_return']),4)\n",
    "\n",
    "# Display the pivoted DataFrame\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b4c201",
   "metadata": {},
   "source": [
    "# Multiarmed Bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4765b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create database with direct and indirect rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a0a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAB dataframe\n",
    "follower_lists = action_follower_lists\n",
    "dataframe = actions_sent.copy()\n",
    "dataframe = dataframe.loc[dataframe.fan_id.isin(follower_lists.index.unique())]\n",
    "\n",
    "import datetime\n",
    "# Target Creation\n",
    "delta = datetime.timedelta(days = days_delta)\n",
    "mask = (actions_sent['date_sent']<= actions_sent['follower_since']) & (actions_sent['follower_since'] <= (actions_sent['date_sent'] + delta))\n",
    "\n",
    "dataframe = actions_sent\n",
    "dataframe.loc[mask, 'reward'] = 1\n",
    "mask = dataframe['reward'].isnull()\n",
    "dataframe.loc[mask, 'reward'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc52aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = activities_df.copy()\n",
    "activities.reset_index(inplace = True)\n",
    "activities.columns = ['activity_id', 'fan_id', 'user_id', 'date_returned', 'outbound_activity_returned', 'day_yr_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213a886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "merged_df = pd.merge(dataframe, activities[['activity_id', 'user_id', 'fan_id', 'date_returned', 'outbound_activity_returned']]\n",
    "                , left_on=['user_id', 'fan_id'], right_on=['user_id', 'fan_id'], how = 'left')\n",
    "\n",
    "# Calculate the time difference between dates\n",
    "merged_df['Date_Diff'] = merged_df['date_returned'] - merged_df['date_sent']\n",
    "\n",
    "# Drop negative Date_Diff\n",
    "\n",
    "merged_df = merged_df[(merged_df['Date_Diff'] > timedelta(minutes=0))| merged_df['Date_Diff'].isna()]\n",
    "\n",
    "# Sort the merged DataFrame by time difference\n",
    "merged_df.sort_values(by=['user_id', 'fan_id', 'Date_Diff'], inplace=True)\n",
    "\n",
    "# Keep only the closest match for each unique combination\n",
    "merged_df.drop_duplicates(subset=['user_id', 'fan_id', 'Date_Diff'], keep='first', inplace=True)\n",
    "\n",
    "merged_df = merged_df[(merged_df['Date_Diff'] < timedelta(days=7))|(merged_df['Date_Diff'].isna())]\n",
    "\n",
    "merged_df['activity_reward'] = (merged_df['Date_Diff'].isna() == False)*1.0\n",
    "\n",
    "merged_df = merged_df.merge(expec_followers2[['user_id', 'fan_id', 'date_sent', 'expec_followers']], \n",
    "                left_on = ['user_id', 'fan_id', 'date_returned'], \n",
    "                right_on = ['user_id', 'fan_id', 'date_sent'], \n",
    "                how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0f319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "expec_followers2.user_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e562e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.loc[(merged_df.date_sent_y.isna() == False)&(merged_df.user_type.isin(['Hermit','f_a']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbd6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.loc[merged_df.expec_followers.isna()== True, 'expec_followers'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a697e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.loc[merged_df['user_type'].isin(['Hermit', 'f_a'])]\n",
    "user_len = merged_df.groupby(['user_id']).user_type.apply(set).apply(lambda x: len(x))\n",
    "\n",
    "merged_df = merged_df.loc[merged_df.user_id.isin(user_len.loc[user_len>1].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600955d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiArmedBandits:\n",
    "    \n",
    "    def __init__(self, arm_names, user_id, data):\n",
    "        self.user_id = user_id\n",
    "        self.arm_names = arm_names\n",
    "        self.arms = {k:{'Sent':0,'Reward':0} for k in arm_names}\n",
    "        self.means = np.array(len(arm_names))\n",
    "        self.variances = np.array(len(arm_names))\n",
    "        self.total_trials = 0 \n",
    "        self.rewards = 0\n",
    "        self.data = data.loc[data.user_id == user_id]\n",
    "        self.next_arm_pull = None\n",
    "        self.N = self.data.shape[0]\n",
    "        self.direct_return = 0\n",
    "        self.indirect_return = 0\n",
    "    \n",
    "    def choose_arm(self):\n",
    "        '''sample from a beta based on self.arms'''\n",
    "        stats = {k:np.random.beta(self.arms[k]['Reward']+1, self.arms[k]['Sent']+1) for k in self.arms}\n",
    "        self.next_arm_pull = max(stats, key=stats.get)\n",
    "    \n",
    "    def sample_reward(self):\n",
    "        '''filter data based on arm and sample a random row'''\n",
    "        i = np.random.randint(len(self.data.loc[self.data.user_type == self.next_arm_pull]))\n",
    "        self.direct_return += self.data.loc[self.data.user_type == self.next_arm_pull].iloc[i]['reward'] \n",
    "        self.indirect_return += self.data.loc[self.data.user_type == self.next_arm_pull].iloc[i]['expec_followers']\n",
    "        return self.data.loc[self.data.user_type == self.next_arm_pull].iloc[i]['reward']\n",
    " \n",
    "    def update_arms(self):\n",
    "        self.arms[self.next_arm_pull]['Sent'] += 1\n",
    "        self.arms[self.next_arm_pull]['Reward'] += self.sample_reward()\n",
    "                \n",
    "    def estimate_moments(self):\n",
    "        Sent = np.array([a[1]['Sent'] for a in self.arms.items()])\n",
    "        Reward = np.array([a[1]['Reward'] for a in self.arms.items()])\n",
    "        \n",
    "        alpha = Reward + 1 \n",
    "        beta = (Sent-Reward)+1\n",
    "\n",
    "        mean = alpha/(alpha+beta)\n",
    "        variance = (alpha*beta)/((alpha+beta+1)*((alpha+beta)**2))\n",
    "        \n",
    "        self.means = np.transpose(np.around(mean,3))\n",
    "        self.variances = np.transpose(np.around(np.sqrt(variance),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b0236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "for user_id in tqdm(response_df.user_id.unique()):\n",
    "    d[user_id] = MultiArmedBandits(['Hermit', 'f_a'], user_id, merged_df)\n",
    "    for _ in range(d[user_id].N):\n",
    "        d[user_id].choose_arm()\n",
    "        d[user_id].update_arms()\n",
    "    d[user_id].estimate_moments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398da291",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13278ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity_data_35k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf66979",
   "metadata": {},
   "outputs": [],
   "source": [
    "expec_followers2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74afe71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "share_follower_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf77617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
