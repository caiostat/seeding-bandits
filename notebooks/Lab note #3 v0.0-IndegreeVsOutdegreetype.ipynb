{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7de64a06",
   "metadata": {},
   "source": [
    "**This notebook is the executable version of lab note 3.\n",
    "It answers the following questions:**\n",
    "\n",
    "Finally, we answer 4 items:\n",
    "\n",
    "    1. Are successful creators more connected to high-outdegree users than do unsuccessful creators?\n",
    "    2. Are mavens more connected to successful creators than to unsuccessful creators?\n",
    "    3. Do successful creators send more non-follow actions towards mavens than to zombies?\n",
    "    4. Do successful creators send more non-follow actions towards mavens than to stars?\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f459c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run parameters\n",
    "#used to control every run. Can be user to perfom sensitivity checks\n",
    "path_dir = r\"/Users/../Volumes/Raw/\"\n",
    "\n",
    "low_success = 0.5 #below the median: unsuccessful\n",
    "high_success = 0.9 #top 10% creators with more followers are deemed successful\n",
    "\n",
    "low_user_outdegree = 0.4 \n",
    "high_user_outdegree = 0.6 \n",
    "\n",
    "low_user_activity = 0.4 \n",
    "high_user_activity = 0.6 \n",
    "\n",
    "low_user_indegree = 0.4\n",
    "high_user_indegree = 0.6\n",
    "\n",
    "activity_filter = 10\n",
    "days_filter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a758ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "import pickle\n",
    "sys.path.insert(0, '/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/')\n",
    "import numpy as np\n",
    "import src.utils\n",
    "from collections import Counter\n",
    "from src.utils import import_dta, import_tracks_dta,\\\n",
    "gen_active_relations, get_fan_interactions_per_week, calculate_avg_monthly_valence,\\\n",
    "gen_active_relations_prob, get_fan_interactions_per_week_prob, stripplot_prob,\\\n",
    "reaction_probability, follower_list, filter_quantile, sample_creators_music,\\\n",
    "gen_outbound_creators\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy\n",
    "import os\n",
    "from statsmodels.stats.proportion import proportions_ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2d1bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date(date):\n",
    "    '''convert date format like '2013-w09' to '2013-03-04', i.e. the first day of that week'''\n",
    "    year = date[0:4]\n",
    "    week = date[6:]\n",
    "    day = \"1\"\n",
    "    date = \"{}-{}-1\".format(year, week)\n",
    "    dt = datetime.datetime.strptime(date, \"%Y-%W-%w\")\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f8fad",
   "metadata": {},
   "source": [
    "# Data Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2605f798",
   "metadata": {},
   "source": [
    "We start by importing the raw data.  `follows_sent`, `comments_sent`, `shares_sent`, `likes_sent` and `messages_sent` contains data pn the promotional activities that the 35k users tracked in the dataset directed to other users. It includes the `user_id`, the `fan_id` and the `date_sent` which identifies the date when the prom. activity was sent. `users_info_1st` shows the type of user (creator or non-creator, which is identified by a blank) and the date the user entered the platform, for every user that sent or received prom. activities from any of the 35k users tracked in this dataset, while `users_info` contains the same information, but pertaining to the 35k users themselves.\n",
    "\n",
    "`follows_received` contains information on the follows received by the 35k users and will be used to generate the successful/unsuccessful groups of content creators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03f61585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%% 12sample_tracks.dta %%%%%%%%%%\n",
      "(56262, 7)\n",
      "%%%%%%%%%% 12sample_affiliations_sent.dta %%%%%%%%%%\n",
      "(800913, 3)\n",
      "%%%%%%%%%% 12sample_comments_made.dta %%%%%%%%%%\n",
      "(29258, 4)\n",
      "%%%%%%%%%% 12sample_reposts_made.dta %%%%%%%%%%\n",
      "(179329, 4)\n",
      "%%%%%%%%%% 12sample_favoritings_made.dta %%%%%%%%%%\n",
      "(527701, 4)\n",
      "%%%%%%%%%% 12sample_messages_sent.dta %%%%%%%%%%\n",
      "(11091, 3)\n",
      "%%%%%%%%%% 12sample_1st_deg_user_infos.dta %%%%%%%%%%\n",
      "(670746, 3)\n",
      "%%%%%%%%%% 12sample_user_infos.dta %%%%%%%%%%\n",
      "(35000, 3)\n",
      "%%%%%%%%%% 12sample_affiliations_received.dta %%%%%%%%%%\n",
      "(432503, 3)\n"
     ]
    }
   ],
   "source": [
    "#affiliations :follows\n",
    "#favoritings :likes\n",
    "\n",
    "#used in filtering:\n",
    "path_dir = r\"/Users/../Volumes/Raw/\"\n",
    "tracks = import_tracks_dta(path_dir, \"12sample_tracks.dta\");\n",
    "\n",
    "#these are the actions sent to \n",
    "follows_sent = import_dta(path_dir, \"12sample_affiliations_sent.dta\");\n",
    "comments_sent = import_dta(path_dir, \"12sample_comments_made.dta\");\n",
    "shares_sent = import_dta(path_dir, \"12sample_reposts_made.dta\");\n",
    "likes_sent = import_dta(path_dir, \"12sample_favoritings_made.dta\");\n",
    "messages_sent = import_dta(path_dir, \"12sample_messages_sent.dta\");\n",
    "\n",
    "#Used to track information on the 1st degree connections\n",
    "user_info_1st = import_dta(path_dir, \"12sample_1st_deg_user_infos.dta\");\n",
    "user_info_1st.columns = ['user_id', 'type', 'entered_platform'];\n",
    "user_info = import_dta(path_dir, \"12sample_user_infos.dta\");\n",
    "\n",
    "#Used to compute creator's success measure\n",
    "follows_received = import_dta(path_dir, \"12sample_affiliations_received.dta\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35300c65",
   "metadata": {},
   "source": [
    "Indegree and outdegree information.\n",
    "\n",
    "The function below import the outdegree dataset. Because the raw version of those dataset are too large to be processed in memory, we preprocessed them in a separate script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cca037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregates preprocessed outdegree of 1st degree users\n",
    "def import_outdegree(path='/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/'):\n",
    "    d = {}\n",
    "    for i in range(6):\n",
    "       d[str(i)] = pd.read_pickle(os.path.join(path,'{}.pkl'.format(i))) \n",
    "       d[str(i)]['created_at'] =  pd.to_datetime(d[str(i)]['created_at'])\n",
    "       d[str(i)]['created_at'] = pd.to_datetime(d[str(i)]['created_at']).dt.floor('d')\n",
    "       d[str(i)] = d[str(i)].groupby(['sender_id', 'created_at'], as_index = False).size() \n",
    "    \n",
    "    data_outdegree = pd.concat([d['0'], d['1'], d['2'], d['3'], d['4'], d['5']])\n",
    "    #data_outdegree.set_index('created_at', inplace = True)\n",
    "    return data_outdegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc63f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the preprocessed indegree data.\n",
    "# the data was previously split in 9 pickeld pd.dataframes for memory reasons\n",
    "def import_indegree_dask(path='/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/indegree/'):\n",
    "    df = pd.read_pickle('{}df0.pkl'.format(path))\n",
    "    df1 = pd.read_pickle('{}df1.pkl'.format(path))\n",
    "    df2 = pd.read_pickle('{}df2.pkl'.format(path))\n",
    "    df3 = pd.read_pickle('{}df3.pkl'.format(path))\n",
    "    df4 = pd.read_pickle('{}df4.pkl'.format(path))\n",
    "    df5 = pd.read_pickle('{}df5.pkl'.format(path))\n",
    "    df6 = pd.read_pickle('{}df6.pkl'.format(path))\n",
    "    df7 = pd.read_pickle('{}df7.pkl'.format(path))\n",
    "    df8 = pd.read_pickle('{}df8.pkl'.format(path))\n",
    "    df9 = pd.read_pickle('{}df9.pkl'.format(path))\n",
    "     \n",
    "    #convert pd.dataframe to dask.dataframe, which better suits big data.\n",
    "    ddf = dd.from_pandas(df, npartitions = 3)\n",
    "    ddf1 = dd.from_pandas(df1, npartitions = 3)\n",
    "    ddf2 = dd.from_pandas(df2, npartitions = 3)\n",
    "    ddf3 = dd.from_pandas(df3, npartitions = 3)\n",
    "    ddf4 = dd.from_pandas(df4, npartitions = 3)\n",
    "    ddf5 = dd.from_pandas(df5, npartitions = 3)\n",
    "    ddf6 = dd.from_pandas(df6, npartitions = 3)\n",
    "    ddf7 = dd.from_pandas(df7, npartitions = 3)\n",
    "    ddf8 = dd.from_pandas(df8, npartitions = 3)\n",
    "    ddf9 = dd.from_pandas(df9, npartitions = 3)\n",
    "    \n",
    "    concatdf = dd.multi.concat([ddf,ddf1,ddf2,ddf3,ddf4,ddf5,ddf6,ddf7,ddf8,ddf9])\n",
    "    \n",
    "    return concatdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e03d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outdegree = import_outdegree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed0a2e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_indegree = import_indegree_dask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f46e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_indegree = data_indegree.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb3d51",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a358956e",
   "metadata": {},
   "source": [
    "## Creator ids, successful and unsucessful creators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb7bc74",
   "metadata": {},
   "source": [
    "Next, we define three lists of ids: one with the ids from the content creators, according to the `users_info` table, one with the ids of successful creators and the last one with the ids of the unsuccessful ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77715356",
   "metadata": {},
   "source": [
    "Let's start with a list of the id of creators. We also create a dataset with containing information on creators only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd634fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (tracks.track_available == 1) & (tracks.public == 't')\n",
    "creator_ids = tracks[mask].user_id.unique()\n",
    "\n",
    "creators = tracks[(tracks.track_available == 1) & (tracks.public == 't')]\n",
    "\n",
    "#mask = user_info.type == 'creator'\n",
    "#creator_ids = user_info[mask].user_id.unique()\n",
    "\n",
    "#creators = user_info[user_info.type == 'creator']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b06476a",
   "metadata": {},
   "source": [
    "## Putting together a dataset with the promotional activities made by content creators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b8a09",
   "metadata": {},
   "source": [
    "The function `gen_actions_sent_df` creates a dataframe with all the promotional activities that content creators sent to users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fff0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_actions_sent_df(follows_sent, shares_sent, likes_sent, comments_sent, messages_sent, creator_ids = creator_ids):\n",
    "    '''\n",
    "    Creates dataframe containing the actions that content creators send to users.\n",
    "        Attributes:\n",
    "                    follows_sent:  dataframe with the follows sent by the 35k users.\n",
    "                    shares_sent:   dataframe with the shares sent by the 35k users.\n",
    "                    likes_sent:    dataframe with the likes sent by the 35k users.\n",
    "                    comments_sent: dataframe with the comments sent by the 35k users.\n",
    "                    messages_sent: dataframe with the messages sent by the 35k users.\n",
    "                    creator_ids:   list with content creator ids. If not none, is used to\n",
    "                                   filter out activities from non creators.\n",
    "    '''\n",
    "    \n",
    "    follows_sent['outbound_activity'] = 'follow'\n",
    "    follows_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'song_id' in shares_sent.columns:\n",
    "        shares_sent.drop(columns=[\"song_id\"])\n",
    "    shares_sent = shares_sent[['reposter_id', \"owner_id\", 'created_at']]\n",
    "    shares_sent['outbound_activity'] = 'share'\n",
    "    shares_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'track_id' in likes_sent.columns:\n",
    "        likes_sent.drop(columns=[\"track_id\"], inplace=True)\n",
    "    likes_sent['outbound_activity'] = 'like'\n",
    "    likes_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'track_id' in comments_sent.columns:\n",
    "        comments_sent.drop(columns=[\"track_id\"], inplace=True)\n",
    "    comments_sent['outbound_activity'] = 'comment'\n",
    "    comments_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    messages_sent[\"outbound_activity\"] = 'message'\n",
    "    messages_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "    df = pd.concat([follows_sent, shares_sent, likes_sent, comments_sent, messages_sent])\n",
    "\n",
    "\n",
    "    if type(creator_ids) == numpy.ndarray:\n",
    "        df = df[df['user_id'].isin(creator_ids)]\n",
    "        \n",
    "    df['week_yr'] = df.date_sent.dt.strftime('%Y-w%U')\n",
    "    df = df.loc[df['user_id'] != df['fan_id'],:]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c6b8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_sent = gen_actions_sent_df(follows_sent, shares_sent, likes_sent, comments_sent,\n",
    "                                     messages_sent, creator_ids = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6462039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_users_ids = actions_sent.groupby('user_id', as_index = False).size()\n",
    "mask = active_users_ids['size']>= activity_filter\n",
    "active_users_ids = active_users_ids[mask].user_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d58e13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def successful_creators_followers(follows_received, base_date = datetime.datetime(2016, 5, 30, 0, 0), perc1 = None, perc2 = None, subset_creators = None):\n",
    "    '''Classifies content creators in successful or unsuccessfull\n",
    "        Arguments:\n",
    "                    follows_received: dataframe containing the follows received by content creators\n",
    "                    base date:        date, in datetime.datetime(YYYY, M, DD, H, M) format, in which the number \n",
    "                                      of followers per creator is calculated.\n",
    "                    perc1:            the threshold used to classify unsuccessful content creators. Creator having \n",
    "                                      total followers below the number dictated by this threshold, at the base date,\n",
    "                                      are classified as unsuccessful \n",
    "                    perc2:            the threshold used to classify successful content creators. Creator having \n",
    "                                      total followers above the number dictated by this threshold, at the base date,\n",
    "                                      are classified as successful\n",
    "                    subset_creators:  a pd.DataFrame containing the creators. If is it available, it will be used to \n",
    "                                      filter out non creators and to make sure creators with 0 followers are part of\n",
    "                                      the resulting dataset.\n",
    "        \n",
    "    '''\n",
    "    print(base_date)\n",
    "\n",
    "    if 'inbound_activity' not in follows_received.columns:\n",
    "        follows_received.columns = ['fan_id', 'user_id', 'date_sent']\n",
    "\n",
    "    mask = (follows_received['date_sent'] < base_date)\n",
    "\n",
    "    df = follows_received[mask].groupby('user_id', as_index=False).agg({'fan_id': pd.Series.nunique})\n",
    "    df.columns = ['user_id', 'followers']\n",
    "\n",
    "    \n",
    "    if type(subset_creators) == pd.DataFrame:\n",
    "        print('subsetting...')\n",
    "        df.set_index('user_id', inplace = True)\n",
    "        df = df.reindex(subset_creators.user_id.unique())\n",
    "        df.fillna(0, inplace = True)\n",
    "        df.reset_index(inplace = True)\n",
    "        df.columns = ['user_id', 'followers']\n",
    "        \n",
    "    mask = df.user_id.isin(active_users_ids)\n",
    "    df = df[mask]\n",
    "\n",
    "    low = np.quantile(df.followers, perc1)\n",
    "    high = np.quantile(df.followers, perc2)\n",
    "\n",
    "    print(\"High influencer boundary: {}\".format(high))\n",
    "    print(\"Low influencer boundary: {}\".format(low))\n",
    "\n",
    "    mask = (df[\"followers\"] <= low) | (df[\"followers\"] >= high)\n",
    "    \n",
    "    unsuccessful_creator_ids = df.loc[df[\"followers\"] <= low].user_id.unique()\n",
    "    successful_creator_ids = df.loc[df[\"followers\"] >= high].user_id.unique()\n",
    "\n",
    "    return unsuccessful_creator_ids, successful_creator_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ee655c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-30 00:00:00\n",
      "subsetting...\n",
      "High influencer boundary: 98.59999999999991\n",
      "Low influencer boundary: 19.0\n"
     ]
    }
   ],
   "source": [
    "unsuccessful_ids, successful_ids = successful_creators_followers(follows_received, \n",
    "                                                        perc1 = low_success, perc2 = high_success, subset_creators = creators)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6f8c4",
   "metadata": {},
   "source": [
    "## Filter only actions that were sent to non-fans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a67b459",
   "metadata": {},
   "source": [
    "We merge the `actions_sent` dataset with a table containing the date each fan started following the creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b904f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_received.columns = ['fan_id', 'user_id', 'date_sent']\n",
    "followers = follows_received[[\"fan_id\", \"user_id\", \"date_sent\"]]\n",
    "followers.columns = [\"fan_id\", \"user_id\", \"follower_since\"]\n",
    "\n",
    "actions_sent = actions_sent.merge(followers, right_on = ['user_id', 'fan_id'],\n",
    "                                      left_on = ['user_id', 'fan_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973ebc19",
   "metadata": {},
   "source": [
    "Since we are interested in acquisition campaings, we need to produce a dataset that exclude actions targetting fans.\n",
    "We do that using filters based on the date of the action and the date that the user became a fan of the content creator. The resulting dataframe is named `actions_sent_non_fans`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dbf162",
   "metadata": {},
   "source": [
    "We then filter only actions that happened before the user follows the content creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c957f00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/cgjzt69n5hlgmtsm36p1pztw0000gn/T/ipykernel_46508/3855957735.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  actions_sent_non_fans['week_yr_date'] = actions_sent_non_fans.week_yr.apply(lambda x: process_date(x))\n"
     ]
    }
   ],
   "source": [
    "mask = (actions_sent.date_sent < actions_sent.follower_since) | (actions_sent.follower_since.isnull())\n",
    "actions_sent_non_fans =  actions_sent[mask]\n",
    "actions_sent_non_fans['week_yr_date'] = actions_sent_non_fans.week_yr.apply(lambda x: process_date(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d9b9e",
   "metadata": {},
   "source": [
    "## Outdegree level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a61f1",
   "metadata": {},
   "source": [
    "Originally, we only have outdegree information on users that follow at least one user. The function below inputs an outdegree of 0 to users that are following anyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1083a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGE DOCUMENTATION\n",
    "def outdegree_level(data, date, user_info = user_info_1st):\n",
    "    \n",
    "    '''\n",
    "    This function returns the membership table at date equals `date`. Every user that interacted with the 35k tracked \n",
    "    users and entered the platform before `date` is present in the table, even if it has indegree 0.\n",
    "    arguments:\n",
    "              data:           the indegree dataset.\n",
    "              user_info:      the dataset containing all the users that interacted with the 35k users tracked.\n",
    "    '''\n",
    "    \n",
    "    data = data[data.created_at.dt.floor('d')<=date]\n",
    "    data = data.groupby('sender_id').agg({'size':'sum'}).compute()\n",
    "    \n",
    "    #merge with user info to obtain users that are not followed by anyone at the current date\n",
    "    data = user_info_1st.merge(data, left_on = 'user_id', right_on = 'sender_id', how= 'outer')\n",
    "    data.loc[data['size'].isnull(), 'size'] = 0\n",
    "    data = data[['user_id', 'size', 'entered_platform']].set_index('user_id')\n",
    "    \n",
    "    #filter out users that didnt exist in the current date\n",
    "    mask = data['entered_platform'].dt.floor('d') <= date\n",
    "    data = data.loc[mask]\n",
    "    \n",
    "    mask = (data['size']>0)\n",
    "    data.loc[~mask, 'size'] = 0 \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04d12134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGE DOCUMENTATION\n",
    "def indegree_level(data, date, user_info = user_info_1st):\n",
    "    \n",
    "    '''\n",
    "    This function returns the membership table at date equals `date`. Every user that interacted with the 35k tracked \n",
    "    users and entered the platform before `date` is present in the table, even if it has indegree 0.\n",
    "    arguments:\n",
    "              data:           the indegree dataset.\n",
    "              user_info:      the dataset containing all the users that interacted with the 35k users tracked.\n",
    "    '''\n",
    "    \n",
    "    data = data[data.created_at.dt.floor('d')<=date]\n",
    "    data = data.groupby('contact_id').agg({'size':'sum'}).compute()\n",
    "    \n",
    "    #merge with user info to obtain users that are not followed by anyone at the current date\n",
    "    data = user_info_1st.merge(data, left_on = 'user_id', right_on = 'contact_id', how= 'outer')\n",
    "    data.loc[data['size'].isnull(), 'size'] = 0\n",
    "    data = data[['user_id', 'size', 'entered_platform']].set_index('user_id')\n",
    "    \n",
    "    #filter out users that didnt exist in the current date\n",
    "    mask = data['entered_platform'].dt.floor('d') <= date\n",
    "    data = data.loc[mask]\n",
    "    \n",
    "    mask = (data['size']>0)\n",
    "    data.loc[~mask, 'size'] = 0 \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63a49e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dask is a python api with objects optimized for big data (user directed acyclic graphs). \n",
    "dask_outdegree = dd.from_pandas(data_outdegree, npartitions = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21950961",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_day =  max(actions_sent.date_sent.dt.floor('d').unique())\n",
    "user_outdegree = outdegree_level(dask_outdegree, last_day, user_info = user_info_1st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "690fc0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dask is a python api with objects optimized for big data (user directed acyclic graphs). \n",
    "dask_indegree = dd.from_pandas(data_indegree, npartitions = 3)\n",
    "user_indegree = indegree_level(dask_indegree, last_day, user_info = user_info_1st)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b5931",
   "metadata": {},
   "source": [
    "Now we classify the creator in successful and unsuccessful, according to the threshold defined in the beggining of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52d85729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_outdegree_level(oudegree_data, perc1 = None, perc2 = None):\n",
    "    '''Classifies content creators in successful or unsuccessfull\n",
    "        Arguments:\n",
    "                    oudegree_data:    dataframe containing the fans followers at \n",
    "                    perc1:            the threshold used to classify unsuccessful content creators. Creator having \n",
    "                                      total followers below the number dictated by this threshold, at the base date,\n",
    "                                      are classified as unsuccessful \n",
    "                    perc2:            the threshold used to classify successful content creators. Creator having \n",
    "                                      total followers above the number dictated by this threshold, at the base date,\n",
    "                                      are classified as successful\n",
    "    '''\n",
    "\n",
    "    df = oudegree_data.reset_index().iloc[:,:2]\n",
    "    df.columns = ['user_id', 'followers']\n",
    "\n",
    "    low = np.quantile(df.followers, perc1)\n",
    "    high = np.quantile(df.followers, perc2)\n",
    "\n",
    "    print(\"High outdegree boundary: {}\".format(high))\n",
    "    print(\"Low outdegree boundary: {}\".format(low))\n",
    "    \n",
    "    low_outdegree_ids = df.loc[df[\"followers\"] <= low].user_id.unique()\n",
    "    high_outdegree_ids = df.loc[df[\"followers\"] >= high].user_id.unique()\n",
    "    \n",
    "    \n",
    "    df['outdegree_level'] = df.user_id.apply(\n",
    "        lambda x: 'high' if x in high_outdegree_ids else ('low' if x in low_outdegree_ids else None))\n",
    "\n",
    "    \n",
    "    return df, low_outdegree_ids, high_outdegree_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87b4271a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High outdegree boundary: 75.0\n",
      "Low outdegree boundary: 46.0\n"
     ]
    }
   ],
   "source": [
    "user_outdegree_df, low_outdegree_ids, high_outdegree_ids = user_outdegree_level(user_outdegree,\n",
    "                perc1 = low_user_outdegree, perc2 = high_user_outdegree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "316225da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_indegree_level(indegree_data, perc1 = None, perc2 = None):\n",
    "    '''Classifies content creators in successful or unsuccessfull\n",
    "        Arguments:\n",
    "                    oudegree_data:    dataframe containing the fans followers at \n",
    "                    perc1:            the threshold used to classify unsuccessful content creators. Creator having \n",
    "                                      total followers below the number dictated by this threshold, at the base date,\n",
    "                                      are classified as unsuccessful \n",
    "                    perc2:            the threshold used to classify successful content creators. Creator having \n",
    "                                      total followers above the number dictated by this threshold, at the base date,\n",
    "                                      are classified as successful\n",
    "    '''\n",
    "\n",
    "    df = indegree_data.reset_index().iloc[:,:2]\n",
    "    df.columns = ['user_id', 'followers']\n",
    "\n",
    "    low = np.quantile(df.followers, perc1)\n",
    "    high = np.quantile(df.followers, perc2)\n",
    "\n",
    "    print(\"High indegree boundary: {}\".format(high))\n",
    "    print(\"Low indegree boundary: {}\".format(low))\n",
    "    \n",
    "    low_indegree_ids = df.loc[df[\"followers\"] <= low].user_id.unique()\n",
    "    high_indegree_ids = df.loc[df[\"followers\"] >= high].user_id.unique()\n",
    "    \n",
    "    \n",
    "    df['indegree_level'] = df.user_id.apply(\n",
    "        lambda x: 'high' if x in high_indegree_ids else ('low' if x in low_indegree_ids else None))\n",
    "\n",
    "    \n",
    "    return df, low_indegree_ids, high_indegree_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ad22239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High indegree boundary: 54.0\n",
      "Low indegree boundary: 23.0\n"
     ]
    }
   ],
   "source": [
    "user_indegree_df, low_indegree_ids, high_indegree_ids = user_indegree_level(user_indegree,\n",
    "                perc1 = low_user_indegree, perc2 = high_user_indegree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc7f983",
   "metadata": {},
   "source": [
    "In the cell below, we create a list with unique ids from users that appear in the oudegree level table. This will later be uses to construct a flow-chart indicating how we lose data based on filters and operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "406e4e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "receiver_ids = user_outdegree.index.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1faaf",
   "metadata": {},
   "source": [
    "## Non-follow Actions level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4db5e11",
   "metadata": {},
   "source": [
    "The activity level is defined as the number of actions performed by users. It is important to notice that we only observe actions targeting the 35k users that joined in march 2012. We consider this measure a proxy for the real activity level.\n",
    "\n",
    "Let's begin by creating a dataset with all action received by those 35k users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec0ad24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%% 12sample_1st_deg_comments_made.dta %%%%%%%%%%\n",
      "(21463011, 4)\n",
      "%%%%%%%%%% 12sample_1st_deg_reposts_made.dta %%%%%%%%%%\n",
      "(18953640, 4)\n"
     ]
    }
   ],
   "source": [
    "path_dir_2 = r'/Users/../Volumes/Alter_outbound_activities/'\n",
    "\n",
    "comments_received = import_dta(path_dir_2, \"12sample_1st_deg_comments_made.dta\");\n",
    "shares_received = import_dta(path_dir_2, \"12sample_1st_deg_reposts_made.dta\");\n",
    "likes_received = import_dta(path_dir_2, \"12sample_1st_deg_favoritings_made.dta\");\n",
    "messages_received = import_dta(path_dir_2, \"12sample_1st_deg_messages_sent.dta\");\n",
    "\n",
    "#comments_received = import_dta(path_dir, \"12sample_comments_received.dta\");\n",
    "#shares_received = import_dta(path_dir, \"12sample_reposts_received.dta\");\n",
    "#likes_received = import_dta(path_dir, \"12sample_favoritings_received.dta\");\n",
    "#messages_received = import_dta(path_dir, \"12sample_messages_received.dta\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec99f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'song_id' in shares_received:\n",
    "        shares_received.drop(columns=[\"song_id\"])\n",
    "shares_received = shares_received[['reposter_id', \"owner_id\", 'created_at']]\n",
    "shares_received['inbound_activity'] = 'share'\n",
    "shares_received.columns = ['fan_id', 'user_id', 'date_sent', 'inbound_activity']\n",
    "\n",
    "if 'track_id' in likes_received:\n",
    "        likes_received = likes_received.drop(columns=[\"track_id\"])\n",
    "likes_received['inbound_activity'] = 'like'\n",
    "likes_received.columns = ['fan_id', 'user_id', 'date_sent', 'inbound_activity']\n",
    "\n",
    "if 'track_id' in comments_received:\n",
    "        comments_received = comments_received.drop(columns=[\"track_id\"])\n",
    "comments_received['inbound_activity'] = 'comment'\n",
    "comments_received.columns = ['fan_id', 'user_id', 'date_sent', 'inbound_activity']\n",
    "\n",
    "messages_received[\"outbound_activity\"] = 'message'\n",
    "messages_received.columns = ['user_id', 'fan_id', 'date_sent', 'inbound_activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ce54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity_data = pd.concat([shares_received, likes_received, comments_received, messages_received])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_activity_level(user_activity_data, receiver_ids, perc1 = None, perc2 = None):\n",
    "    '''Classifies users based on the amount of non-follow activities\n",
    "        Arguments:\n",
    "                    user_activity_data:   dataframe containing the user activities \n",
    "                    base date:             date, in datetime.datetime(YYYY, M, DD, H, M) format, in which the number \n",
    "                                           of followers per creator is calculated.\n",
    "                    perc1:                 the threshold used to classify unsuccessful content creators. Creator having \n",
    "                                           total followers below the number dictated by this threshold, at the base date,\n",
    "                                           are classified as unsuccessful \n",
    "                    perc2:                 the threshold used to classify successful content creators. Creator having \n",
    "                                           total followers above the number dictated by this threshold, at the base date,\n",
    "                                           are classified as successful\n",
    "    '''\n",
    "\n",
    "    df = user_activity_data.groupby('fan_id', as_index = True).size()\n",
    "    df = df.reindex(receiver_ids)\n",
    "    print(df.shape)\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['user_id', 'activities_performed']\n",
    "    \n",
    "    df.loc[df.activities_performed.isna(), 'activities_performed'] = 0\n",
    "    #classification should happen after this\n",
    "\n",
    "    low = np.quantile(df.activities_performed, perc1)\n",
    "    high = np.quantile(df.activities_performed, perc2)\n",
    "\n",
    "    print(\"High activity boundary: {}\".format(high))\n",
    "    print(\"Low activity boundary: {}\".format(low))\n",
    "    \n",
    "    low_activity_ids = df.loc[df[\"activities_performed\"] <= low].user_id.unique()\n",
    "    high_activity_ids = df.loc[df[\"activities_performed\"] > high].user_id.unique()\n",
    "    \n",
    "    df['activity_level'] = df.user_id.apply(\n",
    "    lambda x: 'high' if x in high_activity_ids else ('low' if x in low_activity_ids else None))\n",
    "\n",
    "    return df, low_activity_ids, high_activity_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3367a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_level, low_activity_ids, high_activity_ids = user_activity_level(user_activity_data, receiver_ids, \n",
    "                perc1 = low_user_activity, perc2 = high_user_activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a392a41",
   "metadata": {},
   "source": [
    "Once more we create an object containing the unique ids of users in the resulting dataset. This will be used in a flow-chart, as explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972bf9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_ids = np.append(low_activity_ids, high_activity_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aec8b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(activity_ids).intersection(set(receiver_ids)))\n",
    "#only 35493 from 240292 that follow at least one of the 35k, performed at least one non-follow action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e70261",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc11bf9",
   "metadata": {},
   "source": [
    "Now we merge the datasets with the outdegree, and non-follow activities information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cd81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data = user_outdegree_df.merge(user_indegree_df, left_on = 'user_id', right_on = 'user_id', how = 'inner').merge(activity_level, left_on = 'user_id', right_on = 'user_id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb4428",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data.groupby(['outdegree_level', 'activity_level']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8574a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data.groupby(['outdegree_level', 'indegree_level']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2152784",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data.groupby(['indegree_level', 'activity_level']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67db0c26",
   "metadata": {},
   "source": [
    "And, finally, we create the 4 user groups that we are interested in: *Maven*, *Zombie*, *Stars* and *Stalker*. Everyone else is classified as *Other*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a44734",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data['Type'] = table_data.apply(lambda x: \n",
    "    'Maven' if (x.outdegree_level == 'low') & (x.indegree_level == 'high')\n",
    "     else ('Zombie' if (x.outdegree_level == 'low') & (x.indegree_level == 'low')\n",
    "     else ('Stalker' if (x.outdegree_level == 'high') & (x.indegree_level == 'low')\n",
    "     else ('Star' if (x.outdegree_level == 'high') & (x.indegree_level == 'high')\n",
    "     else 'other'))), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b308ef3e",
   "metadata": {},
   "source": [
    "Let's keep track of each user type's ids, as it gives us a compact way of identifying each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0657cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "zombie_ids = table_data.loc[table_data.Type =='Zombie'].user_id.unique()\n",
    "star_ids = table_data.loc[table_data.Type =='Star'].user_id.unique()\n",
    "maven_ids = table_data.loc[table_data.Type =='Maven'].user_id.unique()\n",
    "stalker_ids = table_data.loc[table_data.Type =='Stalker'].user_id.unique()\n",
    "\n",
    "actions_sent_non_fans['user_type'] = actions_sent_non_fans.fan_id.apply(lambda x: 'Maven' if x in maven_ids else \n",
    "                          ('Zombie' if x in zombie_ids else\n",
    "                          ('Stalker' if x in stalker_ids else\n",
    "                          ('Star' if x in star_ids else 'other'))))\n",
    "\n",
    "## classify content creators\n",
    "actions_sent_non_fans['creator_type'] = actions_sent_non_fans.user_id.apply(\n",
    "                                            lambda x: 'successful' if x in successful_ids else \n",
    "                                            ('unsuccessful' if x in unsuccessful_ids else 'other'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c45484",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data.Type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7edee0",
   "metadata": {},
   "source": [
    "## Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0742cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#incoming follows\n",
    "follows_sent.merge(table_data, left_on = 'fan_id', right_on = 'user_id', how = 'inner')\\\n",
    ".groupby('Type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837082a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outgoing follows\n",
    "follows_received.merge(table_data, left_on = 'fan_id', right_on = 'user_id', how = 'inner')\\\n",
    ".groupby('Type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca81b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#incoming nonfollow actions\n",
    "mask = actions_sent.outbound_activity != 'follow'\n",
    "incoming_non_follow = actions_sent[mask]\n",
    "incoming_non_follow.merge(table_data, left_on = 'fan_id', right_on = 'user_id', how = 'inner')\\\n",
    ".groupby('Type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22758e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outgoing nonfollow actions\n",
    "user_activity_data.merge(table_data, left_on = 'fan_id', right_on = 'user_id', how = 'inner')\\\n",
    ".groupby('Type').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d9a9b",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61797db7",
   "metadata": {},
   "source": [
    "Finally, we answer 4 items:\n",
    "\n",
    "    1. Are successful creators more connected to high-outdegree users than do unsuccessful creators?\n",
    "    2. Are mavens more connected to successful creators thanto unsuccessful creators?\n",
    "    3. Do successful creators send more non-follow actions towards mavens than to zombies?\n",
    "    4. Do successful creators send more non-follow actions towards mavens than to stars?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312b3cbd",
   "metadata": {},
   "source": [
    "## Desc. Statistics\n",
    "\n",
    "Let's start with 3, since if provide the figures we are going to use to answer to other items:\n",
    "\n",
    "### 3. Descriptive statistics of the four groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afab1bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data.groupby('Type', as_index = False).activities_performed.describe().unstack(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8662794",
   "metadata": {},
   "source": [
    "### 3.1. Are successful creators more connected to high-outdegree users than do unsuccessful creators?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb637937",
   "metadata": {},
   "source": [
    "We want to measure if successful creators are skilled in identifying *maven* and connecting to *high-outdegree and mavens*. Unfortunatelly,  we cannot use a probability measure to do the comparison, since it is sharply affected by group size variations. One measure that sidestep this issue is the odds ratio, a statistic that is better suited to compare groups of different sizes because it takes the number of events and non events in each group into account.\n",
    "\n",
    "To calculate the odds ratio of for a given user type, say *hardcore*, we need the probability that a *hardcore* user is targeted by a successful creator. That is obtained by the following ratio: `p_maven_users` = `total unique users of type maven target by successful creators`/`total unique users of type maven`. \n",
    "\n",
    "We then use it to calculate: `odds_maven_user` = `p_maven_users`/(1-`p_maven_users`)\n",
    "\n",
    "Finally, let's say we want to compare `maven` and `zombie` users. We would then use the meetric `odds_ratio` = `odds_maven_user`/`odds_zombie_user`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0065da9",
   "metadata": {},
   "source": [
    "We will also report the Confidence Intervals (95%) for the Odds Ratio. The function below automatizes that calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd14394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def calculate_odds_ratio_ci(exposed_cases, exposed_controls, nonexposed_cases, nonexposed_controls):\n",
    "    # Calculate the odds ratio (OR)\n",
    "    odds_ratio = (exposed_cases / exposed_controls) / (nonexposed_cases / nonexposed_controls)\n",
    "\n",
    "    # Calculate the 95% confidence interval (CI) for the OR\n",
    "    log_odds_ratio = np.log(odds_ratio)\n",
    "    std_error = np.sqrt(1/exposed_cases + 1/exposed_controls + 1/nonexposed_cases + 1/nonexposed_controls)\n",
    "    z_score = stats.norm.ppf(0.975)\n",
    "    lower_ci = np.exp(log_odds_ratio - z_score*std_error)\n",
    "    upper_ci = np.exp(log_odds_ratio + z_score*std_error)\n",
    "\n",
    "    return round(odds_ratio, 2), (round(lower_ci, 2), round(upper_ci, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547eaebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1799ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_received = follows_received.merge(user_info, left_on ='user_id', right_on = 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a98d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask =  follows_received.date_sent < follows_received.created_at + datetime.timedelta(days = days_filter)\n",
    "follows_received = follows_received[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9de56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data.drop(columns = ['followers_x'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1537b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data.columns = ['fan_id','outdegree_level', 'followers','indegree_level', 'activities_performed', 'activity_level', 'Type']\n",
    "table = follows_received.merge(table_data, left_on = 'fan_id', right_on = 'fan_id', how = 'inner') #suffixes\n",
    "\n",
    "table['creator_type'] = table.user_id.apply(\n",
    "                                            lambda x: 'successful' if x in successful_ids else \n",
    "                                            ('unsuccessful' if x in unsuccessful_ids else 'other'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d275ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "table1 = table.groupby(['creator_type','outdegree_level'], as_index = False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6db499",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_outdegree_ids = table[table.outdegree_level == 'high'].fan_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0db975",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (table1.outdegree_level == 'high') & (table1.creator_type == 'successful')\n",
    "g1 = table1.loc[mask]['size'].values[0]\n",
    "\n",
    "mask = (table1.outdegree_level == 'high') & (table1.creator_type == 'unsuccessful')\n",
    "g2 = table1.loc[mask]['size'].values[0]\n",
    "group_ids1 = table.loc[table.creator_type == 'successful']\n",
    "group_ids2 = table.loc[table.creator_type == 'unsuccessful']\n",
    "\n",
    "tab = np.array([[g1, g2], [len(group_ids1)-g1, len(group_ids2)-g2]])\n",
    "\n",
    "# calculate the odds ratio by taking the ratio of the odds of the event occurring in the two groups\n",
    "odds_ratio = (g1/(len(group_ids1)-g1)/(g2/(len(group_ids2)-g2)))\n",
    "print(\"Odds Ratio:\", round(odds_ratio,4))\n",
    "\n",
    "# perform a chi-square test to determine whether the observed odds ratio is statistically significant\n",
    "chi2, p_value, _, _ = chi2_contingency(tab)\n",
    "print(\"Chi-Square Statistic:\", round(chi2,4))\n",
    "print(\"P-Value:\", round(p_value,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7dab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_odds_ratio_ci(g1, g2, len(group_ids1)-g1, len(group_ids2)-g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9951eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g1)\n",
    "print(len(group_ids1)-g1)\n",
    "print(g2)\n",
    "print(len(group_ids2)-g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce81cb",
   "metadata": {},
   "source": [
    "### 3.2 Do successful creators connect to stars more than unsuccessful creators?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023bb390",
   "metadata": {},
   "outputs": [],
   "source": [
    "table1 = table.groupby(['creator_type','Type'], as_index = False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd22847",
   "metadata": {},
   "outputs": [],
   "source": [
    "table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d72ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (table1.Type == 'Stalker') & (table1.creator_type == 'successful')\n",
    "g1 = table1.loc[mask]['size'].values[0]\n",
    "\n",
    "mask = (table1.Type == 'Stalker') & (table1.creator_type == 'unsuccessful')\n",
    "g2 = table1.loc[mask]['size'].values[0]\n",
    "group_ids1 = table.loc[table.creator_type == 'successful']\n",
    "group_ids2 = table.loc[table.creator_type == 'unsuccessful']\n",
    "\n",
    "tab = np.array([[g1, g2], [len(group_ids1)-g1, len(group_ids2)-g2]])\n",
    "\n",
    "# calculate the odds ratio by taking the ratio of the odds of the event occurring in the two groups\n",
    "odds_ratio = (g1/(len(group_ids1)-g1)/(g2/(len(group_ids2)-g2)))\n",
    "print(\"Odds Ratio:\", round(odds_ratio,4))\n",
    "\n",
    "# perform a chi-square test to determine whether the observed odds ratio is statistically significant\n",
    "chi2, p_value, _, _ = chi2_contingency(tab)\n",
    "print(\"Chi-Square Statistic:\", round(chi2,4))\n",
    "print(\"P-Value:\", round(p_value,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca1ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_odds_ratio_ci(g1, g2, len(group_ids1)-g1, len(group_ids2)-g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67b041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g1)\n",
    "print(len(group_ids1)-g1)\n",
    "print(g2)\n",
    "print(len(group_ids2)-g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659a734e",
   "metadata": {},
   "source": [
    "###     3.3 Do successful creators target more Stars than Zombies with non-follow actions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14443d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#actions sentdata + mavens and zombie classification + successful/unsuccessful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d51f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_sent_non_fans = actions_sent_non_fans.merge(user_info, left_on = 'user_id', right_on = 'user_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c8f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = actions_sent_non_fans.date_sent < actions_sent_non_fans.created_at + datetime.timedelta(days = days_filter)\n",
    "actions_sent_non_fans = actions_sent_non_fans[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc369d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_target_user_type = actions_sent_non_fans.groupby(['creator_type', 'user_type']).fan_id.nunique()\n",
    "dist_target_user = distribution_target_user_type.to_frame().reset_index()\n",
    "dist_target_user.columns = ['creator_type', 'user_type', 'non_follow_actions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e97152",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_target_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (dist_target_user.user_type == 'Star') & (dist_target_user.creator_type == 'successful')\n",
    "g1 = dist_target_user.loc[mask].non_follow_actions.values[0]\n",
    "\n",
    "mask = (dist_target_user.user_type == 'Maven') & (dist_target_user.creator_type == 'successful')\n",
    "g2 = dist_target_user.loc[mask].non_follow_actions.values[0]\n",
    "\n",
    "group_ids1 = star_ids\n",
    "group_ids2 = maven_ids\n",
    "\n",
    "table = np.array([[g1, g2], [len(group_ids1)-g1, len(group_ids2)-g2]])\n",
    "\n",
    "# calculate the odds ratio by taking the ratio of the odds of the event occurring in the two groups\n",
    "odds_ratio = (g1/(len(group_ids1)-g1)/(g2/(len(group_ids2)-g2)))\n",
    "print(\"Odds Ratio:\", round(odds_ratio,4))\n",
    "\n",
    "# perform a chi-square test to determine whether the observed odds ratio is statistically significant\n",
    "chi2, p_value, _, _ = chi2_contingency(table)\n",
    "print(\"Chi-Square Statistic:\", round(chi2,4))\n",
    "print(\"P-Value:\", round(p_value,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac2f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(group_ids2)-g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d81e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_odds_ratio_ci(g1, g2, len(group_ids1)-g1, len(group_ids2)-g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf665bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g1)\n",
    "print(len(group_ids1)-g1)\n",
    "print(g2)\n",
    "print(len(group_ids2)-g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32d5b76",
   "metadata": {},
   "source": [
    "###     3.4 Do successful creators target more Stars than Stalkers with non-follow actions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e34e261",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (dist_target_user.user_type == 'Star') & (dist_target_user.creator_type == 'successful')\n",
    "g1 = dist_target_user.loc[mask].non_follow_actions.values[0]\n",
    "\n",
    "mask = (dist_target_user.user_type == 'Stalker') & (dist_target_user.creator_type == 'successful')\n",
    "g2 = dist_target_user.loc[mask].non_follow_actions.values[0]\n",
    "\n",
    "group_ids1 = star_ids\n",
    "group_ids2 = stalker_ids\n",
    "\n",
    "table = np.array([[g1, g2], [len(group_ids1)-g1, len(group_ids2)-g2]])\n",
    "\n",
    "# calculate the odds ratio by taking the ratio of the odds of the event occurring in the two groups\n",
    "odds_ratio = (g1/(len(group_ids1)-g1)/(g2/(len(group_ids2)-g2)))\n",
    "print(\"Odds Ratio:\", round(odds_ratio,4))\n",
    "\n",
    "# perform a chi-square test to determine whether the observed odds ratio is statistically significant\n",
    "chi2, p_value, _, _ = chi2_contingency(table)\n",
    "print(\"Chi-Square Statistic:\", round(chi2,4))\n",
    "print(\"P-Value:\", round(p_value,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2e5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_odds_ratio_ci(g1, g2, len(group_ids1)-g1, len(group_ids2)-g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f08d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g1)\n",
    "print(len(group_ids1)-g1)\n",
    "print(g2)\n",
    "print(len(group_ids2)-g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc63757c",
   "metadata": {},
   "source": [
    "## 5 Are creators better off (more likely to succeed) if they reach out/target mavens than stars?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de63d95",
   "metadata": {},
   "source": [
    "To answer question 5, we will fit a logistic regression. The goal is to predict if a creator becames succesfull based on the number of non-follow activities and follows sent, both in aggregate and per user type.\n",
    "\n",
    "Let's create the dataset to be used in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d554b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create target:\n",
    "#Per creator:\n",
    "#1 non-follow activities sent\n",
    "#2 follow activities sent\n",
    "#3 non-follow activities sent per user type\n",
    "#4 follow activities sent per user type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eaf057",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_sent_non_fans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d80ee45",
   "metadata": {},
   "source": [
    "model_df = pd.DataFrame(creator_ids, columns = ['creator_id'])\n",
    "model_df['successful'] = model_df.creator_id.apply(lambda x: 1 if x in successful_ids else 0)\n",
    "\n",
    "mask = (actions_sent_non_fans.outbound_activity != 'follow')\n",
    "\n",
    "total_non_follow_activities = actions_sent_non_fans[mask].groupby('user_id', as_index = False).size()\n",
    "total_non_follow_activities.columns = ['creator_id', 'total_non_follow_activities']\n",
    "\n",
    "Mavens_targeted_non_follow = actions_sent_non_fans[(mask)\n",
    "                & (actions_sent_non_fans.user_type == 'Maven')].groupby('user_id', as_index = False).size()\n",
    "Mavens_targeted_non_follow.columns = ['creator_id', 'Mavens_targeted_non_follow']\n",
    "\n",
    "Zombies_targeted_non_follow =  actions_sent_non_fans[(mask)\n",
    "                & (actions_sent_non_fans.user_type == 'Zombie')].groupby('user_id', as_index = False).size()\n",
    "Zombies_targeted_non_follow.columns = ['creator_id', 'Zombie_targeted_non_follow']\n",
    "\n",
    "\n",
    "Stars_targeted_non_follow =  actions_sent_non_fans[(mask)\n",
    "                & (actions_sent_non_fans.user_type == 'Star')].groupby('user_id', as_index = False).size()\n",
    "Stars_targeted_non_follow.columns = ['creator_id', 'Stars_targeted_non_follow']\n",
    "\n",
    "Stalkers_targeted_non_follow =  actions_sent_non_fans[(mask)\n",
    "                & (actions_sent_non_fans.user_type == 'Stalker')].groupby('user_id', as_index = False).size()\n",
    "Stalkers_targeted_non_follow.columns = ['creator_id', 'Stalker_targeted_non_follow']\n",
    "\n",
    "mask = (actions_sent_non_fans.outbound_activity == 'follow')\n",
    "model_df['total_follow_activities'] = model_df.creator_id.apply(lambda x: actions_sent_non_fans[mask].\\\n",
    "                                          loc[(mask) & (actions_sent_non_fans.user_id == x)].shape[0])\n",
    "\n",
    "Mavens_targeted_follow = actions_sent_non_fans[(mask)\n",
    "                & (actions_sent_non_fans.user_type == 'Maven')].groupby('user_id', as_index = False).size()\n",
    "Mavens_targeted_follow.columns = ['creator_id', 'Mavens_targeted_non_follow']\n",
    "\n",
    "Zombies_targeted_follow = actions_sent_non_fans[(mask)\n",
    "                & (actions_sent_non_fans.user_type == 'Zombie')].groupby('user_id', as_index = False).size()\n",
    "Zombies_targeted_follow.columns = ['creator_id', 'Zombie_targeted_non_follow']\n",
    "\n",
    "\n",
    "Stars_targeted_follow =  actions_sent_non_fans[(mask)\n",
    "                & (actions_sent_non_fans.user_type == 'Star')].groupby('user_id', as_index = False).size()\n",
    "Stars_targeted_non_follow.columns = ['creator_id', 'Stars_targeted_non_follow']\n",
    "\n",
    "Stalkers_targeted_follow = actions_sent_non_fans[(mask)\n",
    "                & (actions_sent_non_fans.user_type == 'Stalker')].groupby('user_id', as_index = False).size()\n",
    "Stalkers_targeted_follow.columns = ['creator_id', 'Stalker_targeted_non_follow']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85d596d",
   "metadata": {},
   "source": [
    "### 3.5.a: Is p(creator being successful | creator sent a follow to a maven) > p(creator being successful| creator sent a follow to a star)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdf859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p(A|B) = P(A&B)/P(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2abb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 create column: sent follow to maven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b395281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf = pd.DataFrame(creator_ids, columns = ['creator_id'])\n",
    "bdf['successful'] = bdf.creator_id.apply(lambda x: 1 if x in successful_ids else 0)\n",
    "\n",
    "mask = (actions_sent_non_fans.outbound_activity == 'follow')\n",
    "Mavens_targeted_follow = actions_sent_non_fans[(mask)\n",
    "                & (actions_sent_non_fans.user_type == 'Maven')].groupby('user_id', as_index = False).size()\n",
    "Mavens_targeted_follow.columns = ['creator_id', 'Mavens_targeted_follow']\n",
    "\n",
    "Stars_targeted_follow =  actions_sent_non_fans[(mask)\n",
    "                & (actions_sent_non_fans.user_type == 'Star')].groupby('user_id', as_index = False).size()\n",
    "Stars_targeted_follow.columns = ['creator_id', 'Stars_targeted_follow']\n",
    "\n",
    "Zombies_targeted_follow = actions_sent_non_fans[(mask)\n",
    "                & (actions_sent_non_fans.user_type == 'Zombie')].groupby('user_id', as_index = False).size()\n",
    "Zombies_targeted_follow.columns = ['creator_id', 'Zombies_targeted_follow']\n",
    "\n",
    "Stalkers_targeted_follow =  actions_sent_non_fans[(mask)\n",
    "                & (actions_sent_non_fans.user_type == 'Stalker')].groupby('user_id', as_index = False).size()\n",
    "Stalkers_targeted_follow.columns = ['creator_id', 'Stalkers_targeted_follow']\n",
    "\n",
    "bdf = bdf.merge(Mavens_targeted_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "bdf = bdf.fillna(0)\n",
    "bdf = bdf.merge(Stars_targeted_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "bdf = bdf.fillna(0)\n",
    "bdf = bdf.merge(Zombies_targeted_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "bdf = bdf.fillna(0)\n",
    "bdf = bdf.merge(Stalkers_targeted_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "bdf = bdf.fillna(0)\n",
    "\n",
    "bdf['followed_Maven'] = (bdf.Mavens_targeted_follow > 0)*1\n",
    "bdf['followed_Star'] = (bdf.Stars_targeted_follow > 0)*1\n",
    "bdf['followed_Zombie'] = (bdf.Zombies_targeted_follow > 0)*1\n",
    "bdf['followed_Stalker'] = (bdf.Stalkers_targeted_follow > 0)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb2aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.followed_Maven == 1)].shape[0]/bdf.shape[0]\n",
    "P_B = bdf.loc[(bdf.followed_Maven == 1)].shape[0]/bdf.shape[0]\n",
    "P_success_g_Maven = round(P_A_and_B/P_B,3)\n",
    "print('P(success|Maven): {}'.format(P_success_g_Maven))\n",
    "\n",
    "P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.followed_Star == 1)].shape[0]/bdf.shape[0]\n",
    "P_B = bdf.loc[(bdf.followed_Star == 1)].shape[0]/bdf.shape[0]\n",
    "P_success_g_Star = round(P_A_and_B/P_B,3)\n",
    "print('P(success|Star): {}'.format(P_success_g_Star))\n",
    "\n",
    "P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.followed_Zombie == 1)].shape[0]/bdf.shape[0]\n",
    "P_B = bdf.loc[(bdf.followed_Zombie == 1)].shape[0]/bdf.shape[0]\n",
    "P_success_g_Zombie = round(P_A_and_B/P_B,3)\n",
    "print('P(success|Zombie): {}'.format(P_success_g_Zombie))\n",
    "\n",
    "P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.followed_Stalker == 1)].shape[0]/bdf.shape[0]\n",
    "P_B = bdf.loc[(bdf.followed_Stalker == 1)].shape[0]/bdf.shape[0]\n",
    "P_success_g_Stalker = round(P_A_and_B/P_B,3)\n",
    "print('P(success|Stalker): {}'.format(P_success_g_Stalker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b728d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(A)\n",
    "#bdf.loc[(bdf.successful == 1)].shape[0]/bdf.shape[0]\n",
    "#P(B)\n",
    "#bdf.loc[(bdf.followed_Star == 1)].shape[0]/bdf.shape[0]\n",
    "#P(C)\n",
    "#bdf.loc[(bdf.followed_Stalker == 1)].shape[0]/bdf.shape[0]\n",
    "#P(A&B)\n",
    "bdf.loc[(bdf.successful == 1)&(bdf.followed_Star == 1)].shape[0]/bdf.shape[0]\n",
    "#P(A&C)\n",
    "bdf.loc[(bdf.successful == 1)&(bdf.followed_Stalker == 1)].shape[0]#/bdf.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a66da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (actions_sent_non_fans.outbound_activity != 'follow')\n",
    "Mavens_targeted_non_follow = actions_sent_non_fans[(mask)\n",
    "                & (actions_sent_non_fans.user_type == 'Maven')].groupby('user_id', as_index = False).size()\n",
    "Mavens_targeted_non_follow.columns = ['creator_id', 'Mavens_targeted_non_follow']\n",
    "\n",
    "Stars_targeted_non_follow =  actions_sent_non_fans[(mask)\n",
    "                & (actions_sent_non_fans.user_type == 'Star')].groupby('user_id', as_index = False).size()\n",
    "Stars_targeted_non_follow.columns = ['creator_id', 'Stars_targeted_non_follow']\n",
    "\n",
    "Zombies_targeted_non_follow = actions_sent_non_fans[(mask)\n",
    "                & (actions_sent_non_fans.user_type == 'Zombie')].groupby('user_id', as_index = False).size()\n",
    "Zombies_targeted_non_follow.columns = ['creator_id', 'Zombies_targeted_non_follow']\n",
    "\n",
    "Stalkers_targeted_non_follow =  actions_sent_non_fans[(mask)\n",
    "                & (actions_sent_non_fans.user_type == 'Stalker')].groupby('user_id', as_index = False).size()\n",
    "Stalkers_targeted_non_follow.columns = ['creator_id', 'Stalkers_targeted_non_follow']\n",
    "\n",
    "bdf = bdf.merge(Mavens_targeted_non_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "bdf = bdf.fillna(0)\n",
    "bdf = bdf.merge(Stars_targeted_non_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "bdf = bdf.fillna(0)\n",
    "bdf = bdf.merge(Zombies_targeted_non_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "bdf = bdf.fillna(0)\n",
    "bdf = bdf.merge(Stalkers_targeted_non_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "bdf = bdf.fillna(0)\n",
    "\n",
    "bdf['non_follow_Maven'] = (bdf.Mavens_targeted_non_follow > 0)*1\n",
    "bdf['non_follow_Star'] = (bdf.Stars_targeted_non_follow > 0)*1\n",
    "bdf['non_follow_Zombie'] = (bdf.Zombies_targeted_non_follow > 0)*1\n",
    "bdf['non_follow_Stalker'] = (bdf.Stalkers_targeted_non_follow > 0)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eab0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stalkers_targeted_non_follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dba5c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(D)\n",
    "bdf.loc[(bdf.non_follow_Star == 1)].shape[0]/bdf.shape[0]\n",
    "#P(E)\n",
    "bdf.loc[(bdf.non_follow_Stalker == 1)].shape[0]/bdf.shape[0]\n",
    "\n",
    "#P(A&D)\n",
    "bdf.loc[(bdf.successful == 1)&(bdf.non_follow_Star == 1)].shape[0]#/bdf.shape[0]\n",
    "#P(A&E)\n",
    "bdf.loc[(bdf.successful == 1)&(bdf.non_follow_Stalker == 1)].shape[0]#/bdf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c3a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.non_follow_Maven == 1)].shape[0]/bdf.shape[0]\n",
    "P_B = bdf.loc[(bdf.non_follow_Maven == 1)].shape[0]/bdf.shape[0]\n",
    "P_success_g_Maven = round(P_A_and_B/P_B,3)\n",
    "print('P(success|Maven): {}'.format(P_success_g_Maven))\n",
    "\n",
    "P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.non_follow_Star == 1)].shape[0]/bdf.shape[0]\n",
    "P_B = bdf.loc[(bdf.non_follow_Star == 1)].shape[0]/bdf.shape[0]\n",
    "P_success_g_Star = round(P_A_and_B/P_B,3)\n",
    "print('P(success|Star): {}'.format(P_success_g_Star))\n",
    "\n",
    "P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.non_follow_Zombie == 1)].shape[0]/bdf.shape[0]\n",
    "P_B = bdf.loc[(bdf.non_follow_Zombie == 1)].shape[0]/bdf.shape[0]\n",
    "P_success_g_Zombie = round(P_A_and_B/P_B,3)\n",
    "print('P(success|Zombie): {}'.format(P_success_g_Zombie))\n",
    "\n",
    "P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.non_follow_Stalker == 1)].shape[0]/bdf.shape[0]\n",
    "P_B = bdf.loc[(bdf.non_follow_Stalker == 1)].shape[0]/bdf.shape[0]\n",
    "P_success_g_Stalker= round(P_A_and_B/P_B,3)\n",
    "print('P(success|Stalker): {}'.format(P_success_g_Stalker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e94159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_A_and_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f34c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(maven_ids)+len(zombie_ids)+len(stalker_ids)+len(star_ids)\n",
    "print(len(maven_ids)/total*100)\n",
    "print(len(zombie_ids)/total*100)\n",
    "print(len(stalker_ids)/total*100)\n",
    "print(len(star_ids)/total*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03cb07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indegree_df = data_indegree.groupby('contact_id')['size'].sum().compute()\n",
    "indegree_df = indegree_df.reset_index()\n",
    "\n",
    "indegree_df['user_type'] = indegree_df.contact_id.apply(lambda x: 'Maven' if x in maven_ids else \n",
    "                          ('Zombie' if x in zombie_ids else\n",
    "                          ('Stalker' if x in stalker_ids else\n",
    "                          ('Star' if x in star_ids else 'other'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47657c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "indegree_df.groupby('user_type', as_index = False).agg({'size':['count','mean', 'std', 'min', 'median', 'max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932dba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data.groupby(['outdegree_level', 'indegree_level', 'activity_level']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb2e9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stalkers_targeted_follow.Stalkers_targeted_follow.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bd750e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df17f7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
