{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7de64a06",
   "metadata": {},
   "source": [
    "**This notebook is the executable version of lab note 3.\n",
    "It answers the following questions:**\n",
    "\n",
    "Finally, we answer 4 items:\n",
    "\n",
    "    1. Are successful creators more connected to high-outdegree users than do unsuccessful creators?\n",
    "    2. Are mavens more connected to successful creators thanto unsuccessful creators?\n",
    "    3. Do successful creators send more non-follow actions towards mavens than to zombies?\n",
    "    4. Do successful creators send more non-follow actions towards mavens than to stars?\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f459c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run parameters\n",
    "#used to control every run. Can be user to perfom sensitivity checks\n",
    "path_dir = r\"/Users/../Volumes/Raw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a758ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "import pickle\n",
    "sys.path.insert(0, '/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/')\n",
    "import numpy as np\n",
    "import src.utils\n",
    "from collections import Counter\n",
    "from src.utils import import_dta, import_tracks_dta,\\\n",
    "gen_active_relations, get_fan_interactions_per_week, calculate_avg_monthly_valence,\\\n",
    "gen_active_relations_prob, get_fan_interactions_per_week_prob, stripplot_prob,\\\n",
    "reaction_probability, follower_list, filter_quantile, sample_creators_music,\\\n",
    "gen_outbound_creators\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy\n",
    "import os\n",
    "from statsmodels.stats.proportion import proportions_ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2d1bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date(date):\n",
    "    '''convert date format like '2013-w09' to '2013-03-04', i.e. the first day of that week'''\n",
    "    year = date[0:4]\n",
    "    week = date[6:]\n",
    "    day = \"1\"\n",
    "    date = \"{}-{}-1\".format(year, week)\n",
    "    dt = datetime.datetime.strptime(date, \"%Y-%W-%w\")\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f8fad",
   "metadata": {},
   "source": [
    "# Data Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2605f798",
   "metadata": {},
   "source": [
    "We start by importing the raw data.  `follows_sent`, `comments_sent`, `shares_sent`, `likes_sent` and `messages_sent` contains data pn the promotional activities that the 35k users tracked in the dataset directed to other users. It includes the `user_id`, the `fan_id` and the `date_sent` which identifies the date when the prom. activity was sent. `users_info_1st` shows the type of user (creator or non-creator, which is identified by a blank) and the date the user entered the platform, for every user that sent or received prom. activities from any of the 35k users tracked in this dataset, while `users_info` contains the same information, but pertaining to the 35k users themselves.\n",
    "\n",
    "`follows_received` contains information on the follows received by the 35k users and will be used to generate the successful/unsuccessful groups of content creators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03f61585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%% 12sample_tracks.dta %%%%%%%%%%\n",
      "(56262, 7)\n",
      "%%%%%%%%%% 12sample_affiliations_sent.dta %%%%%%%%%%\n",
      "(800913, 3)\n",
      "%%%%%%%%%% 12sample_comments_made.dta %%%%%%%%%%\n",
      "(29258, 4)\n",
      "%%%%%%%%%% 12sample_reposts_made.dta %%%%%%%%%%\n",
      "(179329, 4)\n",
      "%%%%%%%%%% 12sample_favoritings_made.dta %%%%%%%%%%\n",
      "(527701, 4)\n",
      "%%%%%%%%%% 12sample_messages_sent.dta %%%%%%%%%%\n",
      "(11091, 3)\n",
      "%%%%%%%%%% 12sample_1st_deg_user_infos.dta %%%%%%%%%%\n",
      "(670746, 3)\n",
      "%%%%%%%%%% 12sample_user_infos.dta %%%%%%%%%%\n",
      "(35000, 3)\n",
      "%%%%%%%%%% 12sample_affiliations_received.dta %%%%%%%%%%\n",
      "(432503, 3)\n"
     ]
    }
   ],
   "source": [
    "#affiliations :follows\n",
    "#favoritings :likes\n",
    "\n",
    "#used in filtering:\n",
    "path_dir = r\"/Users/../Volumes/Raw/\"\n",
    "tracks = import_tracks_dta(path_dir, \"12sample_tracks.dta\");\n",
    "\n",
    "#these are the actions sent to \n",
    "follows_sent = import_dta(path_dir, \"12sample_affiliations_sent.dta\");\n",
    "comments_sent = import_dta(path_dir, \"12sample_comments_made.dta\");\n",
    "shares_sent = import_dta(path_dir, \"12sample_reposts_made.dta\");\n",
    "likes_sent = import_dta(path_dir, \"12sample_favoritings_made.dta\");\n",
    "messages_sent = import_dta(path_dir, \"12sample_messages_sent.dta\");\n",
    "\n",
    "#Used to track information on the 1st degree connections\n",
    "user_info_1st = import_dta(path_dir, \"12sample_1st_deg_user_infos.dta\");\n",
    "user_info_1st.columns = ['user_id', 'type', 'entered_platform'];\n",
    "user_info = import_dta(path_dir, \"12sample_user_infos.dta\");\n",
    "\n",
    "#Used to compute creator's success measure\n",
    "follows_received = import_dta(path_dir, \"12sample_affiliations_received.dta\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35300c65",
   "metadata": {},
   "source": [
    "Indegree and outdegree information.\n",
    "\n",
    "The function below import the outdegree dataset. Because the raw version of those dataset are too large to be processed in memory, we preprocessed them in a separate script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cca037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregates preprocessed outdegree of 1st degree users\n",
    "def import_outdegree(path='/Users/caiorego/Desktop/BDS/RA/Seeding-Bandits/'):\n",
    "    d = {}\n",
    "    for i in range(6):\n",
    "       d[str(i)] = pd.read_pickle(os.path.join(path,'{}.pkl'.format(i))) \n",
    "       d[str(i)]['created_at'] =  pd.to_datetime(d[str(i)]['created_at'])\n",
    "       d[str(i)]['created_at'] = pd.to_datetime(d[str(i)]['created_at']).dt.floor('d')\n",
    "       d[str(i)] = d[str(i)].groupby(['sender_id', 'created_at'], as_index = False).size() \n",
    "    \n",
    "    data_outdegree = pd.concat([d['0'], d['1'], d['2'], d['3'], d['4'], d['5']])\n",
    "    #data_outdegree.set_index('created_at', inplace = True)\n",
    "    return data_outdegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e03d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outdegree = import_outdegree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed0a2e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_outdegree = data_outdegree.groupby(['sender_id','created_at'], as_index = False).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb3d51",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a358956e",
   "metadata": {},
   "source": [
    "## Creator ids, successful and unsucessful creators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb7bc74",
   "metadata": {},
   "source": [
    "Next, we define three lists of ids: one with the ids from the content creators, according to the `users_info` table, one with the ids of successful creators and the last one with the ids of the unsuccessful ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77715356",
   "metadata": {},
   "source": [
    "Let's start with a list of the id of creators. We also create a dataset with containing information on creators only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd634fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (tracks.track_available == 1) & (tracks.public == 't')\n",
    "creator_ids = tracks[mask].user_id.unique()\n",
    "\n",
    "creators = tracks[(tracks.track_available == 1) & (tracks.public == 't')]\n",
    "\n",
    "#mask = user_info.type == 'creator'\n",
    "#creator_ids = user_info[mask].user_id.unique()\n",
    "\n",
    "#creators = user_info[user_info.type == 'creator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c00d1304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def successful_creators_followers(follows_received, base_date = datetime.datetime(2016, 5, 30, 0, 0), perc1 = None, perc2 = None, subset_creators = None):\n",
    "    '''Classifies content creators in successful or unsuccessfull\n",
    "        Arguments:\n",
    "                    follows_received: dataframe containing the follows received by content creators\n",
    "                    base date:        date, in datetime.datetime(YYYY, M, DD, H, M) format, in which the number \n",
    "                                      of followers per creator is calculated.\n",
    "                    perc1:            the threshold used to classify unsuccessful content creators. Creator having \n",
    "                                      total followers below the number dictated by this threshold, at the base date,\n",
    "                                      are classified as unsuccessful \n",
    "                    perc2:            the threshold used to classify successful content creators. Creator having \n",
    "                                      total followers above the number dictated by this threshold, at the base date,\n",
    "                                      are classified as successful\n",
    "                    subset_creators:  a pd.DataFrame containing the creators. If is it available, it will be used to \n",
    "                                      filter out non creators and to make sure creators with 0 followers are part of\n",
    "                                      the resulting dataset.\n",
    "        \n",
    "    '''\n",
    "    print(base_date)\n",
    "\n",
    "    if 'inbound_activity' not in follows_received.columns:\n",
    "        follows_received.columns = ['fan_id', 'user_id', 'date_sent']\n",
    "\n",
    "    mask = (follows_received['date_sent'] < base_date)\n",
    "\n",
    "    df = follows_received[mask].groupby('user_id', as_index=False).agg({'fan_id': pd.Series.nunique})\n",
    "    df.columns = ['user_id', 'followers']\n",
    "\n",
    "    \n",
    "    if type(subset_creators) == pd.DataFrame:\n",
    "        print('subsetting...')\n",
    "        df.set_index('user_id', inplace = True)\n",
    "        df = df.reindex(subset_creators.user_id.unique())\n",
    "        df.fillna(0, inplace = True)\n",
    "        df.reset_index(inplace = True)\n",
    "        df.columns = ['user_id', 'followers']\n",
    "\n",
    "    low = np.quantile(df.followers, perc1)\n",
    "    high = np.quantile(df.followers, perc2)\n",
    "\n",
    "    print(\"High influencer boundary: {}\".format(high))\n",
    "    print(\"Low influencer boundary: {}\".format(low))\n",
    "\n",
    "    #mask = (df[\"followers\"] <= low) | (df[\"followers\"] >= high)\n",
    "    \n",
    "    unsuccessful_creator_ids = df.loc[df[\"followers\"] <= high].user_id.unique()\n",
    "    successful_creator_ids = df.loc[df[\"followers\"] >= high].user_id.unique()\n",
    "\n",
    "    return unsuccessful_creator_ids, successful_creator_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b06476a",
   "metadata": {},
   "source": [
    "## Putting together a dataset with the promotional activities made by content creators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b8a09",
   "metadata": {},
   "source": [
    "The function `gen_actions_sent_df` creates a dataframe with all the promotional activities that content creators sent to users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fff0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_actions_sent_df(follows_sent, shares_sent, likes_sent, comments_sent, messages_sent, creator_ids = creator_ids):\n",
    "    '''\n",
    "    Creates dataframe containing the actions that content creators send to users.\n",
    "        Attributes:\n",
    "                    follows_sent:  dataframe with the follows sent by the 35k users.\n",
    "                    shares_sent:   dataframe with the shares sent by the 35k users.\n",
    "                    likes_sent:    dataframe with the likes sent by the 35k users.\n",
    "                    comments_sent: dataframe with the comments sent by the 35k users.\n",
    "                    messages_sent: dataframe with the messages sent by the 35k users.\n",
    "                    creator_ids:   list with content creator ids. If not none, is used to\n",
    "                                   filter out activities from non creators.\n",
    "    '''\n",
    "    \n",
    "    follows_sent['outbound_activity'] = 'follow'\n",
    "    follows_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'song_id' in shares_sent.columns:\n",
    "        shares_sent.drop(columns=[\"song_id\"])\n",
    "    shares_sent = shares_sent[['reposter_id', \"owner_id\", 'created_at']]\n",
    "    shares_sent['outbound_activity'] = 'share'\n",
    "    shares_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'track_id' in likes_sent.columns:\n",
    "        likes_sent.drop(columns=[\"track_id\"], inplace=True)\n",
    "    likes_sent['outbound_activity'] = 'like'\n",
    "    likes_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    if 'track_id' in comments_sent.columns:\n",
    "        comments_sent.drop(columns=[\"track_id\"], inplace=True)\n",
    "    comments_sent['outbound_activity'] = 'comment'\n",
    "    comments_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "\n",
    "    messages_sent[\"outbound_activity\"] = 'message'\n",
    "    messages_sent.columns = ['user_id', 'fan_id', 'date_sent', 'outbound_activity']\n",
    "    df = pd.concat([follows_sent, shares_sent, likes_sent, comments_sent, messages_sent])\n",
    "\n",
    "\n",
    "    if type(creator_ids) == numpy.ndarray:\n",
    "        df = df[df['user_id'].isin(creator_ids)]\n",
    "        \n",
    "    df['week_yr'] = df.date_sent.dt.strftime('%Y-w%U')\n",
    "    df = df.loc[df['user_id'] != df['fan_id'],:]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c6b8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_sent = gen_actions_sent_df(follows_sent, shares_sent, likes_sent, comments_sent,\n",
    "                                     messages_sent, creator_ids = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6f8c4",
   "metadata": {},
   "source": [
    "## Filter only actions that were sent to non-fans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a67b459",
   "metadata": {},
   "source": [
    "We merge the `actions_sent` dataset with a table containing the date each fan started following the creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b904f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_received.columns = ['fan_id', 'user_id', 'date_sent']\n",
    "followers = follows_received[[\"fan_id\", \"user_id\", \"date_sent\"]]\n",
    "followers.columns = [\"fan_id\", \"user_id\", \"follower_since\"]\n",
    "\n",
    "actions_sent = actions_sent.merge(followers, right_on = ['user_id', 'fan_id'],\n",
    "                                      left_on = ['user_id', 'fan_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973ebc19",
   "metadata": {},
   "source": [
    "Since we are interested in acquisition campaings, we need to produce a dataset that exclude actions targetting fans.\n",
    "We do that using filters based on the date of the action and the date that the user became a fan of the content creator. The resulting dataframe is named `actions_sent_non_fans`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dbf162",
   "metadata": {},
   "source": [
    "We then filter only actions that happened before the user follows the content creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c957f00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/cgjzt69n5hlgmtsm36p1pztw0000gn/T/ipykernel_21722/3855957735.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  actions_sent_non_fans['week_yr_date'] = actions_sent_non_fans.week_yr.apply(lambda x: process_date(x))\n"
     ]
    }
   ],
   "source": [
    "mask = (actions_sent.date_sent < actions_sent.follower_since) | (actions_sent.follower_since.isnull())\n",
    "actions_sent_non_fans =  actions_sent[mask]\n",
    "actions_sent_non_fans['week_yr_date'] = actions_sent_non_fans.week_yr.apply(lambda x: process_date(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d9b9e",
   "metadata": {},
   "source": [
    "## Outdegree level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a61f1",
   "metadata": {},
   "source": [
    "Originally, we only have outdegree information on users that follow at least one user. The function below inputs an outdegree of 0 to users that are following anyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1083a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGE DOCUMENTATION\n",
    "def outdegree_level(data, date, user_info = user_info_1st):\n",
    "    \n",
    "    '''\n",
    "    This function returns the membership table at date equals `date`. Every user that interacted with the 35k tracked \n",
    "    users and entered the platform before `date` is present in the table, even if it has indegree 0.\n",
    "    arguments:\n",
    "              data:           the indegree dataset.\n",
    "              user_info:      the dataset containing all the users that interacted with the 35k users tracked.\n",
    "    '''\n",
    "    \n",
    "    data = data[data.created_at.dt.floor('d')<=date]\n",
    "    data = data.groupby('sender_id').agg({'size':'sum'}).compute()\n",
    "    \n",
    "    #merge with user info to obtain users that are not followed by anyone at the current date\n",
    "    data = user_info_1st.merge(data, left_on = 'user_id', right_on = 'sender_id', how= 'outer')\n",
    "    data.loc[data['size'].isnull(), 'size'] = 0\n",
    "    data = data[['user_id', 'size', 'entered_platform']].set_index('user_id')\n",
    "    \n",
    "    #filter out users that didnt exist in the current date\n",
    "    mask = data['entered_platform'].dt.floor('d') <= date\n",
    "    data = data.loc[mask]\n",
    "    \n",
    "    mask = (data['size']>0)\n",
    "    data.loc[~mask, 'size'] = 0 \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a49e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dask is a python api with objects optimized for big data (user directed acyclic graphs). \n",
    "dask_outdegree = dd.from_pandas(data_outdegree, npartitions = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21950961",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_day =  max(actions_sent.date_sent.dt.floor('d').unique())\n",
    "user_outdegree = outdegree_level(dask_outdegree, last_day, user_info = user_info_1st)\n",
    "receiver_ids = user_outdegree.index.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b5931",
   "metadata": {},
   "source": [
    "Now we classify the creator in successful and unsuccessful, according to the threshold defined in the beggining of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52d85729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_outdegree_level(oudegree_data, perc1 = None, perc2 = None):\n",
    "    '''Classifies content creators in successful or unsuccessfull\n",
    "        Arguments:\n",
    "                    oudegree_data:    dataframe containing the fans followers at \n",
    "                    perc1:            the threshold used to classify unsuccessful content creators. Creator having \n",
    "                                      total followers below the number dictated by this threshold, at the base date,\n",
    "                                      are classified as unsuccessful \n",
    "                    perc2:            the threshold used to classify successful content creators. Creator having \n",
    "                                      total followers above the number dictated by this threshold, at the base date,\n",
    "                                      are classified as successful\n",
    "    '''\n",
    "\n",
    "    df = oudegree_data.reset_index().iloc[:,:2]\n",
    "    df.columns = ['user_id', 'followers']\n",
    "\n",
    "    low = np.quantile(df.followers, perc1)\n",
    "    high = np.quantile(df.followers, perc2)\n",
    "\n",
    "    print(\"High outdegree boundary: {}\".format(high))\n",
    "    print(\"Low outdegree boundary: {}\".format(low))\n",
    "    \n",
    "    low_outdegree_ids = df.loc[df[\"followers\"] <= high].user_id.unique()\n",
    "    high_outdegree_ids = df.loc[df[\"followers\"] >= high].user_id.unique()\n",
    "    \n",
    "    \n",
    "    df['outdegree_level'] = df.user_id.apply(\n",
    "        lambda x: 'high' if x in high_outdegree_ids else ('low' if x in low_outdegree_ids else None))\n",
    "\n",
    "    \n",
    "    return df, low_outdegree_ids, high_outdegree_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1faaf",
   "metadata": {},
   "source": [
    "## Non-follow Actions level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4db5e11",
   "metadata": {},
   "source": [
    "The activity level is defined as the number of actions performed by users. It is important to notice that we only observe actions targeting the 35k users that joined in march 2012. We consider this measure a proxy for the real activity level.\n",
    "\n",
    "Let's begin by creating a dataset with all action received by those 35k users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec0ad24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%% 12sample_1st_deg_comments_made.dta %%%%%%%%%%\n",
      "(21463011, 4)\n",
      "%%%%%%%%%% 12sample_1st_deg_reposts_made.dta %%%%%%%%%%\n",
      "(18953640, 4)\n"
     ]
    }
   ],
   "source": [
    "#comments_received = import_dta(path_dir, \"12sample_comments_received.dta\");\n",
    "#shares_received = import_dta(path_dir, \"12sample_reposts_received.dta\");\n",
    "#likes_received = import_dta(path_dir, \"12sample_favoritings_received.dta\");\n",
    "#messages_received = import_dta(path_dir, \"12sample_messages_received.dta\");\n",
    "\n",
    "path_dir_2 = r'/Users/../Volumes/Alter_outbound_activities/'\n",
    "\n",
    "comments_received = import_dta(path_dir_2, \"12sample_1st_deg_comments_made.dta\");\n",
    "shares_received = import_dta(path_dir_2, \"12sample_1st_deg_reposts_made.dta\");\n",
    "likes_received = import_dta(path_dir_2, \"12sample_1st_deg_favoritings_made.dta\");\n",
    "messages_received = import_dta(path_dir_2, \"12sample_1st_deg_messages_sent.dta\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec99f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'song_id' in shares_received:\n",
    "        shares_received.drop(columns=[\"song_id\"])\n",
    "shares_received = shares_received[['reposter_id', \"owner_id\", 'created_at']]\n",
    "shares_received['inbound_activity'] = 'share'\n",
    "shares_received.columns = ['fan_id', 'user_id', 'date_sent', 'inbound_activity']\n",
    "\n",
    "if 'track_id' in likes_received:\n",
    "        likes_received = likes_received.drop(columns=[\"track_id\"])\n",
    "likes_received['inbound_activity'] = 'like'\n",
    "likes_received.columns = ['fan_id', 'user_id', 'date_sent', 'inbound_activity']\n",
    "\n",
    "if 'track_id' in comments_received:\n",
    "        comments_received = comments_received.drop(columns=[\"track_id\"])\n",
    "comments_received['inbound_activity'] = 'comment'\n",
    "comments_received.columns = ['fan_id', 'user_id', 'date_sent', 'inbound_activity']\n",
    "\n",
    "messages_received[\"outbound_activity\"] = 'message'\n",
    "messages_received.columns = ['user_id', 'fan_id', 'date_sent', 'inbound_activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b24587",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity_data = pd.concat([shares_received, likes_received, comments_received, messages_received])\n",
    "\n",
    "user_activity_df = user_activity_data.groupby('fan_id', as_index = True).size()\n",
    "user_activity_df = user_activity_df.reindex(receiver_ids)\n",
    "\n",
    "user_activity_df = user_activity_df.reset_index()\n",
    "user_activity_df.columns = ['user_id', 'activities_performed']\n",
    "    \n",
    "user_activity_df.loc[user_activity_df.activities_performed.isna(), 'activities_performed'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_activity_level(user_activity_df, perc1 = None, perc2 = None):\n",
    "    '''Classifies users based on the amount of non-follow activities\n",
    "        Arguments:\n",
    "                    user_activity_data:   dataframe containing the user activities \n",
    "                    base date:             date, in datetime.datetime(YYYY, M, DD, H, M) format, in which the number \n",
    "                                           of followers per creator is calculated.\n",
    "                    perc1:                 the threshold used to classify unsuccessful content creators. Creator having \n",
    "                                           total followers below the number dictated by this threshold, at the base date,\n",
    "                                           are classified as unsuccessful \n",
    "                    perc2:                 the threshold used to classify successful content creators. Creator having \n",
    "                                           total followers above the number dictated by this threshold, at the base date,\n",
    "                                           are classified as successful\n",
    "    '''\n",
    "\n",
    "    \n",
    "    df = user_activity_df\n",
    "    low = np.quantile(df.activities_performed, perc1)\n",
    "    high = np.quantile(df.activities_performed, perc2)\n",
    "\n",
    "    print(\"High activity boundary: {}\".format(high))\n",
    "    print(\"Low activity boundary: {}\".format(low))\n",
    "    \n",
    "    low_activity_ids = df.loc[df[\"activities_performed\"] <= high].user_id.unique()\n",
    "    high_activity_ids = df.loc[df[\"activities_performed\"] > high].user_id.unique()\n",
    "    \n",
    "    df['activity_level'] = df.user_id.apply(\n",
    "    lambda x: 'high' if x in high_activity_ids else ('low' if x in low_activity_ids else None))\n",
    "\n",
    "    return df, low_activity_ids, high_activity_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d9a9b",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61797db7",
   "metadata": {},
   "source": [
    "Finally, we answer 4 items:\n",
    "\n",
    "    1. Are successful creators more connected to high-outdegree users than do unsuccessful creators?\n",
    "    2. Are mavens more connected to successful creators thanto unsuccessful creators?\n",
    "    3. Do successful creators send more non-follow actions towards mavens than to zombies?\n",
    "    4. Do successful creators send more non-follow actions towards mavens than to stars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd14394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def calculate_odds_ratio_ci(exposed_cases, exposed_controls, nonexposed_cases, nonexposed_controls):\n",
    "    # Calculate the odds ratio (OR)\n",
    "    odds_ratio = (exposed_cases / exposed_controls) / (nonexposed_cases / nonexposed_controls)\n",
    "\n",
    "    # Calculate the 95% confidence interval (CI) for the OR\n",
    "    log_odds_ratio = np.log(odds_ratio)\n",
    "    std_error = np.sqrt(1/exposed_cases + 1/exposed_controls + 1/nonexposed_cases + 1/nonexposed_controls)\n",
    "    z_score = stats.norm.ppf(0.975)\n",
    "    lower_ci = np.exp(log_odds_ratio - z_score*std_error)\n",
    "    upper_ci = np.exp(log_odds_ratio + z_score*std_error)\n",
    "\n",
    "    return round(odds_ratio, 2), round(lower_ci, 2), round(upper_ci, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c2bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def odds_ratio(g1, g2, group_ids1, group_ids2):\n",
    "    \n",
    "    tab = np.array([[g1, g2], [len(group_ids1)-g1, len(group_ids2)-g2]])\n",
    "\n",
    "    # calculate the odds ratio by taking the ratio of the odds of the event occurring in the two groups\n",
    "    odds_ratio = (g1/(len(group_ids1)-g1)/(g2/(len(group_ids2)-g2)))\n",
    "    print(\"Odds Ratio:\", round(odds_ratio,4))\n",
    "\n",
    "    # perform a chi-square test to determine whether the observed odds ratio is statistically significant\n",
    "    chi2, p_value, _, _ = chi2_contingency(tab)\n",
    "    print(\"Chi-Square Statistic:\", round(chi2,4))\n",
    "    print(\"P-Value:\", round(p_value,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f86a04",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea61f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_datasets(low_success, high_success, low_user_outdegree, high_user_outdegree, low_user_activity, high_user_activity): \n",
    "    unsuccessful_ids, successful_ids = successful_creators_followers(follows_received, \n",
    "                    perc1 = low_success, perc2 = high_success, subset_creators = creators)\n",
    "    \n",
    "    print('Success step done.')\n",
    "\n",
    "    user_outdegree_df, low_outdegree_ids, high_outdegree_ids = user_outdegree_level(user_outdegree,\n",
    "                    perc1 = low_user_outdegree, perc2 = high_user_outdegree)\n",
    "    print('Outdegree step done.')\n",
    "\n",
    "    activity_level, low_activity_ids, high_activity_ids = user_activity_level(user_activity_df, \n",
    "                    perc1 = low_user_activity, perc2 = high_user_activity)\n",
    "    print('Activity step done.')\n",
    "\n",
    "    table_data = user_outdegree_df.merge(activity_level, left_on = 'user_id', right_on = 'user_id', how = 'inner')\n",
    "\n",
    "    table_data['Type'] = table_data.apply(lambda x: \n",
    "        'Maven' if (x.outdegree_level == 'low') & (x.activity_level == 'high')\n",
    "         else ('Zombie' if (x.outdegree_level == 'low') & (x.activity_level == 'low')\n",
    "         else ('Stalker' if (x.outdegree_level == 'high') & (x.activity_level == 'low')\n",
    "         else ('Star' if (x.outdegree_level == 'high') & (x.activity_level == 'high')\n",
    "         else 'other'))), axis=1)\n",
    "\n",
    "    zombie_ids = table_data.loc[table_data.Type =='Zombie'].user_id.unique()\n",
    "    star_ids = table_data.loc[table_data.Type =='Star'].user_id.unique()\n",
    "    maven_ids = table_data.loc[table_data.Type =='Maven'].user_id.unique()\n",
    "    stalker_ids = table_data.loc[table_data.Type =='Stalker'].user_id.unique()\n",
    "\n",
    "    actions_sent_non_fans['user_type'] = actions_sent_non_fans.fan_id.apply(lambda x: 'Maven' if x in maven_ids else \n",
    "                              ('Zombie' if x in zombie_ids else\n",
    "                              ('Stalker' if x in stalker_ids else\n",
    "                              ('Star' if x in star_ids else 'other'))))\n",
    "\n",
    "    ## classify content creators\n",
    "    actions_sent_non_fans['creator_type'] = actions_sent_non_fans.user_id.apply(\n",
    "                                                lambda x: 'successful' if x in successful_ids else \n",
    "                                                ('unsuccessful' if x in unsuccessful_ids else 'other'))\n",
    "    \n",
    "    return table_data, successful_ids, unsuccessful_ids, actions_sent_non_fans, maven_ids, star_ids, zombie_ids, stalker_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_user_outdegree = 0.25\n",
    "high_user_outdegree = 0.75\n",
    "\n",
    "low_user_activity = 0.25\n",
    "high_user_activity = 0.75\n",
    "\n",
    "Robustness_table = pd.DataFrame(index = ['P(A|B)/P(A|C)', 'P(A|D)/P(A|E)'],\n",
    "                                columns = ['0.1/0.5', '0.1/0.75', '0.1/0.9',\n",
    "                                           '0.25/0.5', '0.25/0.75', '0.25/0.9',\n",
    "                                           '0.5/0.5', '0.5/0.75', '0.5/0.9'])\n",
    "for low_success, high_success in [(0.1, 0.5), (0.1, 0.75), (0.1, 0.9),\n",
    "                                   (0.25, 0.5), (0.25, 0.75), (0.25, 0.9),\n",
    "                                   (0.5, 0.5), (0.5, 0.75), (0.5, 0.9)]:\n",
    "    table_data, successful_ids, unsuccessful_ids, actions_sent_non_fans, maven_ids, star_ids, zombie_ids, stalker_ids = gen_datasets(low_success,\n",
    "           high_success, low_user_outdegree, high_user_outdegree, low_user_activity, high_user_activity) \n",
    "\n",
    "    print('successful',len(successful_ids))\n",
    "    \n",
    "    bdf = pd.DataFrame(creator_ids, columns = ['creator_id'])\n",
    "    bdf['successful'] = bdf.creator_id.apply(lambda x: 1 if x in successful_ids else 0)\n",
    "\n",
    "    #non-follow\n",
    "    mask = (actions_sent_non_fans.outbound_activity != 'follow')\n",
    "    Stalkers_targeted_non_follow = actions_sent_non_fans[(mask)                    & (actions_sent_non_fans.user_type == 'Stalker')].groupby('user_id', as_index = False).size()\n",
    "    Stalkers_targeted_non_follow.columns = ['creator_id', 'Stalkers_targeted_non_follow']\n",
    "\n",
    "    Stars_targeted_non_follow =  actions_sent_non_fans[(mask)                    & (actions_sent_non_fans.user_type == 'Star')].groupby('user_id', as_index = False).size()\n",
    "    Stars_targeted_non_follow.columns = ['creator_id', 'Stars_targeted_non_follow']\n",
    "\n",
    "    bdf = bdf.merge(Stalkers_targeted_non_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "    bdf = bdf.fillna(0)\n",
    "    bdf = bdf.merge(Stars_targeted_non_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "    bdf = bdf.fillna(0)\n",
    "\n",
    "    bdf['non_follow_Stalker'] = (bdf.Stalkers_targeted_non_follow > 0)*1\n",
    "    bdf['non_follow_Star'] = (bdf.Stars_targeted_non_follow > 0)*1\n",
    "\n",
    "\n",
    "    P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.non_follow_Stalker == 1)].shape[0]/bdf.shape[0]\n",
    "    P_B = bdf.loc[(bdf.non_follow_Stalker == 1)].shape[0]/bdf.shape[0]\n",
    "    P_success_g_Stalker = round(P_A_and_B/P_B,2)\n",
    "\n",
    "    print('P(success|Stalker): {}'.format(P_success_g_Stalker))\n",
    "\n",
    "    P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.non_follow_Star == 1)].shape[0]/bdf.shape[0]\n",
    "    P_B = bdf.loc[(bdf.non_follow_Star == 1)].shape[0]/bdf.shape[0]\n",
    "    P_success_g_Star = round(P_A_and_B/P_B,2)\n",
    "    \n",
    "    Robustness_table.loc['P(A|B)/P(A|C)', '{}/{}'.format(low_success, high_success)] = P_success_g_Stalker/P_success_g_Star\n",
    "\n",
    "    print('P(success|Star): {}'.format(P_success_g_Star))\n",
    "    \n",
    "    #follow\n",
    "\n",
    "    mask = (actions_sent_non_fans.outbound_activity == 'follow')\n",
    "    Stalkers_targeted_follow = actions_sent_non_fans[(mask) & (actions_sent_non_fans.user_type == 'Stalker')].groupby('user_id', as_index = False).size()\n",
    "    Stalkers_targeted_follow.columns = ['creator_id', 'Stalkers_targeted_follow']\n",
    "\n",
    "    Stars_targeted_follow =  actions_sent_non_fans[(mask) & (actions_sent_non_fans.user_type == 'Star')].groupby('user_id', as_index = False).size()\n",
    "    Stars_targeted_follow.columns = ['creator_id', 'Stars_targeted_follow']\n",
    "\n",
    "    bdf = bdf.merge(Stalkers_targeted_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "    bdf = bdf.fillna(0)\n",
    "    bdf = bdf.merge(Stars_targeted_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "    bdf = bdf.fillna(0)\n",
    "\n",
    "    bdf['follow_Stalker'] = (bdf.Stalkers_targeted_follow > 0)*1\n",
    "    bdf['follow_Star'] = (bdf.Stars_targeted_follow > 0)*1\n",
    "    \n",
    "    \n",
    "    P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.follow_Stalker == 1)].shape[0]/bdf.shape[0]\n",
    "    P_B = bdf.loc[(bdf.follow_Stalker == 1)].shape[0]/bdf.shape[0]\n",
    "    P_success_g_Stalker = round(P_A_and_B/P_B,2)\n",
    "\n",
    "    print('P(success|Stalker): {}'.format(P_success_g_Stalker))\n",
    "\n",
    "    P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.follow_Star == 1)].shape[0]/bdf.shape[0]\n",
    "    P_B = bdf.loc[(bdf.follow_Star == 1)].shape[0]/bdf.shape[0]\n",
    "    P_success_g_Star = round(P_A_and_B/P_B,2)\n",
    "    \n",
    "    Robustness_table.loc['P(A|D)/P(A|E)', '{}/{}'.format(low_success, high_success)] = P_success_g_Stalker/P_success_g_Star\n",
    "    \n",
    "    \n",
    "    print('P(success|Star): {}'.format(P_success_g_Star))\n",
    "    \n",
    "Robustness_table.to_csv('Robustness_table_star.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154bed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_success = 0.25\n",
    "low_success = 0.75\n",
    "\n",
    "low_user_activity = 0.25\n",
    "high_user_activity = 0.75\n",
    "\n",
    "Robustness_table_2 = pd.DataFrame(index = ['P(A|B)/P(A|C)', 'P(A|D)/P(A|E)'],\n",
    "                                columns = ['0.1/0.5', '0.1/0.75', '0.1/0.9',\n",
    "                                           '0.25/0.5', '0.25/0.75', '0.25/0.9',\n",
    "                                           '0.5/0.5', '0.5/0.75', '0.5/0.9'])\n",
    "\n",
    "for low_user_outdegree, high_user_outdegree in ([(0.1, 0.5), (0.1, 0.75), (0.1, 0.9),\n",
    "                                   (0.25, 0.5), (0.25, 0.75), (0.25, 0.9),\n",
    "                                   (0.5, 0.5), (0.5, 0.75), (0.5, 0.9)]): \n",
    "    table_data, successful_ids, unsuccessful_ids, actions_sent_non_fans, maven_ids, star_ids, zombie_ids, stalker_ids = gen_datasets(low_success,\n",
    "           high_success, low_user_outdegree, high_user_outdegree, low_user_activity, high_user_activity) \n",
    "\n",
    "    print('successful',len(successful_ids))\n",
    "    \n",
    "    bdf = pd.DataFrame(creator_ids, columns = ['creator_id'])\n",
    "    bdf['successful'] = bdf.creator_id.apply(lambda x: 1 if x in successful_ids else 0)\n",
    "\n",
    "    #non-follow\n",
    "    mask = (actions_sent_non_fans.outbound_activity != 'follow')\n",
    "    Stalkers_targeted_non_follow = actions_sent_non_fans[(mask)                    & (actions_sent_non_fans.user_type == 'Stalker')].groupby('user_id', as_index = False).size()\n",
    "    Stalkers_targeted_non_follow.columns = ['creator_id', 'Stalkers_targeted_non_follow']\n",
    "\n",
    "    Stars_targeted_non_follow =  actions_sent_non_fans[(mask)                    & (actions_sent_non_fans.user_type == 'Star')].groupby('user_id', as_index = False).size()\n",
    "    Stars_targeted_non_follow.columns = ['creator_id', 'Stars_targeted_non_follow']\n",
    "\n",
    "    bdf = bdf.merge(Stalkers_targeted_non_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "    bdf = bdf.fillna(0)\n",
    "    bdf = bdf.merge(Stars_targeted_non_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "    bdf = bdf.fillna(0)\n",
    "\n",
    "    bdf['non_follow_Stalker'] = (bdf.Stalkers_targeted_non_follow > 0)*1\n",
    "    bdf['non_follow_Star'] = (bdf.Stars_targeted_non_follow > 0)*1\n",
    "\n",
    "\n",
    "    P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.non_follow_Stalker == 1)].shape[0]/bdf.shape[0]\n",
    "    P_B = bdf.loc[(bdf.non_follow_Stalker == 1)].shape[0]/bdf.shape[0]\n",
    "    P_success_g_Stalker = round(P_A_and_B/P_B,2)\n",
    "\n",
    "    print('P(success|Stalker): {}'.format(P_success_g_Stalker))\n",
    "\n",
    "    P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.non_follow_Star == 1)].shape[0]/bdf.shape[0]\n",
    "    P_B = bdf.loc[(bdf.non_follow_Star == 1)].shape[0]/bdf.shape[0]\n",
    "    P_success_g_Star = round(P_A_and_B/P_B,2)\n",
    "    \n",
    "    Robustness_table_2.loc['P(A|B)/P(A|C)', '{}/{}'.format(low_user_outdegree, high_user_outdegree)] = P_success_g_Stalker/P_success_g_Star\n",
    "\n",
    "    print('P(success|Star): {}'.format(P_success_g_Star))\n",
    "    \n",
    "    #follow\n",
    "\n",
    "    mask = (actions_sent_non_fans.outbound_activity == 'follow')\n",
    "    Stalkers_targeted_follow = actions_sent_non_fans[(mask)                    & (actions_sent_non_fans.user_type == 'Stalker')].groupby('user_id', as_index = False).size()\n",
    "    Stalkers_targeted_follow.columns = ['creator_id', 'Stalkers_targeted_follow']\n",
    "\n",
    "    Stars_targeted_follow =  actions_sent_non_fans[(mask)                    & (actions_sent_non_fans.user_type == 'Star')].groupby('user_id', as_index = False).size()\n",
    "    Stars_targeted_follow.columns = ['creator_id', 'Stars_targeted_follow']\n",
    "\n",
    "    bdf = bdf.merge(Stalkers_targeted_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "    bdf = bdf.fillna(0)\n",
    "    bdf = bdf.merge(Stars_targeted_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "    bdf = bdf.fillna(0)\n",
    "\n",
    "    bdf['follow_Stalker'] = (bdf.Stalkers_targeted_follow > 0)*1\n",
    "    bdf['follow_Star'] = (bdf.Stars_targeted_follow > 0)*1\n",
    "    \n",
    "    \n",
    "    P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.follow_Stalker == 1)].shape[0]/bdf.shape[0]\n",
    "    P_B = bdf.loc[(bdf.follow_Stalker == 1)].shape[0]/bdf.shape[0]\n",
    "    P_success_g_Stalker = round(P_A_and_B/P_B,2)\n",
    "\n",
    "    print('P(success|Stalker): {}'.format(P_success_g_Stalker))\n",
    "\n",
    "    P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.follow_Star == 1)].shape[0]/bdf.shape[0]\n",
    "    P_B = bdf.loc[(bdf.follow_Star == 1)].shape[0]/bdf.shape[0]\n",
    "    P_success_g_Star = round(P_A_and_B/P_B,2)\n",
    "    \n",
    "    Robustness_table_2.loc['P(A|D)/P(A|E)', '{}/{}'.format(low_user_outdegree, high_user_outdegree)] = P_success_g_Stalker/P_success_g_Star\n",
    "    \n",
    "    \n",
    "    print('P(success|Star): {}'.format(P_success_g_Star))\n",
    "    \n",
    "Robustness_table_2.to_csv('Robustness_table_star_2.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa5ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_success = 0.25\n",
    "low_success = 0.75\n",
    "\n",
    "low_user_outdegree = 0.25\n",
    "high_user_outdegree = 0.75\n",
    "\n",
    "Robustness_table_3 = pd.DataFrame(index = ['P(A|B)/P(A|C)', 'P(A|D)/P(A|E)'],\n",
    "                                columns = ['0.1/0.5', '0.1/0.75', '0.1/0.9',\n",
    "                                           '0.25/0.5', '0.25/0.75', '0.25/0.9',\n",
    "                                           '0.5/0.5', '0.5/0.75', '0.5/0.9'])\n",
    "for low_user_activity, high_user_activity in ([(0.1, 0.5), (0.1, 0.75), (0.1, 0.9),\n",
    "                                   (0.25, 0.5), (0.25, 0.75), (0.25, 0.9),\n",
    "                                   (0.5, 0.5), (0.5, 0.75), (0.5, 0.9)]): \n",
    "    table_data, successful_ids, unsuccessful_ids, actions_sent_non_fans, maven_ids, star_ids, zombie_ids, stalker_ids = gen_datasets(low_success, high_success, low_user_outdegree, high_user_outdegree, low_user_activity, high_user_activity) \n",
    "\n",
    "    print('successful',len(successful_ids))\n",
    "    \n",
    "    bdf = pd.DataFrame(creator_ids, columns = ['creator_id'])\n",
    "    bdf['successful'] = bdf.creator_id.apply(lambda x: 1 if x in successful_ids else 0)\n",
    "\n",
    "    #non-follow\n",
    "    mask = (actions_sent_non_fans.outbound_activity != 'follow')\n",
    "    Stalkers_targeted_non_follow = actions_sent_non_fans[(mask)                    & (actions_sent_non_fans.user_type == 'Stalker')].groupby('user_id', as_index = False).size()\n",
    "    Stalkers_targeted_non_follow.columns = ['creator_id', 'Stalkers_targeted_non_follow']\n",
    "\n",
    "    Stars_targeted_non_follow =  actions_sent_non_fans[(mask)                    & (actions_sent_non_fans.user_type == 'Star')].groupby('user_id', as_index = False).size()\n",
    "    Stars_targeted_non_follow.columns = ['creator_id', 'Stars_targeted_non_follow']\n",
    "\n",
    "    bdf = bdf.merge(Stalkers_targeted_non_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "    bdf = bdf.fillna(0)\n",
    "    bdf = bdf.merge(Stars_targeted_non_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "    bdf = bdf.fillna(0)\n",
    "\n",
    "    bdf['non_follow_Stalker'] = (bdf.Stalkers_targeted_non_follow > 0)*1\n",
    "    bdf['non_follow_Star'] = (bdf.Stars_targeted_non_follow > 0)*1\n",
    "\n",
    "\n",
    "    P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.non_follow_Stalker == 1)].shape[0]/bdf.shape[0]\n",
    "    P_B = bdf.loc[(bdf.non_follow_Stalker == 1)].shape[0]/bdf.shape[0]\n",
    "    P_success_g_Stalker = round(P_A_and_B/P_B,2)\n",
    "\n",
    "    print('P(success|Stalker): {}'.format(P_success_g_Stalker))\n",
    "\n",
    "    P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.non_follow_Star == 1)].shape[0]/bdf.shape[0]\n",
    "    P_B = bdf.loc[(bdf.non_follow_Star == 1)].shape[0]/bdf.shape[0]\n",
    "    P_success_g_Star = round(P_A_and_B/P_B,2)\n",
    "    \n",
    "    Robustness_table_3.loc['P(A|B)/P(A|C)', '{}/{}'.format(low_user_activity, high_user_activity)] = P_success_g_Stalker/P_success_g_Star\n",
    "\n",
    "    print('P(success|Star): {}'.format(P_success_g_Star))\n",
    "    \n",
    "    #follow\n",
    "\n",
    "    mask = (actions_sent_non_fans.outbound_activity == 'follow')\n",
    "    Stalkers_targeted_follow = actions_sent_non_fans[(mask)                    & (actions_sent_non_fans.user_type == 'Stalker')].groupby('user_id', as_index = False).size()\n",
    "    Stalkers_targeted_follow.columns = ['creator_id', 'Stalkers_targeted_follow']\n",
    "\n",
    "    Stars_targeted_follow =  actions_sent_non_fans[(mask)                    & (actions_sent_non_fans.user_type == 'Star')].groupby('user_id', as_index = False).size()\n",
    "    Stars_targeted_follow.columns = ['creator_id', 'Stars_targeted_follow']\n",
    "\n",
    "    bdf = bdf.merge(Stalkers_targeted_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "    bdf = bdf.fillna(0)\n",
    "    bdf = bdf.merge(Stars_targeted_follow, left_on = 'creator_id', right_on='creator_id', how = 'left')\n",
    "    bdf = bdf.fillna(0)\n",
    "\n",
    "    bdf['follow_Stalker'] = (bdf.Stalkers_targeted_follow > 0)*1\n",
    "    bdf['follow_Star'] = (bdf.Stars_targeted_follow > 0)*1\n",
    "    \n",
    "    \n",
    "    P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.follow_Stalker == 1)].shape[0]/bdf.shape[0]\n",
    "    P_B = bdf.loc[(bdf.follow_Stalker == 1)].shape[0]/bdf.shape[0]\n",
    "    P_success_g_Stalker = round(P_A_and_B/P_B,2)\n",
    "\n",
    "    print('P(success|Stalker): {}'.format(P_success_g_Stalker))\n",
    "\n",
    "    P_A_and_B = bdf.loc[(bdf.successful == 1) & (bdf.follow_Star == 1)].shape[0]/bdf.shape[0]\n",
    "    P_B = bdf.loc[(bdf.follow_Star == 1)].shape[0]/bdf.shape[0]\n",
    "    P_success_g_Star = round(P_A_and_B/P_B,2)\n",
    "    \n",
    "    Robustness_table_3.loc['P(A|D)/P(A|E)', '{}/{}'.format(low_user_activity, high_user_activity)] = P_success_g_Stalker/P_success_g_Star\n",
    "    \n",
    "    \n",
    "    print('P(success|Star): {}'.format(P_success_g_Star))\n",
    "    \n",
    "Robustness_table_3.to_csv('Robustness_table_star_3.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518689af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Robustness_table_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae5673c",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0d6a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Robustness_table.columns = ['0.9', '0.75', '0.5']\n",
    "Robustness_table = Robustness_table[['0.5', '0.75', '0.9']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff8857",
   "metadata": {},
   "outputs": [],
   "source": [
    "Robustness_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314f1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create a sample dataframe\n",
    "df = Robustness_table\n",
    "\n",
    "# set the font size and style for the plot\n",
    "sns.set(font_scale=1.2, style=\"whitegrid\")\n",
    "\n",
    "# create two subplots, one for each row of the dataframe\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(8, 6), sharex=True)\n",
    "\n",
    "# plot the first row of the dataframe on the first subplot\n",
    "sns.lineplot(x=df.columns, y=df.iloc[0], ax=ax1, color=\"#4c72b0\")\n",
    "ax1.set_title(\"P(A|B)/P(A|C)\", fontweight='bold')\n",
    "ax1.set_ylabel('Probability Ratio', fontweight='bold')\n",
    "ax1.grid(False)\n",
    "\n",
    "# plot the second row of the dataframe on the second subplot\n",
    "sns.lineplot(x=df.columns, y=df.iloc[1], ax=ax2, color=\"#dd8452\")\n",
    "ax2.set_title(\"P(A|D)/P(A|E)\", fontweight='bold')\n",
    "ax2.set_xlabel('Success threshold', fontweight='bold')\n",
    "ax2.set_ylabel('Probability Ratio', fontweight='bold')\n",
    "ax2.grid(False)\n",
    "\n",
    "# add a title to the entire plot\n",
    "#fig.suptitle(\"Successful Creator Threshold Sensitivity: Conditional Probability Ratios\", fontweight='bold')\n",
    "\n",
    "# adjust spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "\n",
    "# display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f72c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "'P_success_g_Stalker/P_success_g_Star'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b71e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Robustness_table_2.columns = ['0.9', '0.75', '0.5']\n",
    "Robustness_table_2 = Robustness_table_2[['0.5', '0.75', '0.9']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae40031",
   "metadata": {},
   "outputs": [],
   "source": [
    "Robustness_table_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606dc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create a sample dataframe\n",
    "df = Robustness_table_2\n",
    "\n",
    "# set the font size and style for the plot\n",
    "sns.set(font_scale=1.2, style=\"whitegrid\")\n",
    "\n",
    "# create two subplots, one for each row of the dataframe\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(8, 6), sharex=True)\n",
    "\n",
    "# plot the first row of the dataframe on the first subplot\n",
    "sns.lineplot(x=df.columns, y=df.iloc[0], ax=ax1, color=\"#4c72b0\")\n",
    "ax1.set_title(\"P(A|B)/P(A|C)\", fontweight='bold')\n",
    "ax1.set_ylabel('Probability Ratio', fontweight='bold')\n",
    "ax1.grid(False)\n",
    "\n",
    "# plot the second row of the dataframe on the second subplot\n",
    "sns.lineplot(x=df.columns, y=df.iloc[1], ax=ax2, color=\"#dd8452\")\n",
    "ax2.set_title(\"P(A|D)/P(A|E)\", fontweight='bold')\n",
    "ax2.set_xlabel('High Outdegree Threshold', fontweight='bold')\n",
    "ax2.set_ylabel('Probability Ratio', fontweight='bold')\n",
    "ax2.grid(False)\n",
    "\n",
    "# add a title to the entire plot\n",
    "#fig.suptitle(\"Sensitivity to Outdegree Threshold: Conditional probability ratios.\")\n",
    "\n",
    "# adjust spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "\n",
    "# display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e1cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create a sample dataframe\n",
    "Robustness_table_3.columns = ['0.9', '0.75', '0.5']\n",
    "Robustness_table_3 = Robustness_table_3[['0.5', '0.75', '0.9']]\n",
    "df = Robustness_table_3\n",
    "\n",
    "# set the font size and style for the plot\n",
    "sns.set(font_scale=1.2, style=\"whitegrid\")\n",
    "\n",
    "# create two subplots, one for each row of the dataframe\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(8, 6), sharex=True)\n",
    "\n",
    "# plot the first row of the dataframe on the first subplot\n",
    "sns.lineplot(x=df.columns, y=df.iloc[0], ax=ax1, color=\"#4c72b0\")\n",
    "ax1.set_title(\"P(A|B)/P(A|C)\", fontweight='bold')\n",
    "ax1.set_ylabel('Probability Ratio', fontweight='bold')\n",
    "ax1.grid(False)\n",
    "\n",
    "# plot the second row of the dataframe on the second subplot\n",
    "sns.lineplot(x=df.columns, y=df.iloc[1], ax=ax2, color=\"#dd8452\")\n",
    "ax2.set_title(\"P(A|D)/P(A|E)\", fontweight='bold')\n",
    "ax2.set_xlabel('High Activity Threshold', fontweight='bold')\n",
    "ax2.set_ylabel('Probability Ratio', fontweight='bold')\n",
    "ax2.grid(False)\n",
    "\n",
    "# add a title to the entire plot\n",
    "#fig.suptitle(\"Sensitivity to High non-follow Actions Threshold: Conditional probability ratios.\")\n",
    "\n",
    "# adjust spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "\n",
    "# display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d01474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_user_outdegree = 0.25\n",
    "low_user_outdegree = 0.75\n",
    "\n",
    "low_user_activity = 0.25\n",
    "high_user_activity = 0.75\n",
    "\n",
    "Robustness_table_or_1 = pd.DataFrame(index = ['Q1', 'Q2', 'Q3', 'Q4'],\n",
    "                                columns = ['0.1/0.5', '0.1/0.75', '0.1/0.9',\n",
    "                                           '0.25/0.5', '0.25/0.75', '0.25/0.9',\n",
    "                                           '0.5/0.5', '0.5/0.75', '0.5/0.9'])\n",
    "\n",
    "for low_success, high_success in ([(0.1, 0.5), (0.1, 0.75), (0.1, 0.9),\n",
    "                                   (0.25, 0.5), (0.25, 0.75), (0.25, 0.9),\n",
    "                                   (0.5, 0.5), (0.5, 0.75), (0.5, 0.9)]): \n",
    "    \n",
    "        table_data, successful_ids, unsuccessful_ids, actions_sent_non_fans, maven_ids, star_ids, zombie_ids, stalker_ids = gen_datasets(low_success,\n",
    "           high_success, low_user_outdegree, high_user_outdegree, low_user_activity, high_user_activity) \n",
    "        \n",
    "        print('successful',len(successful_ids))\n",
    "        \n",
    "        #OR1\n",
    "        table_data.columns = ['fan_id', 'followers', 'outdegree_level', 'activities_performed', 'activity_level', 'Type']\n",
    "        table = follows_received.merge(table_data, left_on = 'fan_id', right_on = 'fan_id', how = 'inner') #suffixes\n",
    "\n",
    "        table['creator_type'] = table.user_id.apply(\n",
    "                                                    lambda x: 'successful' if x in successful_ids else \n",
    "                                                    ('unsuccessful' if x in unsuccessful_ids else 'other'))\n",
    "        try:\n",
    "            table1 = table.groupby(['creator_type','outdegree_level'], as_index = False).size()\n",
    "            mask = (table1.outdegree_level == 'high') & (table1.creator_type == 'successful')\n",
    "            g1 = table1.loc[mask]['size'].values[0]\n",
    "\n",
    "            mask = (table1.outdegree_level == 'high') & (table1.creator_type == 'unsuccessful')\n",
    "            g2 = table1.loc[mask]['size'].values[0]\n",
    "            group_ids1 = table.loc[table.creator_type == 'successful']\n",
    "            group_ids2 = table.loc[table.creator_type == 'unsuccessful']\n",
    "\n",
    "            Robustness_table_or_1.loc['Q1', '{}/{}'\n",
    "                                      .format(low_success, high_success)] = calculate_odds_ratio_ci(g1, g2, len(group_ids1)-g1, len(group_ids2)-g2)[0]\n",
    "        except:\n",
    "             Robustness_table_or_1.loc['Q1', '{}/{}'\n",
    "                                      .format(low_success, high_success)] = np.nan\n",
    "            \n",
    "        #OR2\n",
    "\n",
    "        try:\n",
    "        \n",
    "            table1 = table.groupby(['creator_type','Type'], as_index = False).size()\n",
    "\n",
    "            mask = (table1.Type == 'Star') & (table1.creator_type == 'successful')\n",
    "            g1 = table1.loc[mask]['size'].values[0]\n",
    "\n",
    "            mask = (table1.Type == 'Star') & (table1.creator_type == 'unsuccessful')\n",
    "            g2 = table1.loc[mask]['size'].values[0]\n",
    "            group_ids1 = table.loc[table.creator_type == 'successful']\n",
    "            group_ids2 = table.loc[table.creator_type == 'unsuccessful']\n",
    "            \n",
    "            print(calculate_odds_ratio_ci(g1, g2, len(group_ids1)-g1, len(group_ids2)-g2)[0])\n",
    "            Robustness_table_or_1.loc['Q2', '{}/{}'\n",
    "                                      .format(low_success, high_success)] = calculate_odds_ratio_ci(g1, g2, len(group_ids1)-g1, len(group_ids2)-g2)[0]\n",
    "        except:\n",
    "            \n",
    "            Robustness_table_or_1.loc['Q2', '{}/{}'\n",
    "                                      .format(low_success, high_success)] = np.nan\n",
    "        #OR3\n",
    "        \n",
    "        distribution_target_user_type = actions_sent_non_fans.groupby(['creator_type', 'user_type']).fan_id.nunique()\n",
    "        dist_target_user = distribution_target_user_type.to_frame().reset_index()\n",
    "        dist_target_user.columns = ['creator_type', 'user_type', 'non_follow_actions']\n",
    "        \n",
    "\n",
    "        mask = (dist_target_user.user_type == 'Star') & (dist_target_user.creator_type == 'successful')\n",
    "        g1 = dist_target_user.loc[mask].non_follow_actions.values[0]\n",
    "\n",
    "        mask = (dist_target_user.user_type == 'Zombie') & (dist_target_user.creator_type == 'successful')\n",
    "        g2 = dist_target_user.loc[mask].non_follow_actions.values[0]\n",
    "\n",
    "        group_ids1 = star_ids\n",
    "        group_ids2 = zombie_ids\n",
    "\n",
    "\n",
    "        Robustness_table_or_1.loc['Q3', '{}/{}'\n",
    "                                  .format(low_success, high_success)] = calculate_odds_ratio_ci(g1, g2, len(group_ids1)-g1, len(group_ids2)-g2)[0]\n",
    "\n",
    "\n",
    "        #OR4\n",
    "        \n",
    "\n",
    "        mask = (dist_target_user.user_type == 'Star') & (dist_target_user.creator_type == 'successful')\n",
    "        g1 = dist_target_user.loc[mask].non_follow_actions.values[0]\n",
    "\n",
    "        mask = (dist_target_user.user_type == 'Stalker') & (dist_target_user.creator_type == 'successful')\n",
    "        g2 = dist_target_user.loc[mask].non_follow_actions.values[0]\n",
    "\n",
    "        group_ids1 = star_ids\n",
    "        group_ids2 = stalker_ids\n",
    "\n",
    "        Robustness_table_or_1.loc['Q4', '{}/{}'\n",
    "                                  .format(low_success, high_success)] = calculate_odds_ratio_ci(g1, g2, len(group_ids1)-g1, len(group_ids2)-g2)[0]\n",
    "\n",
    "            \n",
    "Robustness_table_or_1.to_csv('Robustness_or_star.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cd6bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_success = 0.25\n",
    "high_success = 0.75\n",
    "\n",
    "\n",
    "low_user_activity = 0.25\n",
    "high_user_activity = 0.75\n",
    "\n",
    "Robustness_table_or_2 = pd.DataFrame(index = ['Q1', 'Q2', 'Q3', 'Q4'],\n",
    "                                columns = ['0.1/0.5', '0.1/0.75', '0.1/0.9',\n",
    "                                           '0.25/0.5', '0.25/0.75', '0.25/0.9',\n",
    "                                           '0.5/0.5', '0.5/0.75', '0.5/0.9'])\n",
    "                                     \n",
    "for low_user_outdegree, high_user_outdegree in [(0.1, 0.5), (0.1, 0.75), (0.1, 0.9),\n",
    "                                   (0.25, 0.5), (0.25, 0.75), (0.25, 0.9),\n",
    "                                   (0.5, 0.5), (0.5, 0.75), (0.5, 0.9)]:  \n",
    "        table_data, successful_ids, unsuccessful_ids, actions_sent_non_fans, maven_ids, star_ids, zombie_ids, stalker_ids = gen_datasets(low_success,\n",
    "           high_success, low_user_outdegree, high_user_outdegree, low_user_activity, high_user_activity) \n",
    "        \n",
    "        print('successful',len(successful_ids))\n",
    "        print('{} Mavens'.format(len(maven_ids)))\n",
    "        print('{} Star'.format(len(star_ids)))\n",
    "        print('{} Zombies'.format(len(zombie_ids)))\n",
    "        print('{} Stalkers'.format(len(stalker_ids)))\n",
    "        \n",
    "        #OR1\n",
    "        table_data.columns = ['fan_id', 'followers', 'outdegree_level', 'activities_performed', 'activity_level', 'Type']\n",
    "        table = follows_received.merge(table_data, left_on = 'fan_id', right_on = 'fan_id', how = 'inner') #suffixes\n",
    "\n",
    "        table['creator_type'] = table.user_id.apply(\n",
    "                                                    lambda x: 'successful' if x in successful_ids else \n",
    "                                                    ('unsuccessful' if x in unsuccessful_ids else 'other'))\n",
    "        try:\n",
    "            table1 = table.groupby(['creator_type','outdegree_level'], as_index = False).size()\n",
    "            mask = (table1.outdegree_level == 'high') & (table1.creator_type == 'successful')\n",
    "            g1 = table1.loc[mask]['size'].values[0]\n",
    "\n",
    "            mask = (table1.outdegree_level == 'high') & (table1.creator_type == 'unsuccessful')\n",
    "            g2 = table1.loc[mask]['size'].values[0]\n",
    "            group_ids1 = table.loc[table.creator_type == 'successful']\n",
    "            group_ids2 = table.loc[table.creator_type == 'unsuccessful']\n",
    "\n",
    "            Robustness_table_or_2.loc['Q1', '{}/{}'\n",
    "                                      .format(low_user_outdegree, high_user_outdegree)] = calculate_odds_ratio_ci(g1, g2, len(group_ids1)-g1, len(group_ids2)-g2)[0]\n",
    "        \n",
    "        except:\n",
    "            \n",
    "            Robustness_table_or_2.loc['Q1', '{}/{}'\n",
    "                                      .format(low_user_outdegree, high_user_outdegree)] = np.nan\n",
    "        #OR2\n",
    "\n",
    "        try:\n",
    "            table1 = table.groupby(['creator_type','Type'], as_index = False).size()\n",
    "\n",
    "            mask = (table1.Type == 'Star') & (table1.creator_type == 'successful')\n",
    "            g1 = table1.loc[mask]['size'].values[0]\n",
    "\n",
    "            mask = (table1.Type == 'Star') & (table1.creator_type == 'unsuccessful')\n",
    "            g2 = table1.loc[mask]['size'].values[0]\n",
    "            group_ids1 = table.loc[table.creator_type == 'successful']\n",
    "            group_ids2 = table.loc[table.creator_type == 'unsuccessful']\n",
    "\n",
    "            Robustness_table_or_2.loc['Q2', '{}/{}'\n",
    "                                      .format(low_user_outdegree, high_user_outdegree)] = calculate_odds_ratio_ci(g1, g2, len(group_ids1)-g1, len(group_ids2)-g2)[0]\n",
    "        \n",
    "        except:\n",
    "            \n",
    "            Robustness_table_or_2.loc['Q2', '{}/{}'\n",
    "                                      .format(low_user_outdegree, high_user_outdegree)] = np.nan\n",
    "            \n",
    "       #OR3\n",
    "        \n",
    "        distribution_target_user_type = actions_sent_non_fans.groupby(['creator_type', 'user_type']).fan_id.nunique()\n",
    "        dist_target_user = distribution_target_user_type.to_frame().reset_index()\n",
    "        dist_target_user.columns = ['creator_type', 'user_type', 'non_follow_actions']\n",
    "        \n",
    "        try:\n",
    "            mask = (dist_target_user.user_type == 'Star') & (dist_target_user.creator_type == 'successful')\n",
    "            g1 = dist_target_user.loc[mask].non_follow_actions.values[0]\n",
    "\n",
    "            mask = (dist_target_user.user_type == 'Zombie') & (dist_target_user.creator_type == 'successful')\n",
    "            g2 = dist_target_user.loc[mask].non_follow_actions.values[0]\n",
    "\n",
    "            group_ids1 = star_ids\n",
    "            group_ids2 = zombie_ids\n",
    "\n",
    "\n",
    "            Robustness_table_or_2.loc['Q3', '{}/{}'\n",
    "                                      .format(low_user_outdegree, high_user_outdegree)] = calculate_odds_ratio_ci(g1, g2, len(group_ids1)-g1, len(group_ids2)-g2)[0]\n",
    "        except:\n",
    "            Robustness_table_or_2.loc['Q3', '{}/{}'\n",
    "                                      .format(low_user_outdegree, high_user_outdegree)] = np.nan\n",
    "            \n",
    "        #OR4\n",
    "        \n",
    "        try:\n",
    "            mask = (dist_target_user.user_type == 'Star') & (dist_target_user.creator_type == 'successful')\n",
    "            g1 = dist_target_user.loc[mask].non_follow_actions.values[0]\n",
    "\n",
    "            mask = (dist_target_user.user_type == 'Stalker') & (dist_target_user.creator_type == 'successful')\n",
    "            g2 = dist_target_user.loc[mask].non_follow_actions.values[0]\n",
    "\n",
    "            group_ids1 = star_ids\n",
    "            group_ids2 = stalker_ids\n",
    "\n",
    "            Robustness_table_or_2.loc['Q4', '{}/{}'\n",
    "                                      .format(low_user_outdegree, high_user_outdegree)] = calculate_odds_ratio_ci(g1, g2, len(group_ids1)-g1, len(group_ids2)-g2)[0]\n",
    "        except:\n",
    "            \n",
    "            Robustness_table_or_2.loc['Q4', '{}/{}'\n",
    "                                      .format(low_user_outdegree, high_user_outdegree)] = np.nan\n",
    "            \n",
    "Robustness_table_or_2.to_csv('Robustness_or_star_2.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e605632",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_success = 0.25\n",
    "high_success = 0.75\n",
    "\n",
    "low_user_outdegree = 0.25\n",
    "high_user_outdegree = 0.75\n",
    "\n",
    "Robustness_table_or_3 = pd.DataFrame(index = ['Q1', 'Q2', 'Q3', 'Q4'],\n",
    "                                columns = ['0.1/0.5', '0.1/0.75', '0.1/0.9',\n",
    "                                           '0.25/0.5', '0.25/0.75', '0.25/0.9',\n",
    "                                           '0.5/0.5', '0.5/0.75', '0.5/0.9'])\n",
    "\n",
    "for low_user_activity, high_user_activity in ([(0.1, 0.5), (0.1, 0.75), (0.1, 0.9),\n",
    "                                   (0.25, 0.5), (0.25, 0.75), (0.25, 0.9),\n",
    "                                   (0.5, 0.5), (0.5, 0.75), (0.5, 0.9)]):\n",
    "    \n",
    "        table_data, successful_ids, unsuccessful_ids, actions_sent_non_fans, maven_ids, star_ids, zombie_ids, stalker_ids = gen_datasets(low_success,\n",
    "           high_success, low_user_outdegree, high_user_outdegree, low_user_activity, high_user_activity) \n",
    "        \n",
    "        print('successful',len(successful_ids))\n",
    "        \n",
    "        #OR1\n",
    "        table_data.columns = ['fan_id', 'followers', 'outdegree_level', 'activities_performed', 'activity_level', 'Type']\n",
    "        table = follows_received.merge(table_data, left_on = 'fan_id', right_on = 'fan_id', how = 'inner') #suffixes\n",
    "\n",
    "        table['creator_type'] = table.user_id.apply(\n",
    "                                                    lambda x: 'successful' if x in successful_ids else \n",
    "                                                    ('unsuccessful' if x in unsuccessful_ids else 'other'))\n",
    "        try:\n",
    "            table1 = table.groupby(['creator_type','outdegree_level'], as_index = False).size()\n",
    "            mask = (table1.outdegree_level == 'high') & (table1.creator_type == 'successful')\n",
    "            g1 = table1.loc[mask]['size'].values[0]\n",
    "\n",
    "            mask = (table1.outdegree_level == 'high') & (table1.creator_type == 'unsuccessful')\n",
    "            g2 = table1.loc[mask]['size'].values[0]\n",
    "            group_ids1 = table.loc[table.creator_type == 'successful']\n",
    "            group_ids2 = table.loc[table.creator_type == 'unsuccessful']\n",
    "\n",
    "            Robustness_table_or_3.loc['Q1', '{}/{}'\n",
    "                                      .format(low_user_activity, high_user_activity)] = calculate_odds_ratio_ci(g1, g2, len(group_ids1)-g1, len(group_ids2)-g2)[0]\n",
    "        except:\n",
    "            Robustness_table_or_3.loc['Q1', '{}/{}'\n",
    "                                      .format(low_user_activity, high_user_activity)] = np.nan\n",
    "            \n",
    "        #OR2\n",
    "        try:\n",
    "            table1 = table.groupby(['creator_type','Type'], as_index = False).size()\n",
    "\n",
    "            mask = (table1.Type == 'Star') & (table1.creator_type == 'successful')\n",
    "            g1 = table1.loc[mask]['size'].values[0]\n",
    "\n",
    "            mask = (table1.Type == 'Star') & (table1.creator_type == 'unsuccessful')\n",
    "            g2 = table1.loc[mask]['size'].values[0]\n",
    "            group_ids1 = table.loc[table.creator_type == 'successful']\n",
    "            group_ids2 = table.loc[table.creator_type == 'unsuccessful']\n",
    "\n",
    "            Robustness_table_or_3.loc['Q2', '{}/{}'\n",
    "                                      .format(low_user_activity, high_user_activity)] = calculate_odds_ratio_ci(g1, g2, len(group_ids1)-g1, len(group_ids2)-g2)[0]\n",
    "\n",
    "        except:\n",
    "            Robustness_table_or_3.loc['Q2', '{}/{}'\n",
    "                                      .format(low_user_activity, high_user_activity)] = np.nan\n",
    "            \n",
    "        #OR3\n",
    "        \n",
    "        distribution_target_user_type = actions_sent_non_fans.groupby(['creator_type', 'user_type']).fan_id.nunique()\n",
    "        dist_target_user = distribution_target_user_type.to_frame().reset_index()\n",
    "        dist_target_user.columns = ['creator_type', 'user_type', 'non_follow_actions']\n",
    "\n",
    "        try:\n",
    "            mask = (dist_target_user.user_type == 'Star') & (dist_target_user.creator_type == 'successful')\n",
    "            g1 = dist_target_user.loc[mask].non_follow_actions.values[0]\n",
    "\n",
    "            mask = (dist_target_user.user_type == 'Zombie') & (dist_target_user.creator_type == 'successful')\n",
    "            g2 = dist_target_user.loc[mask].non_follow_actions.values[0]\n",
    "\n",
    "            group_ids1 = star_ids\n",
    "            group_ids2 = zombie_ids\n",
    "\n",
    "\n",
    "            Robustness_table_or_3.loc['Q3', '{}/{}'\n",
    "                                      .format(low_user_activity, high_user_activity)] = calculate_odds_ratio_ci(g1, g2, len(group_ids1)-g1, len(group_ids2)-g2)[0]\n",
    "    \n",
    "        except:\n",
    "            \n",
    "            Robustness_table_or_3.loc['Q3', '{}/{}'\n",
    "                                      .format(low_user_activity, high_user_activity)] = np.nan\n",
    "        #OR4\n",
    "        \n",
    "        try:\n",
    "            mask = (dist_target_user.user_type == 'Star') & (dist_target_user.creator_type == 'successful')\n",
    "            g1 = dist_target_user.loc[mask].non_follow_actions.values[0]\n",
    "\n",
    "            mask = (dist_target_user.user_type == 'Stalker') & (dist_target_user.creator_type == 'successful')\n",
    "            g2 = dist_target_user.loc[mask].non_follow_actions.values[0]\n",
    "\n",
    "            group_ids1 = star_ids\n",
    "            group_ids2 = stalker_ids\n",
    "\n",
    "            Robustness_table_or_3.loc['Q4', '{}/{}'\n",
    "                                      .format(low_user_activity, high_user_activity)] = calculate_odds_ratio_ci(g1, g2, len(group_ids1)-g1, len(group_ids2)-g2)[0]\n",
    "        except:\n",
    "            \n",
    "            Robustness_table_or_3.loc['Q4', '{}/{}'\n",
    "                                      .format(low_user_activity, high_user_activity)] = np.nan\n",
    "            \n",
    "Robustness_table_or_3.to_csv('Robustness_or_star_3.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2074e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#low_success, high_success\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create a sample dataframe\n",
    "df = Robustness_table_or_1\n",
    "\n",
    "# set the font size and style for the plot\n",
    "sns.set(font_scale=1.2, style=\"whitegrid\")\n",
    "\n",
    "# create two subplots, one for each row of the dataframe\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows=4, figsize=(8, 12), sharex=True)\n",
    "\n",
    "# plot the first row of the dataframe on the first subplot\n",
    "sns.lineplot(x=df.columns, y=df.iloc[0], ax=ax1, color=\"#4c72b0\")\n",
    "ax1.set_title(\"Q1\", fontweight='bold')\n",
    "ax1.set_ylabel('Odds Ratio', fontweight='bold')\n",
    "ax1.grid(False)\n",
    "\n",
    "# plot the second row of the dataframe on the second subplot\n",
    "sns.lineplot(x=df.columns, y=df.iloc[1], ax=ax2, color=\"#dd8452\")\n",
    "ax2.set_title(\"Q2\", fontweight='bold')\n",
    "ax2.set_ylabel('Odds Ratio', fontweight='bold')\n",
    "ax2.grid(False)\n",
    "\n",
    "# plot the third row of the dataframe on the second subplot\n",
    "sns.lineplot(x=df.columns, y=df.iloc[2], ax=ax3, color='#2ca02c')\n",
    "ax3.set_title(\"Q3\", fontweight='bold')\n",
    "ax3.set_ylabel('Odds Ratio', fontweight='bold')\n",
    "ax3.grid(False)\n",
    "\n",
    "# plot the fourth row of the dataframe on the second subplot\n",
    "sns.lineplot(x=df.columns, y=df.iloc[3], ax=ax4, color=\"#9467bd\")\n",
    "ax4.set_title(\"Q4\", fontweight='bold')\n",
    "ax4.set_ylabel('Odds Ratio', fontweight='bold')\n",
    "ax4.grid(False)\n",
    "\n",
    "# add a title to the entire plot\n",
    "#fig.suptitle(\"Successful Creator Threshold Sensitivity: Conditional Probability Ratios\", fontweight='bold')\n",
    "\n",
    "# adjust spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.25)\n",
    "\n",
    "# display the plot\n",
    "plt.show()\n",
    "#ax2.set_xlabel('Success threshold', fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73ef4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#low_user_outdegree, high_user_outdegree\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create a sample dataframe\n",
    "Robustness_table_or_2.columns = ['0.9', '0.75', '0.5']\n",
    "Robustness_table_or_2 = Robustness_table_or_2[['0.5', '0.75', '0.9']]\n",
    "df = Robustness_table_or_2\n",
    "\n",
    "# set the font size and style for the plot\n",
    "sns.set(font_scale=1.2, style=\"whitegrid\")\n",
    "\n",
    "# create two subplots, one for each row of the dataframe\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows=4, figsize=(8, 12), sharex=True)\n",
    "\n",
    "# plot the first row of the dataframe on the first subplot\n",
    "sns.lineplot(x=df.columns, y=df.iloc[0], ax=ax1, color=\"#4c72b0\")\n",
    "ax1.set_title(\"Q1\", fontweight='bold')\n",
    "ax1.set_ylabel('Odds Ratio', fontweight='bold')\n",
    "ax1.grid(False)\n",
    "\n",
    "# plot the second row of the dataframe on the second subplot\n",
    "sns.lineplot(x=df.columns, y=df.iloc[1], ax=ax2, color=\"#dd8452\")\n",
    "ax2.set_title(\"Q2\", fontweight='bold')\n",
    "ax2.set_ylabel('Odds Ratio', fontweight='bold')\n",
    "ax2.grid(False)\n",
    "\n",
    "# plot the third row of the dataframe on the second subplot\n",
    "sns.lineplot(x=df.columns, y=df.iloc[2], ax=ax3, color='#2ca02c')\n",
    "ax3.set_title(\"Q3\", fontweight='bold')\n",
    "ax3.set_ylabel('Odds Ratio', fontweight='bold')\n",
    "ax3.grid(False)\n",
    "\n",
    "# plot the fourth row of the dataframe on the second subplot\n",
    "sns.lineplot(x=df.columns, y=df.iloc[3], ax=ax4, color=\"#9467bd\")\n",
    "ax4.set_title(\"Q4\", fontweight='bold')\n",
    "ax4.set_ylabel('Odds Ratio', fontweight='bold')\n",
    "ax4.grid(False)\n",
    "\n",
    "# add a title to the entire plot\n",
    "#fig.suptitle(\"Successful Creator Threshold Sensitivity: Conditional Probability Ratios\", fontweight='bold')\n",
    "\n",
    "# adjust spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "\n",
    "# display the plot\n",
    "plt.show()\n",
    "#ax2.set_xlabel('Success threshold', fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47341579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#low_user_activity, high_user_activity\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create a sample dataframe\n",
    "Robustness_table_or_3.columns = ['0.9', '0.75', '0.5']\n",
    "Robustness_table_or_3 = Robustness_table_or_2[['0.5', '0.75', '0.9']]\n",
    "df = Robustness_table_or_3\n",
    "\n",
    "# set the font size and style for the plot\n",
    "sns.set(font_scale=1.2, style=\"whitegrid\")\n",
    "\n",
    "# create two subplots, one for each row of the dataframe\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows=4, figsize=(8, 12), sharex=True)\n",
    "\n",
    "# plot the first row of the dataframe on the first subplot\n",
    "sns.lineplot(x=df.columns, y=df.iloc[0], ax=ax1, color=\"#4c72b0\")\n",
    "ax1.set_title(\"Q1\", fontweight='bold')\n",
    "ax1.set_ylabel('Odds Ratio', fontweight='bold')\n",
    "ax1.grid(False)\n",
    "\n",
    "# plot the second row of the dataframe on the second subplot\n",
    "sns.lineplot(x=df.columns, y=df.iloc[1], ax=ax2, color=\"#dd8452\")\n",
    "ax2.set_title(\"Q2\", fontweight='bold')\n",
    "ax2.set_ylabel('Odds Ratio', fontweight='bold')\n",
    "ax2.grid(False)\n",
    "\n",
    "# plot the third row of the dataframe on the second subplot\n",
    "sns.lineplot(x=df.columns, y=df.iloc[2], ax=ax3, color='#2ca02c')\n",
    "ax3.set_title(\"Q3\", fontweight='bold')\n",
    "ax3.set_ylabel('Odds Ratio', fontweight='bold')\n",
    "ax3.grid(False)\n",
    "\n",
    "# plot the fourth row of the dataframe on the second subplot\n",
    "sns.lineplot(x=df.columns, y=df.iloc[3], ax=ax4, color=\"#9467bd\")\n",
    "ax4.set_title(\"Q4\", fontweight='bold')\n",
    "ax4.set_ylabel('Odds Ratio', fontweight='bold')\n",
    "ax4.grid(False)\n",
    "# add a title to the entire plot\n",
    "#fig.suptitle(\"Successful Creator Threshold Sensitivity: Conditional Probability Ratios\", fontweight='bold')\n",
    "\n",
    "# adjust spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "\n",
    "# display the plot\n",
    "plt.show()\n",
    "#ax2.set_xlabel('Success threshold', fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495e943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Robustness_table_or_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1b248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Robustness_table_or_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd63da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Robustness_table_or_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0094376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Q5\"\n",
    "mask = (dist_target_user.user_type == 'Star') & (dist_target_user.creator_type == 'successful')\n",
    "g1 = dist_target_user.loc[mask].non_follow_actions.values[0]\n",
    "\n",
    "mask = (dist_target_user.user_type == 'Star') & (dist_target_user.creator_type == 'unsuccessful')\n",
    "g2 = dist_target_user.loc[mask].non_follow_actions.values[0]\n",
    "\n",
    "group_ids1 = table.loc[table.creator_type == 'successful']\n",
    "group_ids2 = table.loc[table.creator_type == 'unsuccessful']\n",
    "\n",
    "calculate_odds_ratio_ci(g1, g2, len(group_ids1)-g1, len(group_ids2)-g2)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abda3ca5",
   "metadata": {},
   "source": [
    "# random distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae49dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(maven_ids)+len(zombie_ids)+len(stalker_ids)+len(star_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23565e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(maven_ids)/total*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f8c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zombie_ids)/total*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc71f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stalker_ids)/total*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e5b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(star_ids)/total*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7883e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81028191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
